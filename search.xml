<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>卷积神经网络和树递归神经网络</title>
      <link href="/posts/4a42f569.html"/>
      <url>/posts/4a42f569.html</url>
      
        <content type="html"><![CDATA[<h1 id="ConvNet"><a href="#ConvNet" class="headerlink" title="ConvNet"></a>ConvNet</h1><h2 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h2><p>Apart from doing convolution to a 2-D image, we can do convolution to languages.<br>Typically, it should be using a 1-D convolutional layer.<br>To the first layer, the number of input channel is equal to the dimension of word embeddings.<br><img src="/img/CS224n/截屏2025-11-12 09.03.47.png" alt=""><br>After a layer of convolution, we can then apply <strong>MaxPool</strong> or <strong>AveragePool</strong> to the features.<br>Also, we can set strides to convolutional filters or pools.<br><img src="/img/CS224n/截屏2025-11-12 09.09.07.png" alt=""><br>Note that pooling can do globally(take average or max through all output features) or locally(only do pooling in a $n$-gram sliding windows)<br>We can use $k$-max pooling: not use max number of a channel, but use top $k$ largest values in a channel, to capture some more informations.</p><h2 id="Single-Layer-CNN"><a href="#Single-Layer-CNN" class="headerlink" title="Single Layer CNN"></a>Single Layer CNN</h2><p>A single CNN can be just one layer: convolution-pooling.<br>It can do some sentence classification.<br>The inner process of doing this is just doing vector product.<br>If word embedding is $d$-dimensional, and kernel size is $h$.<br>We concatenate $h$ adjacent vectors and form a longer $hd\times 1$ vector.</p><script type="math/tex; mode=display">x_{k:k+h-1}=[x^T_k,x^T_{k+1},...,x^T_{k+h-1}]^T</script><p>Then, we do convolution.</p><script type="math/tex; mode=display">c_k=f(W^Tx_{k:k+h-1}+b)</script><p>in which, $W$ is $hd\times 1$ vector while $f$ is activation function.<br>Then, we get the result for this full channel.</p><script type="math/tex; mode=display">c=[c_1,c_2,...,c_{n-h+1}]\in R^n-h+1</script><p>We pool it to extract some information.</p><script type="math/tex; mode=display">\hat{c}=max(c)</script><p>We can use multi-channels($m$ as example). So output of this layer can be</p><script type="math/tex; mode=display">z=[\hat c_1,\hat c_2,...,\hat c_m]</script><p>Then do linear and logistic regression or softmax to adapt for downstream tasks.</p><h2 id="Mixed-Kernel-Size"><a href="#Mixed-Kernel-Size" class="headerlink" title="Mixed Kernel Size"></a>Mixed Kernel Size</h2><p>Sometimes we can mix some kernel size, do different grams and mix them.<br>It can capture information of different scales of language.<br><img src="/img/CS224n/截屏2025-11-12 11.58.16.png" alt=""></p><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p>Transform the convolution output of a batch by scaling the activations to have zero mean and unit variance.<br>To be specific, for each channel, we do normalization among all elements in one channel.<br>If the activation feature is $batchSize\times channel\times n$, Then we do normalization to each $n$-elements.<br>Different from Layer Normalization in <a href="/posts/ab3e853d.html" title="Transformers">Transformers</a>, BatchNorm normalizes across all elements and items in a batch for each feature independently. While LayerNorm calculates statistics across all feature dimensions for each instance independently.</p><h2 id="Size-1-Convolution"><a href="#Size-1-Convolution" class="headerlink" title="Size 1 Convolution"></a>Size 1 Convolution</h2><p>In CV, size 1 convolution can serve as a <strong>Full-connection</strong> layer.<br>In NLP, intuitively, it can re-comprehend the meaning of a word.<br>Also, it can be used to map from many channels to fewer channels.</p><h2 id="Deep-Convolutional-Neural-Networks"><a href="#Deep-Convolutional-Neural-Networks" class="headerlink" title="Deep Convolutional Neural Networks"></a>Deep Convolutional Neural Networks</h2><p>Here we take VD-CNN as example.<br><img src="/img/CS224n/截屏2025-11-12 12.19.09.png" alt=""><br>ResNets are applied here.<br>A single <strong>Convolutional Block</strong> looks like as follows.<br><img src="/img/CS224n/截屏2025-11-12 12.20.32.png" alt=""></p><h1 id="Tree-Recursive-Neural-Network"><a href="#Tree-Recursive-Neural-Network" class="headerlink" title="Tree Recursive Neural Network"></a>Tree Recursive Neural Network</h1><h2 id="Constituency-Sentence-Parsing"><a href="#Constituency-Sentence-Parsing" class="headerlink" title="Constituency Sentence Parsing"></a>Constituency Sentence Parsing</h2><p>A sentence can be parsed into a tree, according to relationships of different words.<br><img src="/img/CS224n/截屏2025-11-12 12.22.55.png" alt=""><br>Compared to RNN, Tree Recursive Neural Network can capture more prefix context.<br><img src="/img/CS224n/截屏2025-11-12 12.25.19.png" alt=""></p><h2 id="Parsing-a-Sentence"><a href="#Parsing-a-Sentence" class="headerlink" title="Parsing a Sentence"></a>Parsing a Sentence</h2><p>Get a pair-wise score for each adjacent token pair.<br><img src="/img/CS224n/截屏2025-11-12 12.36.42.png" alt=""><br>Form a binary tree struct on pair that wins the highest score.<br><img src="/img/CS224n/截屏2025-11-12 12.37.38.png" alt=""><br>Continue to form a complete tree.</p><h2 id="Score-and-New-Vector"><a href="#Score-and-New-Vector" class="headerlink" title="Score and New Vector"></a>Score and New Vector</h2><p>There is a single way to get a new score and a new vector of a combination of two origin vectors.<br>The new combined vector $p$ is</p><script type="math/tex; mode=display">p=\tanh (W\begin{bmatrix}c_1\\c_2\end{bmatrix}+b)</script><p>The score can be mapped out from $p$.</p><script type="math/tex; mode=display">s=U^Tp</script><p>note that same $W$, $b$ and $U$ are applied to every node pair.<br>Here, some multiplicative relations of $c_1$ and $c_2$ may be missed.<br>We can also work out the $p$ as follows</p><script type="math/tex; mode=display">p=f(\begin{bmatrix}c_1\\c_2\end{bmatrix}^TV\begin{bmatrix}c_1\\c_2\end{bmatrix}+W\begin{bmatrix}c_1\\c_2\end{bmatrix})</script><p>Here $f$ can be sigmoid, serving as a logistic regression to indicate whether to combine the two nodes.(This can make training easier: prepare some manual labeled parsing process, logistic regress which nodes to combine every step.)</p><h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>Tree Recursive Neural Network can be used to do some sentence classification.<br><img src="/img/CS224n/截屏2025-11-12 13.01.42.png" alt=""><br>With a tree structure, the classification of positive/negative can be more naturally indicated. Because the meanings of human languages are more like a tree structure rather than a linear structure.</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> 树递归神经网络 </tag>
            
            <tag> 句法分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>训练优化</title>
      <link href="/posts/a7b1f35d.html"/>
      <url>/posts/a7b1f35d.html</url>
      
        <content type="html"><![CDATA[<h1 id="Mixed-Precision-Training"><a href="#Mixed-Precision-Training" class="headerlink" title="Mixed Precision Training"></a>Mixed Precision Training</h1><h2 id="Two-Kinds-of-float"><a href="#Two-Kinds-of-float" class="headerlink" title="Two Kinds of float"></a>Two Kinds of <code>float</code></h2><p>FP16 and FP 32 are all floats. FP16 takes 2 bytes while FP32 takes 4 bytes.<br>Compared to FP16, FP32 has greater range and is preciser. But it takes more memory and time during computation.<br>It’s common to meet CUDA <code>Out Of Memory</code> exception.<br><img src="/img/CS224n/截屏2025-11-07 11.34.52.png" alt=""><br>But when we are using FP16 throughout the training, some small gradient values will <strong>underflow(become zero)</strong>. We should use both FP16 and FP32.</p><h2 id="Mixing-FP32-and-FP16"><a href="#Mixing-FP32-and-FP16" class="headerlink" title="Mixing FP32 and FP16"></a>Mixing FP32 and FP16</h2><p><img src="/img/CS224n/截屏2025-11-07 11.39.52.png" alt=""><br>For origin model parameters, we all use FP32 to store them.<br>When passing to the training process(Forward, Backward and Compute Gradient), we cut them to FP16.<br>We can scale the final loss by a constant factor to further reduce the possibility of underflow.<br>Before doing gradient operations(gradient clipping, updating the original model parameters), we unscale the gradient(divide by scale factor).</p><h2 id="Implement-in-PyTorch"><a href="#Implement-in-PyTorch" class="headerlink" title="Implement in PyTorch"></a>Implement in PyTorch</h2><p>We first initialize a <code>GradScaler</code>.<br>We can assign the FWD and Loss Calculation process explicitly<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Creates model and optimizer in default precision</span></span><br><span class="line">model = Net().cuda()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), ...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Creates a GradScaler once at the beginning of training.</span></span><br><span class="line">scaler = GradScaler()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> data:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Runs the forward pass with autocasting.</span></span><br><span class="line">        <span class="keyword">with</span> autocast(device_type=<span class="string">&#x27;cuda&#x27;</span>, dtype=torch.float16):</span><br><span class="line">            output = model(<span class="built_in">input</span>)</span><br><span class="line">            loss = loss_fn(output, target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Scales loss.  Calls backward() on scaled loss to create scaled gradients.</span></span><br><span class="line">        <span class="comment"># Backward passes under autocast are not recommended.</span></span><br><span class="line">        <span class="comment"># Backward ops run in the same dtype autocast chose for corresponding forward ops.</span></span><br><span class="line">        scaler.scale(loss).backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># scaler.step() first unscales the gradients of the optimizer&#x27;s assigned params.</span></span><br><span class="line">        <span class="comment"># If these gradients do not contain infs or NaNs, optimizer.step() is then called,</span></span><br><span class="line">        <span class="comment"># otherwise, optimizer.step() is skipped.</span></span><br><span class="line">        scaler.step(optimizer)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Updates the scale for next iteration.</span></span><br><span class="line">        scaler.update()</span><br></pre></td></tr></table></figure><br>The <code>step</code> function of scaler will automatically <code>unscale</code> the gradient.<br>But if we need to do gradient clipping, we should unscale it explicitly.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Since the gradients of optimizer&#x27;s assigned params are unscaled, clips as usual:</span></span><br><span class="line">        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># optimizer&#x27;s gradients are already unscaled, so scaler.step does not unscale them,</span></span><br><span class="line">        <span class="comment"># although it still skips optimizer.step() if the gradients contain infs or NaNs.</span></span><br><span class="line">        scaler.step(optimizer)</span><br></pre></td></tr></table></figure></p><h2 id="BFloat16"><a href="#BFloat16" class="headerlink" title="BFloat16"></a>BFloat16</h2><p><img src="/img/CS224n/截屏2025-11-07 12.01.48.png" alt=""><br>BFloat16 is a special float type.<br>It can express much smaller(closer to 0) or larger values than FP16, for it has 8 Exponents.<br>But it can’t be much precise.<br>Involving BFloat16(replace FP16 with BFloat16), we then need no gradient scaling.</p><h1 id="Multi-GPU-Training"><a href="#Multi-GPU-Training" class="headerlink" title="Multi-GPU Training"></a>Multi-GPU Training</h1><h2 id="Distributed-Data-Parallel-DDP"><a href="#Distributed-Data-Parallel-DDP" class="headerlink" title="Distributed Data Parallel(DDP)"></a>Distributed Data Parallel(DDP)</h2><p>When we have a few GPUs, to implement DDP, we store a copy of the whole model parameters in each GPU.<br><img src="/img/CS224n/截屏2025-11-07 21.26.04.png" alt=""><br>When do batched-training, we equally divide the batch into parts.(For example, there are 64 data point in one batch, and we have 8 GPUs, so we assign 8 data point to each GPU)<br>After calculating the loss and the gradient of each GPU’s batches, all GPUs communicate with each other and average each one’s gradient(this process is called “AllReduce”), and do the parameter updating.<br>Then load the next batch and continue training.<br>However, each GPU holds a full copy of model parameters, optimizer state and gradients. It’s a waste of memory.</p><h2 id="Fully-Sharded-Data-Parallel-FSDP"><a href="#Fully-Sharded-Data-Parallel-FSDP" class="headerlink" title="Fully Sharded Data Parallel(FSDP)"></a>Fully Sharded Data Parallel(FSDP)</h2><p>FSDP also needs to divide the batch into several parts.<br>GPUs need to communicate with each other, sending values needed by other GPUs.<br><img src="/img/CS224n/截屏2025-11-09 21.17.16.png" alt=""><br>In stage 1(<script type="math/tex">P_{os}</script>) and stage 2(<script type="math/tex">P_{os+g}</script>), we distribute the optimizer states(stage1 and stage 2) and the gradient(stage 2), each GPU only holding a shard of the full datas.<br>These process won’t cause a time cost.<br>To stage 3(<script type="math/tex">P_{os+g+p}</script>), we even distribute the parameters. This will save a lot of memory, but need to cost more time.<br>The full process of FSDP goes as follows.</p><ol><li>Divide model parameters into FSDP units, and shard each unit across multiple GPUs.<br><img src="/img/CS224n/截屏2025-11-09 21.30.41.png" alt=""></li><li>Run forward pass.<ul><li>For each layer, perform an all-gather so each GPU gets what it needs.</li><li>Run forward pass.</li><li>Discard used parts of each GPU.<br><img src="/img/CS224n/截屏2025-11-09 21.33.55.png" alt=""></li></ul></li><li>Run backward pass.<ul><li>For each layer, perform an all-gather so each GPU gets what it needs.</li><li>Each GPU computes gradient for its data chunk.</li><li>Do a reduce-scatter(send full gradient piece to the right GPU).</li><li>Each GPU updates its own shard using the full gradient received earlier.<br><img src="/img/CS224n/截屏2025-11-09 21.38.39.png" alt=""><h1 id="Parameter-efficient-Fine-tuning-PEFT"><a href="#Parameter-efficient-Fine-tuning-PEFT" class="headerlink" title="Parameter-efficient Fine-tuning(PEFT)"></a>Parameter-efficient Fine-tuning(PEFT)</h1>To finetune a large model, we need huge memory. So we shall come up with some methods.<br>First we can only choose and finetune only a small part of the model.<br>We do forward propagation with full parameters and only do gradient step to some parameters and fix other parameters.<br><img src="/img/CS224n/截屏2025-11-09 21.39.53.png" alt=""><h2 id="Low-rank-parameterized-Update-LoRA"><a href="#Low-rank-parameterized-Update-LoRA" class="headerlink" title="Low-rank-parameterized Update(LoRA)"></a>Low-rank-parameterized Update(LoRA)</h2>When doing weight update, the updating matrix usually is a low rank matrix.<br>For a weight matrix $W_0$, we do<script type="math/tex; mode=display">W'=W_0+\Delta W</script>in which, Three matrices are $d\times k$.<br>Notice that $W_0$ is weight matrix after pretraining. $\Delta W$ is the overall difference between the pretrained weight and the finetuned weight.<br>And here, $\Delta W$ is usually a low-rank matrix.<br>So, we can view it as<script type="math/tex; mode=display">\Delta W=BA</script>in which, $B\in R^{d\times r}$ and $A\in R^{r\times k}$.<br>$r$ is far small than $\min(d,k)$, causing the number of parameters to be update greatly reduced.<br>While finetuning, we fix $W_0$ and only modify $B$ and $A$.<br>After the training process, we do update with hyperparameter $\alpha$<script type="math/tex; mode=display">W_+=W_0+\alpha BA</script>in which, $\alpha$ is a scalar that do a trade-off between original knowledge learned from pretraining and new knowledge learned from finetuning.<h1 id="Strategy-Selection-in-Efficient-Training"><a href="#Strategy-Selection-in-Efficient-Training" class="headerlink" title="Strategy Selection in Efficient Training"></a>Strategy Selection in Efficient Training</h1>We shall use different efficient training methods, for our GPU power and memory are always finite.<br><img src="/img/CS224n/截屏2025-11-09 22.30.24.png" alt=""></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 混合精度训练 </tag>
            
            <tag> 多卡训练 </tag>
            
            <tag> LoRA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HuggingFace入门</title>
      <link href="/posts/8c119005.html"/>
      <url>/posts/8c119005.html</url>
      
        <content type="html"><![CDATA[<p>Basic python tools are in transformers library.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers</span><br></pre></td></tr></table></figure></p><h1 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h1><p>A Large Language Model has its own tokenizer.<br>Tokenizer is the algorithm to divide sentences into a sequence of tokens.</p><h2 id="Load-Tokenizer"><a href="#Load-Tokenizer" class="headerlink" title="Load Tokenizer"></a>Load Tokenizer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DistilBertTokenizer, DistilBertTokenizerFast, AutoTokenizer</span><br></pre></td></tr></table></figure><p><em>DistilBert is the distilled version of BERT Model.(distill makes the model smaller but has similar function)</em><br><em>DistilBertTokenizer is its Tokenizer.</em><br><em>DistilBertTokenizerFast the version rewrite in Rust which goes faster than the Python version.</em><br>Use these tokenizer models to contain tokenizer from internet.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">&quot;distilbert/distilbert-base-cased&quot;</span></span><br><span class="line"></span><br><span class="line">tokenizer = DistilBertTokenizer.from_pretrained(name) <span class="comment"># written in Python</span></span><br><span class="line"><span class="built_in">print</span>(tokenizer)</span><br><span class="line"></span><br><span class="line">tokenizer = DistilBertTokenizerFast.from_pretrained(name) <span class="comment"># written in Rust</span></span><br><span class="line"><span class="built_in">print</span>(tokenizer)</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(name) <span class="comment"># convenient! Defaults to Fast</span></span><br><span class="line"><span class="built_in">print</span>(tokenizer)</span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DistilBertTokenizer(name_or_path=<span class="string">&#x27;distilbert/distilbert-base-cased&#x27;</span>, vocab_size=<span class="number">28996</span>, model_max_length=<span class="number">1000000000000000019884624838656</span>, ...... &#125; </span><br><span class="line"></span><br><span class="line">DistilBertTokenizerFast(name_or_path=<span class="string">&#x27;distilbert/distilbert-base-cased&#x27;</span>, vocab_size=<span class="number">28996</span>, model_max_length=<span class="number">1000000000000000019884624838656</span>, ...... &#125; </span><br><span class="line"></span><br><span class="line">DistilBertTokenizerFast(name_or_path=<span class="string">&#x27;distilbert/distilbert-base-cased&#x27;</span>, vocab_size=<span class="number">28996</span>, model_max_length=<span class="number">1000000000000000019884624838656</span>, ...... &#125;</span><br></pre></td></tr></table></figure></p><h2 id="Call-Tokenizer"><a href="#Call-Tokenizer" class="headerlink" title="Call Tokenizer"></a>Call Tokenizer</h2><p>Just feed String sentence into it.<br>The output is a dict include <code>input_ids</code> and <code>attention_mask</code>.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">input_str = <span class="string">&quot;Hugging Face Transformers is great!&quot;</span></span><br><span class="line"></span><br><span class="line">tokenized_inputs = tokenizer(input_str)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Two ways to access:</span></span><br><span class="line"><span class="built_in">print</span>(tokenized_inputs.input_ids)</span><br><span class="line"><span class="built_in">print</span>(tokenized_inputs[<span class="string">&quot;input_ids&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tokenized_inputs.attention_mask)</span><br><span class="line"><span class="built_in">print</span>(tokenized_inputs.[<span class="string">&quot;attention_mask&quot;</span>])</span><br></pre></td></tr></table></figure><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[101, 20164, 10932, 10289, 25267, 1110, 1632, 106, 102]</span><br><span class="line">[101, 20164, 10932, 10289, 25267, 1110, 1632, 106, 102]</span><br><span class="line"></span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 1, 1]</span><br><span class="line">[1, 1, 1, 1, 1, 1, 1, 1, 1]</span><br></pre></td></tr></table></figure><br>The inner process is like as follows<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">start:Hugging Face Transformers is great!</span><br><span class="line">tokenize:[&#x27;Hu&#x27;, &#x27;##gging&#x27;, &#x27;Face&#x27;, &#x27;Transformers&#x27;, &#x27;is&#x27;, &#x27;great&#x27;, &#x27;!&#x27;]</span><br><span class="line">convert_tokens_to_ids:[20164, 10932, 10289, 25267, 1110, 1632, 106]</span><br><span class="line">add special tokens:[101, 20164, 10932, 10289, 25267, 1110, 1632, 106, 102]</span><br><span class="line">--------</span><br><span class="line">decode:[CLS] Hugging Face Transformers is great! [SEP]</span><br></pre></td></tr></table></figure><br>We can let the tokenizer output pytorch tensors.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_inputs = tokenizer(<span class="string">&quot;Hugging Face Transformers is great!&quot;</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br></pre></td></tr></table></figure><br>We can feed in batches of sentences, and ask it to pad the tokens(make all the tokenized sequence same-length, by padding special <code>&lt;Pad&gt;</code> tokens to end of not-longest sequences, or just pad every sequence to the model’s max length)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model_inputs = tokenizer(</span><br><span class="line">[<span class="string">&quot;Hugging Face Transformers is great!&quot;</span>,</span><br><span class="line"><span class="string">&quot;The quick brown fox jumps over the lazy dog.&quot;</span> +\</span><br><span class="line"><span class="string">&quot;Then the dog got up and ran away because she didn&#x27;t like foxes.&quot;</span>,</span><br><span class="line">],</span><br><span class="line">return_tensors=<span class="string">&quot;pt&quot;</span>,</span><br><span class="line">padding=<span class="literal">True</span>,</span><br><span class="line">truncation=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br>truncation means that when the sequence is longer than limited length of the model(transformers model has fixed max input length, according to <a href="/posts/ab3e853d.html" title="Transformers">Transformers</a>), the tokenizer will cut and discard the rest tokens in the end.</p><h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><h2 id="Load-Model"><a href="#Load-Model" class="headerlink" title="Load Model"></a>Load Model</h2><p>Models in transformers can be loaded in similar ways.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification, DistilBertForSequenceClassification, DistilBertModel</span><br><span class="line"></span><br><span class="line">base_model = DistilBertModel.from_pretrained(<span class="string">&#x27;distilbert-base-cased&#x27;</span>)</span><br><span class="line">model = DistilBertForSequenceClassification.from_pretrained(<span class="string">&#x27;distilbert-base-cased&#x27;</span>, num_labels=<span class="number">2</span>)</span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(<span class="string">&#x27;distilbert-base-cased&#x27;</span>, num_labels=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><br>We can also load model with random weights.<br>Here we load a model with a random classifier with output dimension $2$.<br>Note that the parameters of the classifier haven’t been trained right after it’s loaded.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DistilBertConfig, DistilBertModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initializing a DistilBERT configuration</span></span><br><span class="line">configuration = DistilBertConfig()</span><br><span class="line">configuration.num_labels=<span class="number">2</span></span><br><span class="line"><span class="comment"># Initializing a model (with random weights) from the configuration</span></span><br><span class="line">model = DistilBertForSequenceClassification(configuration)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accessing the model configuration</span></span><br><span class="line">configuration = model.config</span><br></pre></td></tr></table></figure></p><h2 id="Feed-Data"><a href="#Feed-Data" class="headerlink" title="Feed Data"></a>Feed Data</h2><p>We can feed datas in form of key-value.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model_inputs = tokenizer(input_str, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Option 1</span></span><br><span class="line">model_outputs = model(</span><br><span class="line">input_ids=model_inputs.input_ids,</span><br><span class="line">attention_mask=model_inputs.attention_mask</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Option 2 - the keys of the dictionary the tokenizer returns are the same as the keyword arguments</span></span><br><span class="line">model_outputs = model(**model_inputs)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model_outputs)</span><br></pre></td></tr></table></figure><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SequenceClassifierOutput(loss=None, logits=tensor([[0.0368, 0.0659]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</span><br></pre></td></tr></table></figure><br>For training, we can concatenate the loaded model with torch’s APIs.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># We can calculate the loss like normal</span></span><br><span class="line">label = torch.tensor([<span class="number">1</span>])</span><br><span class="line">loss = torch.nn.functional.cross_entropy(model_outputs.logits, label)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># You can get the parameters</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(model.named_parameters())[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tensor(0.6787, grad_fn=&lt;NllLossBackward0&gt;)</span><br><span class="line"></span><br><span class="line">(&#x27;distilbert.embeddings.word_embeddings.weight&#x27;,</span><br><span class="line"> Parameter containing:</span><br><span class="line"> tensor([[-2.5130e-02, -3.3044e-02, -2.4396e-03,  ..., -1.0848e-02,</span><br><span class="line">          -4.6824e-02, -9.4855e-03],</span><br><span class="line">         [-4.8244e-03, -2.1486e-02, -8.7145e-03,  ..., -2.6029e-02,</span><br><span class="line">          -3.7862e-02, -2.4103e-02],</span><br><span class="line">         ...,</span><br><span class="line">         [ 1.1905e-02, -2.3293e-02, -2.2506e-02,  ..., -2.7136e-02,</span><br><span class="line">          -4.3556e-02,  1.0529e-04]], requires_grad=True))</span><br></pre></td></tr></table></figure><br>To extract the output attention and hidden state in the model calculation, we can set some parameters when load the model.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel</span><br><span class="line"></span><br><span class="line">model = AutoModel.from_pretrained(<span class="string">&quot;distilbert-base-cased&quot;</span>, output_attentions=<span class="literal">True</span>, output_hidden_states=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">model_inputs = tokenizer(input_str, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    model_output = model(**model_inputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Hidden state size (per layer):  &quot;</span>, model_output.hidden_states[<span class="number">0</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Attention head size (per layer):&quot;</span>, model_output.attentions[<span class="number">0</span>].shape)</span><br></pre></td></tr></table></figure></p><h1 id="Finetuning"><a href="#Finetuning" class="headerlink" title="Finetuning"></a>Finetuning</h1><h2 id="Load-the-Dataset"><a href="#Load-the-Dataset" class="headerlink" title="Load the Dataset"></a>Load the Dataset</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset, DatasetDict</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataLoader(zip(list1, list2))</span></span><br><span class="line">dataset_name = <span class="string">&quot;stanfordnlp/imdb&quot;</span></span><br><span class="line">imdb_dataset = load_dataset(dataset_name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Just take the first 50 tokens for speed/running on cpu</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">truncate</span>(<span class="params">example</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;text&#x27;</span>: <span class="string">&quot; &quot;</span>.join(example[<span class="string">&#x27;text&#x27;</span>].split()[:<span class="number">50</span>]),</span><br><span class="line">        <span class="string">&#x27;label&#x27;</span>: example[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(imdb_dataset)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;, &#x27;label&#x27;],</span><br><span class="line">        num_rows: 25000</span><br><span class="line">    &#125;)</span><br><span class="line">    test: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;, &#x27;label&#x27;],</span><br><span class="line">        num_rows: 25000</span><br><span class="line">    &#125;)</span><br><span class="line">    unsupervised: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;, &#x27;label&#x27;],</span><br><span class="line">        num_rows: 50000</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>Here, we randomly load some of the data<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Take 128 random examples for train and 32 validation</span></span><br><span class="line">small_imdb_dataset = DatasetDict(</span><br><span class="line">train=imdb_dataset[<span class="string">&#x27;train&#x27;</span>].shuffle(seed=<span class="number">1111</span>).select(<span class="built_in">range</span>(<span class="number">128</span>)).<span class="built_in">map</span>(truncate),</span><br><span class="line">    val=imdb_dataset[<span class="string">&#x27;train&#x27;</span>].shuffle(seed=<span class="number">1111</span>).select(<span class="built_in">range</span>(<span class="number">128</span>, <span class="number">160</span>)).<span class="built_in">map</span>(truncate),</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(small_imdb_dataset)</span><br></pre></td></tr></table></figure><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;, &#x27;label&#x27;],</span><br><span class="line">        num_rows: 128</span><br><span class="line">    &#125;)</span><br><span class="line">    val: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;, &#x27;label&#x27;],</span><br><span class="line">        num_rows: 32</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><br>Then, we tokenize the dataset and turn it into batched tensors.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Prepare the dataset - this tokenizes the dataset in batches of 16 examples.</span></span><br><span class="line">small_tokenized_dataset = small_imdb_dataset.<span class="built_in">map</span>(</span><br><span class="line">    <span class="keyword">lambda</span> example: tokenizer(example[<span class="string">&#x27;text&#x27;</span>], padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>),</span><br><span class="line">    batched=<span class="literal">True</span>,</span><br><span class="line">    batch_size=<span class="number">16</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">small_tokenized_dataset = small_tokenized_dataset.remove_columns([<span class="string">&quot;text&quot;</span>])</span><br><span class="line">small_tokenized_dataset = small_tokenized_dataset.rename_column(<span class="string">&quot;label&quot;</span>, <span class="string">&quot;labels&quot;</span>)</span><br><span class="line">small_tokenized_dataset.set_format(<span class="string">&quot;torch&quot;</span>)</span><br></pre></td></tr></table></figure><br>Feed the data into <code>dataloader</code>, ready to do tensor jobs in <code>pytorch</code>.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">train_dataloader = DataLoader(small_tokenized_dataset[<span class="string">&#x27;train&#x27;</span>], batch_size=<span class="number">16</span>)</span><br><span class="line">eval_dataloader = DataLoader(small_tokenized_dataset[<span class="string">&#x27;val&#x27;</span>], batch_size=<span class="number">16</span>)</span><br></pre></td></tr></table></figure></p><h2 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h2><p>Hugging Face models are also <code>torch.nn.Module</code>s so backpropagation happens the same way.<br>For optimization, we’re using the AdamW Optimizer, which is almost identical to Adam except it also includes weight decay. And we’re using a linear learning rate scheduler, which reduces the learning rate a little bit after each training step over the course of training.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW, get_linear_schedule_with_warmup</span><br><span class="line"><span class="keyword">from</span> tqdm.notebook <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">model = DistilBertForSequenceClassification.from_pretrained(<span class="string">&#x27;distilbert-base-cased&#x27;</span>, num_labels=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">1</span></span><br><span class="line">num_training_steps = <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">optimizer = AdamW(model.parameters(), lr=<span class="number">5e-5</span>, weight_decay=<span class="number">0.01</span>)</span><br><span class="line">lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=<span class="number">0</span>, num_training_steps=num_training_steps)</span><br><span class="line"></span><br><span class="line">best_val_loss = <span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)</span><br><span class="line">progress_bar = tqdm(<span class="built_in">range</span>(num_training_steps))</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># training</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch_i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># batch = ([text1, text2], [0, 1])</span></span><br><span class="line"></span><br><span class="line">        output = model(**batch)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output.loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        progress_bar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># validation</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">for</span> batch_i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(eval_dataloader):</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            output = model(**batch)</span><br><span class="line">        loss += output.loss</span><br><span class="line"></span><br><span class="line">    avg_val_loss = loss / <span class="built_in">len</span>(eval_dataloader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Validation loss: <span class="subst">&#123;avg_val_loss&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> avg_val_loss &lt; best_val_loss:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Saving checkpoint!&quot;</span>)</span><br><span class="line">        best_val_loss = avg_val_loss</span><br><span class="line">        <span class="comment"># torch.save(&#123;</span></span><br><span class="line">        <span class="comment">#     &#x27;epoch&#x27;: epoch,</span></span><br><span class="line">        <span class="comment">#     &#x27;model_state_dict&#x27;: model.state_dict(),</span></span><br><span class="line">        <span class="comment">#     &#x27;optimizer_state_dict&#x27;: optimizer.state_dict(),</span></span><br><span class="line">        <span class="comment">#     &#x27;val_loss&#x27;: best_val_loss,</span></span><br><span class="line">        <span class="comment">#     &#125;,</span></span><br><span class="line">        <span class="comment">#     f&quot;checkpoints/epoch_&#123;epoch&#125;.pt&quot;</span></span><br><span class="line">        <span class="comment"># )</span></span><br></pre></td></tr></table></figure><br><code>transformers</code> also provides us with a <code>Trainer</code> class and a <code>TrainingArguments</code> class.<br>We first create the arguments object, then define the trainer.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments, Trainer</span><br><span class="line"></span><br><span class="line">model = DistilBertForSequenceClassification.from_pretrained(<span class="string">&#x27;distilbert-base-cased&#x27;</span>, num_labels=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">arguments = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;sample_hf_trainer&quot;</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">16</span>,</span><br><span class="line">    per_device_eval_batch_size=<span class="number">16</span>,</span><br><span class="line">    num_train_epochs=<span class="number">2</span>,</span><br><span class="line">    evaluation_strategy=<span class="string">&quot;epoch&quot;</span>, <span class="comment"># run validation at the end of each epoch</span></span><br><span class="line">    save_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    load_best_model_at_end=<span class="literal">True</span>,</span><br><span class="line">    seed=<span class="number">224</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_metrics</span>(<span class="params">eval_pred</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Called at the end of validation. Gives accuracy&quot;&quot;&quot;</span></span><br><span class="line">    logits, labels = eval_pred</span><br><span class="line">    predictions = np.argmax(logits, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># calculates the accuracy</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;accuracy&quot;</span>: np.mean(predictions == labels)&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=arguments,</span><br><span class="line">    train_dataset=small_tokenized_dataset[<span class="string">&#x27;train&#x27;</span>],</span><br><span class="line">    eval_dataset=small_tokenized_dataset[<span class="string">&#x27;val&#x27;</span>], <span class="comment"># change to test when you do your final evaluation!</span></span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><h2 id="Evaluate"><a href="#Evaluate" class="headerlink" title="Evaluate"></a>Evaluate</h2><p>Using the trainer class, evaluating the model is very easy.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># results = trainer.evaluate() # just gets evaluation metrics</span></span><br><span class="line">results = trainer.predict(small_tokenized_dataset[<span class="string">&#x27;val&#x27;</span>]) <span class="comment"># also gives you predictions</span></span><br></pre></td></tr></table></figure></p><h2 id="Load"><a href="#Load" class="headerlink" title="Load"></a>Load</h2><p>To load the model, we can just type in the directory and check point.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># To load our saved model, we can pass the path to the checkpoint into the `from_pretrained` method:</span></span><br><span class="line">test_str = <span class="string">&quot;I enjoyed the movie!&quot;</span></span><br><span class="line"></span><br><span class="line">finetuned_model = AutoModelForSequenceClassification.from_pretrained(<span class="string">&quot;sample_hf_trainer/checkpoint-8&quot;</span>)</span><br><span class="line">model_inputs = tokenizer(test_str, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">prediction = torch.argmax(finetuned_model(**model_inputs).logits)</span><br><span class="line"><span class="built_in">print</span>([<span class="string">&quot;NEGATIVE&quot;</span>, <span class="string">&quot;POSITIVE&quot;</span>][prediction])</span><br></pre></td></tr></table></figure></p><h2 id="Suggested-Hyper-Parameters-for-Finetuning"><a href="#Suggested-Hyper-Parameters-for-Finetuning" class="headerlink" title="Suggested Hyper Parameters for Finetuning"></a>Suggested Hyper Parameters for Finetuning</h2><ul><li>Epochs: {2, 3, 4} (larger amounts of data need fewer epochs)</li><li>Batch size (bigger is better: as large as you can make it)</li><li>Optimizer: AdamW</li><li>AdamW learning rate: {2e-5, 5e-5}</li><li>Learning rate scheduler: linear warm up for first {0, 100, 500} steps of training</li><li>weight_decay (l2 regularization): {0, 0.01, 0.1}</li></ul>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HuggingFace </tag>
            
            <tag> 大语言模型 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>预训练后续</title>
      <link href="/posts/26410c69.html"/>
      <url>/posts/26410c69.html</url>
      
        <content type="html"><![CDATA[<h1 id="Prompting-for-Pretrained-Models"><a href="#Prompting-for-Pretrained-Models" class="headerlink" title="Prompting for Pretrained Models"></a>Prompting for Pretrained Models</h1><p><em>This involves no gradient steps!</em><br>Pretrained models have learned some basic tools and knowledges to handle human language tasks.<br>Take GPT as example. GPT is a decoder that can generated a sequence of tokens based on input tokens(may be human’s questions).<br>When it’s not finetuned for specific tasks, we can still use some prompts(ask it explicitly in the input sentence) to let it handle specific tasks with already learned general skills.<br>The state that the model is trained on enough amount of data and is big enough, then it can handle some specific task without finetuning is called <strong>Emergent</strong>.</p><h2 id="Zero-shot-Learning"><a href="#Zero-shot-Learning" class="headerlink" title="Zero-shot Learning"></a>Zero-shot Learning</h2><p>Give the model a prompt, and just ask following questions.<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Your following task is to translate the sentences to Chinese.</span><br><span class="line"></span><br><span class="line">I love china.</span><br><span class="line">I want to eat fish.</span><br></pre></td></tr></table></figure><br>Then, the model can generate response that translates user’s request.</p><h2 id="Few-shot-Learning"><a href="#Few-shot-Learning" class="headerlink" title="Few-shot Learning"></a>Few-shot Learning</h2><p>Give the model a prompt, and some example inputs and outputs. Then the model can do the task more precisely.<br>A shot is an example for the model.<br><img src="/img/CS224n/截屏2025-11-01 22.17.45.png" alt=""><br>The picture shows the user gives the model a task and give some examples. And let the model to do new task of the same kind.</p><h3 id="Chain-of-Thought-Prompting"><a href="#Chain-of-Thought-Prompting" class="headerlink" title="Chain-of-Thought Prompting"></a>Chain-of-Thought Prompting</h3><p>For some tasks that needs a chain of thought(can’t work out directly), we can give the examples in the form of Question-Thinking Chain-Answer.<br><img src="/img/CS224n/截屏2025-11-01 22.21.10.png" alt=""><br>In this pattern, the model tends to give more precise answer with its thinking chain.<br>Another way to implement Chain-of-Thought is force the model to output a sentence like “Let’s think step by step.”<br>Then the model will output step-by-step thinking.</p><h1 id="Scaling-Up-Finetuning"><a href="#Scaling-Up-Finetuning" class="headerlink" title="Scaling Up Finetuning"></a>Scaling Up Finetuning</h1><p>We can feed the data each in the form of <strong>Initial Input-Task Label-Output</strong>.<br>Then we can let the model do multi-tasks.<br>This finetuning doesn’t need the model to do Chatting with user, but do various kinds of tasks with clear label in the input.</p><h1 id="Instruction-Finetuning"><a href="#Instruction-Finetuning" class="headerlink" title="Instruction Finetuning"></a>Instruction Finetuning</h1><h2 id="Implement"><a href="#Implement" class="headerlink" title="Implement"></a>Implement</h2><p><img src="/img/CS224n/截屏2025-11-01 23.18.39.png" alt=""><br>Finetuning the model with the dataset in the from of <strong>Question-Answer</strong>.<br><img src="/img/CS224n/截屏2025-11-01 23.18.56.png" alt=""></p><h2 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h2><p>language modeling penalizes all token-level mistakes equally. But tasks like open-ended creative generation have no right answer, and even with instruction finetuning, there are mismatches between the LM objective and the objective of “satisfy human preferences”.</p><h1 id="Direct-Preference-Optimization-DPO"><a href="#Direct-Preference-Optimization-DPO" class="headerlink" title="Direct Preference Optimization(DPO)"></a>Direct Preference Optimization(DPO)</h1><p>After doing the instruction finetuning, we can do some extra optimization for the model, to let the model more possible to generate the answer that satisfy humans.</p><h2 id="Dataset-Demand"><a href="#Dataset-Demand" class="headerlink" title="Dataset Demand"></a>Dataset Demand</h2><p>We need the data in the form of</p><ul><li>Input sequence $x$</li><li>Some possible output sequence $y$s to the given $x$</li><li>The human labeled satisfied rank of the $y$s.<br>The model itself can calculate the log-likelihood $p_\theta(y|x)$ for an input $x$ and a specific $y$ as follows<script type="math/tex; mode=display">\log p_\theta(y|x)=\log\prod_{t=1}^np_\theta(y_t|x,y_1,y_2,...,y_{t-1})=\sum_{t=1}^n\log p_\theta(y_t|x,y_1,y_2,...,y_{t-1})</script><em>Note that $y$ is a token sequence here. $y_i$ is the $i^{th}$ token.</em><h2 id="The-Loss-to-Optimize"><a href="#The-Loss-to-Optimize" class="headerlink" title="The Loss to Optimize"></a>The Loss to Optimize</h2>We can have a reward model to evaluate the satisfying score of a pair of $x,y$ which can be represented as $RM(x,y)$. Use this model to help the original model to optimize.<br>But in the pattern of DPO, during the calculation, we can cancel out all the $RM(x,y)$.<br>For a $x$ and its $y$s, we can take out all pairs $y^w$ and $y^l$ that $y^w$ is more satisfying than $y^l$ for humans<br>Then we can have the DPO Loss<script type="math/tex; mode=display">J_{DPO}(\theta)=-E_{(x,y^w,y^l)\sim D}[\log\sigma(RM_\theta(x,y^w)-RM_\theta(x,y^l))]</script>in which, $E<em>{(x,y^w,y^l)\sim D}$ means sampling and out all pairs of demanding $y^w,y^l$ in dataset add up the calculating result.<br>$RM</em>\theta(x,y)$ is the division of original model’s(right after finetuning) predicted possibility to current-step model’s(the model updates its parameters every gradient step) predicted possibility. <em>So we need to remain a copy of the original model.</em><script type="math/tex; mode=display">RM_\theta=\beta\log\frac{p_\theta^{RL}(y|x)}{p^{PT}(y|x)}</script>$\beta$ is the <strong>Temperature Coefficient</strong>, a hyper-parameter scalar.<br>$p_\theta^{RL}$ is the current model prediction(after some turns of parameter update).<br>$p^{PT}$ is the original model prediction(right after the finetuning process).<br>Using this form of division can prevent the model goes too far away from the finetuned version, generating unexpected answers.</li></ul>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
            <tag> DPO </tag>
            
            <tag> 模型微调 </tag>
            
            <tag> Prompting </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>预训练</title>
      <link href="/posts/b1811702.html"/>
      <url>/posts/b1811702.html</url>
      
        <content type="html"><![CDATA[<h1 id="Subword"><a href="#Subword" class="headerlink" title="Subword"></a>Subword</h1><p>A trained embedding can’t cover every word in human language(humans are keeping generating new words, and there misspelling of human).<br>If we keep signing this words with <code>&lt;Unk&gt;</code>(unknown) token, then great amount of information will be missed.</p><h2 id="Byte-pair-Encode-Algorithm"><a href="#Byte-pair-Encode-Algorithm" class="headerlink" title="Byte-pair Encode Algorithm"></a>Byte-pair Encode Algorithm</h2><p>Then, we can generate some subword tokens according to the appearing frequency in the corpus of specific character combinations.<br>In detail, we do</p><ol><li>Separate the whole text into smallest units(usually one character). Each adding a special sign(e.g. <code>&lt;/w&gt;</code>) to stand for the end of the word.</li><li>Count the appearing frequency of all the adjacent characters. Use most common adjacent characters to form a subword.(e.g. <code>s,u,b</code> are usually appearing together so we add <code>sub</code> as a new subword)</li><li>Replace instances of the character pair with the new subword; repeat until desired vocab size.<br>Below is the process of forming subword <code>est</code> as an example<br><img src="/img/CS224n/截屏2025-10-31 21.30.46.png" alt=""><h1 id="Inspiration-of-Pretraining"><a href="#Inspiration-of-Pretraining" class="headerlink" title="Inspiration of Pretraining"></a>Inspiration of Pretraining</h1><h2 id="The-Concept-of-Pretraining"><a href="#The-Concept-of-Pretraining" class="headerlink" title="The Concept of Pretraining"></a>The Concept of Pretraining</h2>Before, we train our word embeddings first.<br>Then, the vector of each token is fixed through the whole training process.<br><img src="/img/CS224n/截屏2025-10-31 21.33.02.png" alt=""><br>Instead, we can train the whole model parameters.<br>To elaborate, we can train the word embeddings and neural layers jointly.<br>This process is called <strong>Pretraining</strong>.<br><img src="/img/CS224n/截屏2025-10-31 21.36.14.png" alt=""><br>The model can’t be used after pretraining.<br>It’s just a method of initializing the parameters of the model to lay the foundation for the latter training(may be a profile of human language or knowledge of some basic human syntax).<h2 id="The-Pretraining-finetuning-Process"><a href="#The-Pretraining-finetuning-Process" class="headerlink" title="The Pretraining-finetuning Process"></a>The Pretraining-finetuning Process</h2>After the initializing process called pretraining, we can do <strong>Finetuning</strong> to the model, which makes the model be able to handle some task of more specific areas and functions.<br>Starting from the outcome $\hat{\theta}$ of pretraining, we finetune process can go better</li></ol><ul><li>Maybe the finetuning local minima near $\hat{\theta}$ tend to generalize well!</li><li>Maybe the gradients of finetuning loss near $\hat{\theta}$ propagate nicely(less explosion or vanishment)!<br><img src="/img/CS224n/截屏2025-10-31 21.46.48.png" alt=""><br>Pretraining costs a lot. But the outcome of the pretraining can be used(finetuned) many times.<br>Finetuning costs far less. It’s common to run finetuning on a single GPU.<h1 id="Pretraining-for-Encoder"><a href="#Pretraining-for-Encoder" class="headerlink" title="Pretraining for Encoder"></a>Pretraining for Encoder</h1>The core method of pretraining encoders is randomly mask some tokens in the source sentence and let the model to predict what masked token is.<h2 id="Bidirectional-Encoder-Representations-from-Transformers-BERT"><a href="#Bidirectional-Encoder-Representations-from-Transformers-BERT" class="headerlink" title="Bidirectional Encoder Representations from Transformers(BERT)"></a>Bidirectional Encoder Representations from Transformers(BERT)</h2>The process is called “Masked LM”.<br>We randomly choose 15% tokens in the source sentence. To the chosen tokens</li><li>Replace 80% of them with a special <code>&lt;Mask&gt;</code> token.</li><li>Replace 10% of them with another randomly chosen token.</li><li>Else 10% we don’t change them as input,but the model still needs to predict them as its output.<br><img src="/img/CS224n/截屏2025-10-31 22.13.06.png" alt=""><br>This teaches the model to make use of context tokens, and find some rules of human language.<h2 id="SpanBERT"><a href="#SpanBERT" class="headerlink" title="SpanBERT"></a>SpanBERT</h2>The hidden tokens are randomly chosen for the BERT above.<br>In SpanBERT, we tend to choose adjacent tokens to do some masking.<br>This teaches the model to make use farther and longer contexts, and understand the text structure.<h1 id="Pretraining-for-Encoder-decoder"><a href="#Pretraining-for-Encoder-decoder" class="headerlink" title="Pretraining for Encoder-decoder"></a>Pretraining for Encoder-decoder</h1>The classical process is divide the source sentence into two parts.</li><li>Prefix: need to feed into the encoder part with no mask operations.</li><li>Target: the task for decoder to predict, and based on the prediction to do back-propagation.<br><img src="/img/CS224n/截屏2025-10-31 23.46.08.png" alt=""><br>Another method used the mask.<br><img src="/img/CS224n/截屏2025-11-01 00.21.04.png" alt=""><br>As the picture shows, we mask some tokens and predict the other tokens.<h1 id="Pretraining-for-Decoder"><a href="#Pretraining-for-Decoder" class="headerlink" title="Pretraining for Decoder"></a>Pretraining for Decoder</h1><em>The Generative Pretrained Transformer(GPT) is a pure Decoder model.</em><h2 id="Target-Output-as-a-Sequence"><a href="#Target-Output-as-a-Sequence" class="headerlink" title="Target Output as a Sequence"></a>Target Output as a Sequence</h2>The precess must be done recurrently.<br><img src="/img/CS224n/截屏2025-11-01 00.48.21.png" alt=""><br>Forward propagation with known tokens <script type="math/tex">w_1,w_2,......,w_t</script>, and generate a hidden layer <script type="math/tex">h_t</script>.<br>Do linear and maybe softmax to <script type="math/tex">h_t</script>, work out the loss and back propagation.<br><img src="/img/CS224n/截屏2025-11-01 00.49.11.png" alt=""><br>Pass the right $w_{t+1}$ to continue training.<h2 id="Other-Downstream-Tasks"><a href="#Other-Downstream-Tasks" class="headerlink" title="Other Downstream Tasks"></a>Other Downstream Tasks</h2>Just recurrently go through all the given tokens, generating a sequence of hidden layers.<br><img src="/img/CS224n/截屏2025-11-01 00.50.39.png" alt=""><br>Use the last hidden layer only.<br>Do linear and softmax to it, and use it to predict some target labels such as the emotion(positive/ negative) of the sentence.<br>The $A$ and $b$ here to do linear are randomly and normally generated.<br><img src="/img/CS224n/截屏2025-11-01 00.53.19.png" alt=""><br>Basing on this, back propagate through the whole network.</li></ul>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 词嵌入 </tag>
            
            <tag> BERT </tag>
            
            <tag> LLM </tag>
            
            <tag> Transformers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transformers</title>
      <link href="/posts/ab3e853d.html"/>
      <url>/posts/ab3e853d.html</url>
      
        <content type="html"><![CDATA[<p>For RNNs, it’s difficult to handle word that are far from each other but have dependencies.<br>Moreover, GPUs work well in doing parallelizable tasks such as matrix multiplication. For recurrent jobs, GPUs can’t work well.<br><strong>Transformers</strong> can take advantages of parallel computing of GPUs.<br>Time cost for transformers is $O(dn^2)$ while for RNN is $O(d^2n)$.<br>In which, $d$ is the dimension of word vectors and $n$ is the sequence length.</p><h1 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h1><h2 id="Similarity-with-RNN’s-Attention"><a href="#Similarity-with-RNN’s-Attention" class="headerlink" title="Similarity with RNN’s Attention"></a>Similarity with RNN’s Attention</h2><p>Recall the Attention process in <a href="/posts/ade63eae.html" title="RNN进阶">RNN进阶</a><br>The whole process of <strong>Query</strong>-<strong>Key</strong>-<strong>Value</strong>.</p><script type="math/tex; mode=display">e_i=s_t^T(U^TV)h_i=(Us_t)^T(Vh_i)</script><p>To the processing token $s_t$, we map it with $U$, and get a query vector of $s_t$.<br>Then mapping $h_i$ with $V$ is the process of get the key.<br>Multiply query vector and key vector, we get the weight for each value.</p><script type="math/tex; mode=display">\alpha^t=softmax(e^t)</script><script type="math/tex; mode=display">a_t=\sum_{i=1}^N\alpha_i^tv_i</script><h2 id="Q-K-V-for-Transformers"><a href="#Q-K-V-for-Transformers" class="headerlink" title="Q-K-V for Transformers"></a>Q-K-V for Transformers</h2><p>Let $w_{1:n}$ be a sequence of words in corpus $V$.<br>$E$ is the whole word Embeddings $d\times |V|$.<br>For each word $w_i$, we have its word vector $x_i(d\times 1)=Ew_i$.<br>Then, we have three mapping matrices $Q,K,V$, which are all $d\times d$.<br>For every word in the sentence $w_i$, we take the mapping</p><script type="math/tex; mode=display">q_i=Qx_i</script><script type="math/tex; mode=display">k_i=Kx_i</script><script type="math/tex; mode=display">v_i=Vx_i</script><p>Then, we can build a attention distribution from any one word $i$ to all words in the sentence.</p><script type="math/tex; mode=display">e_{ij}=q_i^Tk_j</script><p>Use softmax to map the results to a distribution</p><script type="math/tex; mode=display">a_{ij}=\frac{\exp(e_{ij})}{\sum_{j^{'}}\exp(e_{ij^{'}})}</script><p>Do a weighted sum of output softmax</p><script type="math/tex; mode=display">o_i=\sum_ja_{ij}v_j</script><h2 id="Vectorization"><a href="#Vectorization" class="headerlink" title="Vectorization"></a>Vectorization</h2><p>The math process can be vectorized.<br>Let $X=[x_1;x_2;……;x_n]$ which is a $n\times d$ matrix that holds the all word embeddings.<br>The same with before, we have $Q,K,V\in R^{d\times d}$.<br>So we have $XQ,XK,XV\in R^{n\times d}$.<br>Then we can work out the output $o$ of this Q-K-V layer directly.</p><script type="math/tex; mode=display">o=softmax(XQ(XK)^T)XV</script><p>It’s really fast for GPUs.</p><h2 id="Piling-Up-for-more-Layers"><a href="#Piling-Up-for-more-Layers" class="headerlink" title="Piling Up for more Layers"></a>Piling Up for more Layers</h2><p>A layer of QKV takes in a sequence of word vectors and outputs a same-length sequence of word vectors.<br>Only one layer can’t work the best. We can use more layers of QKV self-attention.<br>But in fact, there are no element-wise nonlinearities so far. In math, stacking more such layers are just re-averaging the <strong>value vectors</strong>.<br>The solution is to add a <strong>Feed-forward Network</strong> to post-process each output vector.</p><script type="math/tex; mode=display">m_i=MLP(o_i)=W_2ReLU(W_1o_i+b_1)+b_2</script><p>So the big picture looks like<br><img src="/img/CS224n/截屏2025-10-27 23.33.03.png" alt=""><br>We can call a layer of attention(including Q-K-V and Feed-forward Network) a Transformer <strong>Building Block</strong>.</p><h1 id="Sequence-Order"><a href="#Sequence-Order" class="headerlink" title="Sequence Order"></a>Sequence Order</h1><p>In math, in the process of Q-K-V, every word is dealt with equally.<br>In another word, no matter in what order the original sequence is, the outputs are all the same.</p><h2 id="Sequence-Index-Vector"><a href="#Sequence-Index-Vector" class="headerlink" title="Sequence Index Vector"></a>Sequence Index Vector</h2><p>We need to give the model a notation of sequence.<br>To trade off, we have to fix the max length of the input sequence to $n$, and pad the rest places with default vectors.<br>We initialize $n$ $d\times 1$ vectors $p_i$ for $i\in \begin{Bmatrix}1,2,……,n\end{Bmatrix}$.<br>For the input word vector $x_i$ in index $i$, we add the $p_i$.</p><script type="math/tex; mode=display">\tilde x_i=x_i+p_i</script><p>Pass the modified vector $\tilde x$ to the self-attention layer.<br>We can learn all the $p_i$ while training.<br>Then, each $p_i$ is a distinct sign for every index, which can be used to represent the sequence order.</p><h2 id="Rotary-Position-Embedding-RoPE"><a href="#Rotary-Position-Embedding-RoPE" class="headerlink" title="Rotary Position Embedding(RoPE)"></a>Rotary Position Embedding(RoPE)</h2><h3 id="2-d-Vector-Rotation"><a href="#2-d-Vector-Rotation" class="headerlink" title="2-d Vector Rotation"></a>2-d Vector Rotation</h3><p>To a 2-d vector $v=(a,b)$, we have its complex $c_v=a+bi$.<br>Then $e^{i\theta}c_v$ is the complex of the vector that is the $v$ rotated by angle $\theta$.<br>The process can also be replaced by a matrix multiplication(a $2\times 2$ matrix multiplies a $2\times 1$ vector).<br>If two 2-d vectors are rotated by a same angle $\theta$, their inner product doesn’t change.<br>If $v_1$ is rotated $\theta_1$ and $v_2$ rotated $\theta_2$, the only value that influences the their inner product  is $\theta_1-\theta_2$.</p><h3 id="Rotation-of-High-dimension-Vectors-for-Transformers"><a href="#Rotation-of-High-dimension-Vectors-for-Transformers" class="headerlink" title="Rotation of High-dimension Vectors for Transformers"></a>Rotation of High-dimension Vectors for Transformers</h3><p><img src="/img/CS224n/截屏2025-10-28 09.52.06.png" alt=""><br>Break the $d$-dimension vector into $d/2$ $2$-dimension vectors.<br>For each $2$-dimension vector, do rotation respectively.<br>Then concatenate all the results back to a $d$-dimension vector.<br>This process can also be vectorized.</p><h3 id="Rotate-for-Sequence"><a href="#Rotate-for-Sequence" class="headerlink" title="Rotate for Sequence"></a>Rotate for Sequence</h3><p>For every $q_i$ and $k_i$, we rotate them with a angle $\theta_i = mi$, in which $m$ is a constant, and $i$ is the index of their token in the original sentence.<br>So, the sequence order of the input sentence is perfectly described.<br>Note that what matters in this process is the distance of two words in the sentence(<strong>Relative Position</strong>) instead of the <strong>Absolute Position</strong> of each word.</p><h1 id="Masking"><a href="#Masking" class="headerlink" title="Masking"></a>Masking</h1><p>To use self-attention in decoders, the model should not know the future while predicting next words.<br>We only take out the already generated words to Query.<br>While dealing with future words, we mask them by setting the attention score to $-\infty$.</p><script type="math/tex; mode=display">e_{ij}=\begin{cases}q_i^Tk_j,j\leq i\\-\infty,j>i\end{cases}</script><p><img src="/img/CS224n/截屏2025-10-28 10.25.58.png" alt=""><br>Also, instead of setting $-\infty$ scores, we can pad some <code>&lt;EMPTY&gt;</code> tokens to the blank that haven’t been generated yet.</p><h1 id="Multi-head-Self-attention"><a href="#Multi-head-Self-attention" class="headerlink" title="Multi-head Self-attention"></a>Multi-head Self-attention</h1><h2 id="Independent-Q-K-V-s"><a href="#Independent-Q-K-V-s" class="headerlink" title="Independent $Q,K,V$s"></a>Independent $Q,K,V$s</h2><p>In self-attention, we only have a group of $Q,K,V$.<br>The Multi-head Self-attention introduces several groups of $Q_l,K_l,V_l$s.<br>Each group extract information from the input features independently(some catches syntax and some catches dependency for example).</p><h2 id="Implement"><a href="#Implement" class="headerlink" title="Implement"></a>Implement</h2><p>For word vectors with dimension $d$, and $h$ heads, we let</p><script type="math/tex; mode=display">Q_l,K_l,V_l\in R^{d\times \frac{d}{h}}</script><p>in which $l$ ranges from $1$ to $h$.<br>Each attention has head performs attention and give output independently</p><script type="math/tex; mode=display">o_i=softmax(XQ_l(XK_l)^T)XV_l</script><p>$XQ_l,XK_l,XV_l$ are all $n\times \frac{d}{h}$.<br>So it is $n\times n$ in the softmax.<br>Note that softmax always do the mapping along the last axis. For this matrix, it takes each row in the matrix as input and outputs a mapped row.<br>$o_i$ is $n\times \frac{d}{h}$.<br>Concatenate all $o_i$ for $i\in\begin{Bmatrix}1,2,……,h\end{Bmatrix}$, we get an output $n\times d$ vector. Them objective with a $d\times d$ matrix $Y$(can help integrate outcomes from different heads).</p><script type="math/tex; mode=display">o=[o_1,o_2,......,o_h]Y\in R^{n\times d}</script><h2 id="Vectorization-1"><a href="#Vectorization-1" class="headerlink" title="Vectorization"></a>Vectorization</h2><p>Take $Q$ as an example.<br>First, concatenate all $Q_l$ to form a $d\times d$ matrix $Q$.<br>Compute $XQ$, which is $n\times d$.<br>Break the second dimension down to 2 new dimensions, then the shape goes to $n\times h\times\frac{d}{h}$.<br>Transpose the tensor to $h\times n\times\frac{d}{h}$.<br>The $h$ is the “Heads” axis(piles up the matrices of each heads).<br>Do the same operations to $K$ and $V$.<br><img src="/img/CS224n/截屏2025-10-28 11.43.06.png" alt=""><br>The whole expression is still</p><script type="math/tex; mode=display">o=softmax(XQ(XK)^T)XVY</script><p>Now, $XQ$ is $h\times n\times\frac{d}{h}$. $(XK)^T$ is $h\times\frac{d}{h}\times n$.<br>$XQ(XK)^T$ is $h\times n\times n$.<br>Still, softmax is done to the last dimension.<br><em>View the tensor $XQ(XK)^T$ as a $h$-floor building. On each floor there is a distinct matrix. The softmax is done to each row in each floor.</em><br>Then we multiply it with $XV$ which is also $h\times n\times\frac{d}{h}$.<br>The output is a $h\times n\times\frac{d}{h}$ tensor.<br>Then, pile the first and third dimension up(just like the building fall horizontally) and form a $n\times d$ matrix.<br>Multiply it with $Y$ to get the outcome of this layer.<br><em>The $Y$ are all optional.</em></p><h2 id="Scaled-Dot-Product"><a href="#Scaled-Dot-Product" class="headerlink" title="Scaled Dot Product"></a>Scaled Dot Product</h2><p>As $d$ becomes larger, dot products between vectors tend to become large.<br>We should rescale it in each attention layer.<br>So, the update version of attention layer is</p><script type="math/tex; mode=display">o=softmax(\frac{XQ(XK)^T}{\sqrt{d/h}})XVY</script><h1 id="Transformer-Architecture"><a href="#Transformer-Architecture" class="headerlink" title="Transformer Architecture"></a>Transformer Architecture</h1><h2 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h2><p>The basic architecture is after several building blocks, we connect to Linear Layer and Softmax Layer to get some outputs.<br><img src="/img/CS224n/截屏2025-10-28 18.15.48.png" alt=""></p><h2 id="Residual-Connection"><a href="#Residual-Connection" class="headerlink" title="Residual Connection"></a>Residual Connection</h2><p>Before and After a Layer, we have $X^{(i-1)}$ and $X^{(i)}$, we have<br><img src="/img/CS224n/截屏2025-10-28 18.49.39.png" alt=""></p><script type="math/tex; mode=display">X^{(i)}=Layer(X^{(i-1)})</script><p>The additional Residual Connection links directly $X^{(i-1)}$ and $X^{(i)}$. Which makes training more smooth.<br><img src="/img/CS224n/截屏2025-10-28 18.52.18.png" alt=""></p><script type="math/tex; mode=display">X^{(i)}=Layer(X^{(i-1)})+X^{(i-1)}</script><p><img src="/img/CS224n/截屏2025-10-28 18.55.02.png" alt=""><br>With some residual connections, we are more likely to find the global optimize by gradient descent.<br><img src="/img/CS224n/截屏2025-10-28 18.54.08.png" alt=""></p><h2 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h2><p>After each layer, some word vectors may be larger in scale than other vector.<br>Then, we should do a independent normalization for each word.<br>For each word’s vector $x\in R^d$.<br>Let the mean</p><script type="math/tex; mode=display">\mu=\frac{1}{d}\sum_{i=1}^dx_i</script><p>and the standard deviation</p><script type="math/tex; mode=display">\sigma=\sqrt{\frac{1}{d}\sum_{i=1}^d(x_i-\mu)^2}</script><p>Then, we standardize the initial $x$ and use $\gamma,\beta\in R^d$ to map it.</p><script type="math/tex; mode=display">o_x=\frac{x-\mu}{\sqrt{\sigma}+\epsilon}\odot\gamma+\beta</script><p>in which, $\epsilon$ is a small scalar to prevent against divide zero problem.</p><h2 id="Encoder-and-Decoder"><a href="#Encoder-and-Decoder" class="headerlink" title="Encoder and Decoder"></a>Encoder and Decoder</h2><p>The encoder needs no mask. It needs to generate features based on whole inputs.<br><img src="/img/CS224n/截屏2025-10-28 19.40.55.png" alt=""><br>The decoder needs mask.<br><img src="/img/CS224n/截屏2025-10-28 19.36.37.png" alt=""></p><h2 id="Cross-attention"><a href="#Cross-attention" class="headerlink" title="Cross-attention"></a>Cross-attention</h2><p><img src="/img/CS224n/截屏2025-10-28 19.47.08.png" alt=""><br>Suppose in the current state, the decoder has generated $t$ tokens $z_1,z_2,……,z_t$. We concatenate these $d$-dimensional vectors to generate a whole matrix $Z=[z_1;z_2;……,z_t]\in R^{t\times d}$.<br>The encoder has $T$ tokens $h_1,h_2,……,h_T$. We concatenate these $d$-dimensional vectors to generate a whole matrix $H=[h_1;h_2;……;h_T]\in R^{T\times d}$.<br>Now, we use $Z$ to Query, and use $H$ to Key and Value.<br>First, we calculate $ZQ$, which is $t\times d$.<br>Then, calculate $HK$ which is $T\times d$.<br>Multiply $ZQ(HK)^T$, which is $t\times T$. Each row refers to the all attention scores in terms of each $z_i$. This indicates which input token should each output(docoder-generated) token should focus more in.<br>Do softmax to each row to get the attention distribution, multiply the result matrix with $HV$ and get the output.<br>The whole process is described as</p><script type="math/tex; mode=display">o=softmax(ZQ(HK)^T)HV</script><p>Sometimes, we can pad some tokens to make the number of decoder features from $t$ tokens to $T$ tokens which is the same as encoder(like masking).</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 注意力机制 </tag>
            
            <tag> Seq2seq </tag>
            
            <tag> 维度分析 </tag>
            
            <tag> Transformers </tag>
            
            <tag> RoPE </tag>
            
            <tag> 残差 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN进阶</title>
      <link href="/posts/ade63eae.html"/>
      <url>/posts/ade63eae.html</url>
      
        <content type="html"><![CDATA[<h1 id="Long-Short-Term-Memory-RNNs"><a href="#Long-Short-Term-Memory-RNNs" class="headerlink" title="Long Short-Term Memory RNNs"></a>Long Short-Term Memory RNNs</h1><p><strong>LSTM</strong> introduces some gates into the model.<br><img src="/img/CS224n/截屏2025-10-24 23.03.38.png" alt=""><br>Cell content is the container vector to store long-term memories.<br>The sigmoids in the forget gate, input gate and output gate are used to turn switch on($1$) or off($0$), in order decide which value in the coming vector remains and which discards.<br>For example, if the model judges that a certain dimension of $c^{(t-1)}$ should be forgotten, then the same dimension in $f^{(t)}$ should be nearly $0$. Then after element-wise product, the output in this dimension is nearly $0$.<br>So, the three gates serve as masks, filter datas according to which value should be passed down and which should be blocked.<br>The data flow in one layer can be shown in a graph.<br><img src="/img/CS224n/截屏2025-10-24 23.16.44.png" alt=""><br>Vanilla RNN has memory almost no more than 7 layers. But LSTM can enhance that value to about 100 layers.</p><h1 id="Usages-of-RNN"><a href="#Usages-of-RNN" class="headerlink" title="Usages of RNN"></a>Usages of RNN</h1><p>RNNs are sophisticated in processing sequences.<br>Some usages of RNN are all based on its capability on sequence processing tasks.</p><h2 id="Sequence-Tagging"><a href="#Sequence-Tagging" class="headerlink" title="Sequence Tagging"></a>Sequence Tagging</h2><p>For example, we can sign Part-of-speech for every word in a sentence.<br><img src="/img/CS224n/截屏2025-10-24 23.29.56.png" alt=""></p><h2 id="Sentence-Encoder-Model"><a href="#Sentence-Encoder-Model" class="headerlink" title="Sentence Encoder Model"></a>Sentence Encoder Model</h2><p>We can use RNN to verdict whether the sentence is positive or negative.<br><img src="/img/CS224n/截屏2025-10-24 23.31.43.png" alt=""></p><h1 id="Bidirectional-RNN"><a href="#Bidirectional-RNN" class="headerlink" title="Bidirectional RNN"></a>Bidirectional RNN</h1><h2 id="Implement"><a href="#Implement" class="headerlink" title="Implement"></a>Implement</h2><p>The RNN shown above only processes the sentence in one direction. This is only how humans accept information.<br>Moreover, this method only makes use of contexts from only one side.<br>We can reversely process the sequence and generate another sequence of vectors(a vector represents a hidden layer here).<br>Then, concatenate two vectors and gain a more comprehensive vector.<br><img src="/img/CS224n/截屏2025-10-24 23.37.48.png" alt=""></p><h2 id="Occasions-to-Use"><a href="#Occasions-to-Use" class="headerlink" title="Occasions to Use"></a>Occasions to Use</h2><p>Bidirectional RNN should be applied by default when the model can already know the whole sequence.<br>But when it comes to language models, this is of no use.</p><h1 id="Multi-layer-RNN"><a href="#Multi-layer-RNN" class="headerlink" title="Multi-layer RNN"></a>Multi-layer RNN</h1><p>The implement of Multi-layer RNN is shown below.<br><img src="/img/CS224n/截屏2025-10-24 23.47.42.png" alt=""><br>Often 2-layers is a lot better than 1-layer RNN, while 3-layers RNN might be only a little better than 2-layers RNN.<br>Usually, skip-connections/dense-connections are needed to train deeper RNNs(e.g., 8 layers).</p><h1 id="Neural-Machine-Translation"><a href="#Neural-Machine-Translation" class="headerlink" title="Neural Machine Translation"></a>Neural Machine Translation</h1><h2 id="Seq2seq-Model"><a href="#Seq2seq-Model" class="headerlink" title="Seq2seq Model"></a>Seq2seq Model</h2><p>Neural Machine Translation(NMT) is a way to do <strong>Machine Translation</strong> in a single end-to-end neural network.<br>The neural network architecture is called a sequence-to-sequence model(a.k.a seq2seq) and it involves two RNNs: <strong>Encoder RNN</strong> and <strong>Decoder RNN</strong>.<br><img src="/img/CS224n/截屏2025-10-24 23.54.37.png" alt=""></p><h2 id="Predicting"><a href="#Predicting" class="headerlink" title="Predicting"></a>Predicting</h2><p>First, go through the Encoder RNN and get the hidden layer(vector) of the last token.<br>Then, use this vector as the initial input layer of the Decoder RNN. Use this RNN to predict the translated texts step by step(<code>hidden layers-&gt;linear-&gt;softmax-&gt;choose the word-&gt;pass its embedding to next layer</code>).</p><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>To train the two RNNs, we should prepare a parallel dataset.<br>For example, enough Chinese-English parallel texts, in which a English sentence and a Chinese sentence with the same meaning as a pair.<br><img src="/img/CS224n/截屏2025-10-25 00.57.47.png" alt=""><br>The concept of multi-layer can also be applied here.<br><img src="/img/CS224n/截屏2025-10-25 00.58.30.png" alt=""></p><h1 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h1><p>Seq2seq described above can only use features in the last layer in the Encoder RNN. But usually, hidden features in last layer can’t completely cover the message from previous layers.<br><strong>Attention</strong> is a method to process some previous layers of the Encoder RNN. Just like a human translator, he won’t focus on the last word of the sentence. Instead, he’ll skip from one word to any another word while translating.<br>Attention builds shortcuts to faraway layers, which is helpful to handle gradient vanishing problem.</p><h2 id="Basic-Implement"><a href="#Basic-Implement" class="headerlink" title="Basic Implement"></a>Basic Implement</h2><p><img src="/img/CS224n/截屏2025-10-26 12.09.22.png" alt=""><br>Given the Decoder RNN’s hidden layers and Encoder RNN’s hidden layers are same-dimensional vectors.<br>Suppose the encoder RNN has $N$ layers, each is a $h$-dimensional vector. They are $h_1,h_2,h_3,……,h_N$. When it comes to the $t$ layer of decoder RNN, suppose the hidden layer is a $h$-dimensional vector $s_t$.<br>Then, we can work out the attention score for each layer of every input tokens(a token refers to a layer in encoder RNN) in respect to $s_t$.</p><script type="math/tex; mode=display">e^t=[s_t^Th_1,s_t^Th_2,......,s_t^Th_N]=s_t^T[h_1,h_2,......,h_N]</script><p>We have $e^t\in R^N$. Then we can map it with softmax to form Attention Distribution.</p><script type="math/tex; mode=display">\alpha^t=softmax(e^t)</script><p>$\alpha^t$ is the weight for layers in encoder layer. It interprets how much attention should the model pay to each layer.<br>We can then based on this work out the additional $h\times 1$ input vector for the current layer in decoder RNN.</p><script type="math/tex; mode=display">a_t=\sum_{i=1}^N\alpha_i^th_i</script><p>Then we can concatenate it with the original $s_t$.</p><script type="math/tex; mode=display">\begin{bmatrix}a_t\\s_t\end{bmatrix}\in R^{2h}</script><p>Use this to predict and pass to next layer.</p><h2 id="Multiplicative-Attention"><a href="#Multiplicative-Attention" class="headerlink" title="Multiplicative Attention"></a>Multiplicative Attention</h2><p>Sometimes just use $e_i=s_t^Th_i$ can’t fully represent the attention score. And it forces the $s_t$ and $h_i$ has same dimension.<br>We can use a mid matrix $W$.<br>If $s_t$ is $d_1\times 1$, $h_i$ is $d_2\times 1$. Then, $W$ is $d_1\times d_2$.<br>This time, we have</p><script type="math/tex; mode=display">e_i=s_t^TWh_i</script><p>This method is called <strong>Multiplicative Attention</strong> or <strong>Bilinear Attention</strong>.<br>However, hidden layers are large. So the $W$ could be large. Then, many multiplications will be involved in only one layer. So, there’s Reduced-rank Multiplicative Attention below.</p><h2 id="Reduced-rank-Multiplicative-Attention"><a href="#Reduced-rank-Multiplicative-Attention" class="headerlink" title="Reduced-rank Multiplicative Attention"></a>Reduced-rank Multiplicative Attention</h2><p>We can decompress $W$ to two low rank matrices.</p><script type="math/tex; mode=display">W = U^TV</script><p>In which, $U$ is $k\times d_1$, $V$ is $k\times d_2$.<br>$k$ is far more smaller than $d_1$ and $d_2$, to ensure that both $U$ and $V$ are low-rank matrices, which contains far less parameters.<br>Then we have</p><script type="math/tex; mode=display">e_i=s_t^T(U^TV)h_i=(Us_t)^T(Vh_i)</script><p>Calculating in this order(after the second $=$ in expression above) can save much time.</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> LSTM </tag>
            
            <tag> 注意力机制 </tag>
            
            <tag> 梯度 </tag>
            
            <tag> 反向传播 </tag>
            
            <tag> Seq2seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN</title>
      <link href="/posts/6fe72dd0.html"/>
      <url>/posts/6fe72dd0.html</url>
      
        <content type="html"><![CDATA[<h1 id="Language-Modeling"><a href="#Language-Modeling" class="headerlink" title="Language Modeling"></a>Language Modeling</h1><p>The task of a language model is to predict the next word given the formal several context words.<br>For example, when typing some words in a keyboard, the phone will predict some potential next words.<br><strong>Recurrent Neural Network(RNN)</strong> is a common tool to build a language model.</p><h1 id="Brief-Structure-of-RNN"><a href="#Brief-Structure-of-RNN" class="headerlink" title="Brief Structure of RNN"></a>Brief Structure of RNN</h1><p><img src="/img/CS224n/截屏2025-10-23 01.08.40.png" alt=""><br>A sentence is actually a sequence of words.<br>RNN can take in previous words and predict the upcoming words.</p><h1 id="Generating-Words"><a href="#Generating-Words" class="headerlink" title="Generating Words"></a>Generating Words</h1><h2 id="Viewing-the-Context"><a href="#Viewing-the-Context" class="headerlink" title="Viewing the Context"></a>Viewing the Context</h2><p>Look up the embedding of each word in the sequence.<br>Initialize the hidden layer $h^{(0)}$.<br>From the beginning of the first known tokens, recurrently do a fixed calculation.<br>For the $i^{th}$ word $x^{(i)}$, look up for its word vector $e^{(i)}$. Then, multiply it with a fixed Matrix $W_e$.<br>Multiply the previous hidden layer $h^{(i-1)}$ with a fixed Matrix $W_h$.<br>Then, sum them up and add a bias $b_1$.<br><em>$W_e,W_h,b_1$ are fixed parameters in the model.</em></p><script type="math/tex; mode=display">z^{(i)}=W_hh^{(i-1)}+W_ee^{(i)}+b_1</script><p>Then, to get the hidden layer of state $i$, we activate with a non-linear function $\sigma$.<br>Note that the activate function here is <strong>tanh</strong> instead of sigmoid. Briefly, sigmoid is always mapping values to positive, which will cause the values in hidden layers accumulatively become larger as the model propagates. <strong>tanh</strong> is fair for both positive and negative values.</p><script type="math/tex; mode=display">h^{(i)}=\sigma(z^{(i)})</script><h2 id="Predicting"><a href="#Predicting" class="headerlink" title="Predicting"></a>Predicting</h2><p>After processing the last known word, we can begin predicting.<br>First, linear the last hidden layer to a $|V|\times 1$ vector, in which $|V|$ is the size of the whole corpus(the number of tokens in the corpus).</p><script type="math/tex; mode=display">Z^{(t)}=Uh^{(t)}+b_2</script><p>Activate $Z^{(t)}$ with a softmax. Use the largest value’s index to do predict the next word.</p><script type="math/tex; mode=display">\hat{y}^{(t)}=softmax(Z)</script><p>Then, use the predicted word’s embedding $e^{(t+1)}$ as input for next roll’s prediction.</p><h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><h2 id="Loss-Function-for-One-Step"><a href="#Loss-Function-for-One-Step" class="headerlink" title="Loss Function for One Step"></a>Loss Function for One Step</h2><p>For single step $t$, the Loss Function is a Cross Entropy Loss.</p><script type="math/tex; mode=display">J^{(t)}(\theta)=CE(y^{(t)},\hat y^{(t)})=-\sum_{w\in V}y_w^{(t)}\log\hat y_w^{(t)}=-\log\hat y_{x_{t+1}}^{(t)}</script><h2 id="Loss-Function-for-a-sequence"><a href="#Loss-Function-for-a-sequence" class="headerlink" title="Loss Function for a sequence"></a>Loss Function for a sequence</h2><p>Suppose the length of a sequence is $T$.<br>Then, the loss of the sequence is the average of the loss of all steps.</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{T}\sum_{t=1}^TJ^{(t)}(\theta)=\frac{1}{T}\sum_{t=1}^T-\log\hat y_{x_{t+1}}^{(t)}</script><h2 id="Back-Propagation-Through-Time"><a href="#Back-Propagation-Through-Time" class="headerlink" title="Back Propagation Through Time"></a>Back Propagation Through Time</h2><p><img src="/img/CS224n/截屏2025-10-23 20.57.19.png" alt=""><br>RNN uses same parameters to forward propagate. So we take derivatives to same Parameters each step.<br>Take $W_h$ as an example.</p><script type="math/tex; mode=display">\frac{\partial J^{(t)}}{\partial W_h}=\sum_{i=1}^t\frac{\partial J^{(t)}}{\partial W_h}\bigg|_{(i)}</script><p>It’s in the form of sum because $J^{(t)}$ is influenced by $h^{(t)}$, and $h^{(t)}$ has relationship with $h^{(1)},h^{(2)},h^{(3)},……,h^{(t-1)}$.<br>While training, the workload to calculate the gradient rockets up in exponential scale.<br>So we need to truncate the derivatives(use a pseudo derivative for latter layers) and update the parameters of the model after a fixed number of steps.</p><h2 id="Batching"><a href="#Batching" class="headerlink" title="Batching"></a>Batching</h2><p>Scanning through the whole corpus takes up a lot of time. We can use batches to do it faster.<br>Naturally, we use a sentence or a fixed number of sentences to do batch training.<br>Compute loss for a batch(or a truncate point), compute gradients and update weights. Repeat on a new batch of sentences.</p><h1 id="Attributes-of-RNN"><a href="#Attributes-of-RNN" class="headerlink" title="Attributes of RNN"></a>Attributes of RNN</h1><ol><li>RNN can process any length of context(but some words far from the current word are easy to forget).</li><li>Model size is constant. It won’t increase for longer input context.</li><li>Same weights applied on every time step, so there is <strong>symmetry</strong> in how inputs are processed.</li><li>Recurrent computation is slow(repeat doing matrix multiplication).<h1 id="Perplexity"><a href="#Perplexity" class="headerlink" title="Perplexity"></a>Perplexity</h1>The standard evaluation metric for Language Models is perplexity.<br>A bigger perplexity indicates that the model feels more confused when predicting the next word given previous words.<script type="math/tex; mode=display">perplexity=\prod_{t=1}^T(\frac{1}{P_{LM}(x^{(t+1)}|x^{(t)},x^{(t-1)},......,x^{(1)})})^{1/T}</script>Specifically,<script type="math/tex; mode=display">perplexity=\prod_{t=1}^T(\frac{1}{\hat y_{x_{t+1}}^{(t)}})^{1/T}=\exp(\frac{1}{T}\sum_{t=1}^T-\log\hat y_{x_{t+1}}^{(t)})=\exp(J(\theta))</script>it is directly related to the Loss.<br>So, the smaller the perplexity is, the better the model predicts.<h1 id="Vanishing-and-Exploding-Gradients"><a href="#Vanishing-and-Exploding-Gradients" class="headerlink" title="Vanishing and Exploding Gradients"></a>Vanishing and Exploding Gradients</h1>Intuitively, an RNN model can’t learn from contexts that are far away.<br>In math, one of the explain is vanishing and exploding of gradients.<h2 id="Vanish"><a href="#Vanish" class="headerlink" title="Vanish"></a>Vanish</h2><img src="/img/CS224n/截屏2025-10-24 22.24.04.png" alt=""><br>Chain Rule is used when working out gradients in RNN.<br>When $x\in (-1,1)$, $\tanh(x)$ is approximately equal to $x$.<br>Approximately, we have<script type="math/tex; mode=display">\frac{\partial h^{(t)}}{\partial h^{(t-1)}}\approx W_h</script>After propagating for $t$ layers, we’ll get $W_h^t$, and we consider eigenvalues $\lambda_1,\lambda_2,……,\lambda_n$ and eigenvectors $q_1,q_2,……,q_n$, we have<script type="math/tex; mode=display">W_h^t=\sum_{i=1}^nc_i\lambda_i^tq_i</script>As $t$ get larger and $|\lambda_i|&lt;1$, $\lambda_i^t$ is sure to be pretty small.<br>It’s obvious that some sub-directions of the gradient will be close to $0$, leading to what’s called <strong>Vanish</strong>.<br>The model can’t learn because the gradient vanishes.<h2 id="Explode"><a href="#Explode" class="headerlink" title="Explode"></a>Explode</h2>The same factor will also contribute to gradient <strong>Explode</strong>, which means the gradient goes much more big in one step.<br>This will lead to bad steps.<br><img src="/img/CS224n/截屏2025-10-24 22.25.37.png" alt=""><br>One way to solve Explode is to set a threshold.<br>If the norm of the gradient is larger than the threshold, re-scale the gradient to a small one(but pointing to the same direction).<h2 id="Generalize"><a href="#Generalize" class="headerlink" title="Generalize"></a>Generalize</h2>Gradient vanish and explode is not just a problem of RNN.<br>As the layers go deep, the problems are common to meet.<br>Some knows solutions such as “ResNet” and “DenseNet” are all based on creating <strong>skip-connections</strong> between layers that are not close to each other.</li></ol>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> 梯度 </tag>
            
            <tag> 反向传播 </tag>
            
            <tag> 梯度消失/爆炸 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>依存句法分析</title>
      <link href="/posts/b610878f.html"/>
      <url>/posts/b610878f.html</url>
      
        <content type="html"><![CDATA[<h1 id="Dependency-Structure"><a href="#Dependency-Structure" class="headerlink" title="Dependency Structure"></a>Dependency Structure</h1><p>The structure of a sentence can usually be shown in a tree.<br>Sentence structure consists of relations between words, which are normally binary asymmetric relations(“arrows”) called dependencies.<br>For example, the sentence “<code>[ROOT]</code> Bills on ports and immigration were submitted by Republican Senator Brownback of Kansas.” can be represented by a tree<br><img src="/img/CS224n/截屏2025-10-20 09.47.44.png" alt=""><br>The root is a assist node to help parse the sentence. There is a tree in an array to describe the whole structure.<br><img src="/img/CS224n/截屏2025-10-20 09.54.42.png" alt=""><br>In the sentence above, “completed” is the central word(head); “was”, “Discussion” is dependent of “completed”. “Discussion” then has some own sub-structures.</p><h2 id="Projectivity"><a href="#Projectivity" class="headerlink" title="Projectivity"></a>Projectivity</h2><p>Use some arcs(arrows) to demonstrate the tree structure, and find if there are any crosses among the arcs.<br>If there exists an cross, the sentence is of no projectivity.<br>Normally a sentence is of no projectivity.<br>But when it comes to sentences that have <strong>displaced constituents</strong>, the sentence becomes non-projective, which is more challenging to analyse.</p><h1 id="Arc-standard-Transition-based-Parser"><a href="#Arc-standard-Transition-based-Parser" class="headerlink" title="Arc-standard Transition-based Parser"></a>Arc-standard Transition-based Parser</h1><p>We need to use a parser to parse a linear sentence into tree structure. A parser maintains a stack $\sigma$, a buffer $\beta$, a set of dependency arcs $A$, and some actions.</p><h2 id="Actions-of-a-Basic-Transition-based-Parser"><a href="#Actions-of-a-Basic-Transition-based-Parser" class="headerlink" title="Actions of a Basic Transition-based Parser"></a>Actions of a Basic Transition-based Parser</h2><p>In the following demonstration, $w_i,w_j$ are some tokens(words) as a part of the whole sentence.<br>$\sigma$ is the stack that added to the beginning of the sentence. The token <code>[ROOT]</code> is in the bottom of $\sigma$.<br>$A$ is the set of dependency arcs.<br>$r(w_x,w_y)$ is the dependency of $w_y$ to $w_x$(an arrow from $w_x$ to $w_y$ in the graph)<br>$\rightarrow$ means from former value change to latter value.<br>$|$ is the link. $w_x|w_y$ means $w_x$ and $w_y$ are both in the stack or both in the buffer.<br>$B$ is the buffer, which contains all the tokens in the sentence that haven’t been added to the stack.</p><ol><li>Shift: push the front word of the buffer to stack.<script type="math/tex; mode=display">\sigma,w_i|B\rightarrow\sigma|W_i,B</script></li><li>Left-Arc: create a dependency between the two tokens on the top of $\sigma$.<script type="math/tex; mode=display">\sigma|w_i|w_j\rightarrow\sigma|w_j</script><script type="math/tex; mode=display">A\rightarrow A\cup r(w_j,w_i)</script></li><li>Right-Arc: create a dependency between the two tokens on the top of $\sigma$.<script type="math/tex; mode=display">\sigma|w_i|w_j\rightarrow\sigma|w_i</script><script type="math/tex; mode=display">A\rightarrow A\cup r(w_i,w_j)</script><h2 id="An-Example-With-a-Sequence-of-Actions"><a href="#An-Example-With-a-Sequence-of-Actions" class="headerlink" title="An Example With a Sequence of Actions"></a>An Example With a Sequence of Actions</h2><img src="/img/CS224n/截屏2025-10-20 21.15.00.png" alt=""><br><img src="/img/CS224n/截屏2025-10-20 21.15.38.png" alt=""><br>The process ends when the buffer is empty and the stack has only the root.<h2 id="Neural-Dependency-Parser"><a href="#Neural-Dependency-Parser" class="headerlink" title="Neural Dependency Parser"></a>Neural Dependency Parser</h2>We can use a neural network to decide which action to take on a certain state.<br>Input the word vectors of the top 2(or more) tokens in the stack and 1(or more) front tokens in the buffer to the model as input features and some other features such as POS(Part of Speech,词性).<br><img src="/img/CS224n/截屏2025-10-20 22.55.11.png" alt=""><br>There are 7 words involve.<br> $s_1,s_2,b_1$: top 2 tokens in the stack and the front word in the buffer.<br> $lc(s_1)$: the left child of $s_1$ in the already build dependency in $A$. If there are multi left children, pick the nearest one or pick the dependency that are more close.<br> $rc(s_1),lc(s_2),rc(s_2)$: same with $lc(s_1)$.<br>There are 3 attributes of a token involve.<br> The token itself(word vector).<br> The labeled POS.<br> The already build dependency. For example, the subject is signed as “nsubj”.<br>The output of the model is a 3-dimensional vector after a Softmax, indicating which action to take.<br>There is no searching in the process. So roughly the cost is $O(n)$. Some extra search operations can be used to rise the accuracy but it will cost time. But in general, the accuracy of this model is enough.<br><img src="/img/CS224n/截屏2025-10-20 22.45.19.png" alt=""><h2 id="Advantages-of-Neural-Dependency-Parser"><a href="#Advantages-of-Neural-Dependency-Parser" class="headerlink" title="Advantages of Neural Dependency Parser"></a>Advantages of Neural Dependency Parser</h2></li><li>The non-linear feature of neural network which allows to learn more complex nonlinear decision boundaries.</li><li>Use dense word vector rather than one-hot encoding for every circumstance.<h1 id="Evaluation-of-Dependency-Parser"><a href="#Evaluation-of-Dependency-Parser" class="headerlink" title="Evaluation of Dependency Parser"></a>Evaluation of Dependency Parser</h1>After building a dependency of a sentence, we can use some values to measure the accuracy of the parser.<br><img src="/img/CS224n/截屏2025-10-20 23.24.46.png" alt=""><br>For example, Gold is the right answer assigned by human. Parsed is the outcome if machine.<h2 id="Unlabeled-attachment-score-UAS"><a href="#Unlabeled-attachment-score-UAS" class="headerlink" title="Unlabeled attachment score(UAS)"></a>Unlabeled attachment score(UAS)</h2>Measure how much <strong>arcs</strong> the model predicts right.<br>In the picture, tokens <code>1,2,4,5</code> are right. So the UAS is 80%.<h2 id="Unlabeled-attachment-score-LAS"><a href="#Unlabeled-attachment-score-LAS" class="headerlink" title="Unlabeled attachment score(LAS)"></a>Unlabeled attachment score(LAS)</h2>Measure how much tokens that both the <strong>arcs</strong> and the <strong>dependencies</strong> are predicted right.<br>In the picture, tokens <code>1,2</code> are right. So the LAS is 40%.</li></ol>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 句法分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch入门</title>
      <link href="/posts/5f1831aa.html"/>
      <url>/posts/5f1831aa.html</url>
      
        <content type="html"><![CDATA[<h1 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h1><p>Exactly the same action with <code>numpy.array</code>.<br>Doing sections returns a smaller tensor even it’s only one number. Use <code>tensor.item()</code> to extract the single value.</p><h1 id="Auto-Grad"><a href="#Auto-Grad" class="headerlink" title="Auto Grad"></a>Auto Grad</h1><p>Pytorch works out gradient for every tensor automatically.<br>We can activate the auto grad system for a tensor when defining it.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = x * x * <span class="number">3</span> <span class="comment">#define a function y=f(x) here, and y is also a tensor.</span></span><br><span class="line"></span><br><span class="line">y.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad) <span class="comment"># returns 12</span></span><br></pre></td></tr></table></figure><br>If x is forward propagated to multiple variables, it’s gradient will be added up from all gradients passed back.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x.grad = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">z = x * x * <span class="number">3</span> <span class="comment"># 3x^2</span></span><br><span class="line"></span><br><span class="line">z.backward() <span class="comment">#passes gradient 12 to x</span></span><br><span class="line">y.backward() <span class="comment">#passes gradient 12 to x</span></span><br><span class="line"><span class="comment"># y = x * x * 3</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.grad) <span class="comment">#returns 24 = 12 + 12.</span></span><br></pre></td></tr></table></figure><br>So during backward propagation, the gradient to a node is accumulated up.<br>Run <code>zero_grad()</code> to clear all the grad before every training iteration.</p><h1 id="Neural-Network-Layers"><a href="#Neural-Network-Layers" class="headerlink" title="Neural Network Layers"></a>Neural Network Layers</h1><p>We need to import the <code>nn</code> module.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br></pre></td></tr></table></figure></p><h2 id="Linear-Layer"><a href="#Linear-Layer" class="headerlink" title="Linear Layer"></a>Linear Layer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create the inputs</span></span><br><span class="line"><span class="built_in">input</span> = torch.ones(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make a linear layers transforming N,*,H_in dimensinal inputs to N,*,H_out dimensional outputs</span></span><br><span class="line">linear = nn.Linear(<span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">linear_output = linear(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(linear_output.shape)</span><br><span class="line"><span class="comment">#output:torch.Size([2, 3, 2])</span></span><br></pre></td></tr></table></figure><p>In the code above, input size is <code>2,3,4</code>.<br>The first number <code>2</code> is the batch size dimension. The after are matrices that contains datas.</p><h2 id="Activation-Function-Layer"><a href="#Activation-Function-Layer" class="headerlink" title="Activation Function Layer"></a>Activation Function Layer</h2><p>Some examples of activations functions are <code>nn.ReLU()</code>, <code>nn.Sigmoid()</code> and <code>nn.LeakyReLU()</code>.</p><h2 id="Encapsulating-the-Layers"><a href="#Encapsulating-the-Layers" class="headerlink" title="Encapsulating the Layers"></a>Encapsulating the Layers</h2><p>We can use <code>nn.Sequential(layers...)</code> to capture different layers in a container.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">block = nn.Sequential(</span><br><span class="line">nn.Linear(<span class="number">4</span>, <span class="number">2</span>),</span><br><span class="line">nn.Sigmoid()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.ones(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">output = block(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure></p><h1 id="Neural-Network-Implement"><a href="#Neural-Network-Implement" class="headerlink" title="Neural Network Implement"></a>Neural Network Implement</h1><p>A neural network should extend the class <code>nn.Module</code>.<br>Implement the <code>__init__()</code> function. Call the constructor of super class first. Define some variables to store some information(e.g. size). Then declare the layers in the network.<br>Override the forward() function to predict an output based on the inputs.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultilayerPerceptron</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size</span>):</span><br><span class="line">    <span class="comment"># Call to the __init__ function of the super class</span></span><br><span class="line">    <span class="built_in">super</span>(MultilayerPerceptron, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Bookkeeping: Saving the initialization parameters</span></span><br><span class="line">    <span class="variable language_">self</span>.input_size = input_size</span><br><span class="line">    <span class="variable language_">self</span>.hidden_size = hidden_size</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Defining of our model</span></span><br><span class="line">    <span class="comment"># There isn&#x27;t anything specific about the naming of `self.model`. It could</span></span><br><span class="line">    <span class="comment"># be something arbitrary.</span></span><br><span class="line">    <span class="variable language_">self</span>.model = nn.Sequential(</span><br><span class="line">        nn.Linear(<span class="variable language_">self</span>.input_size, <span class="variable language_">self</span>.hidden_size),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Linear(<span class="variable language_">self</span>.hidden_size, <span class="variable language_">self</span>.input_size),</span><br><span class="line">        nn.Sigmoid()</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    output = <span class="variable language_">self</span>.model(x)</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><br>Another way to declare the layers are as follows.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultilayerPerceptron</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size</span>):</span><br><span class="line">    <span class="comment"># Call to the __init__ function of the super class</span></span><br><span class="line">    <span class="built_in">super</span>(MultilayerPerceptron, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Bookkeeping: Saving the initialization parameters</span></span><br><span class="line">    <span class="variable language_">self</span>.input_size = input_size</span><br><span class="line">    <span class="variable language_">self</span>.hidden_size = hidden_size</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Defining of our layers</span></span><br><span class="line">    <span class="variable language_">self</span>.linear = nn.Linear(<span class="variable language_">self</span>.input_size, <span class="variable language_">self</span>.hidden_size)</span><br><span class="line">    <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">    <span class="variable language_">self</span>.linear2 = nn.Linear(<span class="variable language_">self</span>.hidden_size, <span class="variable language_">self</span>.input_size)</span><br><span class="line">    <span class="variable language_">self</span>.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    linear = <span class="variable language_">self</span>.linear(x)</span><br><span class="line">    relu = <span class="variable language_">self</span>.relu(linear)</span><br><span class="line">    linear2 = <span class="variable language_">self</span>.linear2(relu)</span><br><span class="line">    output = <span class="variable language_">self</span>.sigmoid(linear2)</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><br>To use our network, create an instance of the class.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make a sample input</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create our model</span></span><br><span class="line">model = MultilayerPerceptron(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pass our input through our model</span></span><br><span class="line">predict = model(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(predict)</span><br></pre></td></tr></table></figure></p><h1 id="Procedure-of-Optimizing"><a href="#Procedure-of-Optimizing" class="headerlink" title="Procedure of Optimizing"></a>Procedure of Optimizing</h1><p>Once the model class is defined and dataset is ready, we can optimize the parameters in a fixed procedure.<br>We need to import the module first.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br></pre></td></tr></table></figure></p><h2 id="Initialize-the-Variables"><a href="#Initialize-the-Variables" class="headerlink" title="Initialize the Variables"></a>Initialize the Variables</h2><p>Create instances of out model, optimizer, loss function.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Instantiate the model</span></span><br><span class="line">model = MultilayerPerceptron(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the optimizer</span></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">1e-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define loss using a predefined loss function</span></span><br><span class="line">loss_function = nn.MSELoss()</span><br></pre></td></tr></table></figure></p><h2 id="Train-in-Loops"><a href="#Train-in-Loops" class="headerlink" title="Train in Loops"></a>Train in Loops</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the number of epoch, which determines the number of training iterations</span></span><br><span class="line">n_epoch = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epoch):</span><br><span class="line">  <span class="comment"># Set the gradients to 0</span></span><br><span class="line">  optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Get the model predictions</span></span><br><span class="line">  y_pred = model(x)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Get the loss</span></span><br><span class="line">  loss = loss_function(y_pred, y)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Print stats</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch&#125;</span>: traing loss: <span class="subst">&#123;loss&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Compute the gradients</span></span><br><span class="line">  loss.backward()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Take a step to optimize the weights</span></span><br><span class="line">  optimizer.step()</span><br></pre></td></tr></table></figure><p>Some other code such as calculating and printing the accuracy of training in every epoch can be added to the loop statement.</p><h1 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h1><p>DataLoader is a tool that can yield datas in batches.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br></pre></td></tr></table></figure></p><h2 id="Create-a-Loader"><a href="#Create-a-Loader" class="headerlink" title="Create a Loader"></a>Create a Loader</h2><p>The statement is<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)</span><br></pre></td></tr></table></figure><br>in which, <code>collate_fn</code> is the function that implements to a batch of data. It should have only one parameter: the batched data.<br>Different loaders can be integrate to train a model such as <code>train_x</code>, <code>train_y</code>, <code>test_x</code>, <code>test_y</code>.<br>Also, data and labels can be zipped into a same loader.</p><h2 id="Yield-from-a-Loader"><a href="#Yield-from-a-Loader" class="headerlink" title="Yield from a Loader"></a>Yield from a Loader</h2><p>When training, load data with loader.<br>Use a for loop. For each iteration, we have inputs, labels, and batch size.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch</span>(<span class="params">loss_function, optimizer, model, loader</span>):</span><br><span class="line"><span class="comment"># Keep track of the total loss for the batch</span></span><br><span class="line">total_loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_inputs, batch_labels, batch_lengths <span class="keyword">in</span> loader:</span><br><span class="line"><span class="comment"># Clear the gradients</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run a forward pass</span></span><br><span class="line">outputs = model.forward(batch_inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the batch loss</span></span><br><span class="line">loss = loss_function(outputs, batch_labels, batch_lengths)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate the gradients</span></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update the parameteres</span></span><br><span class="line">optimizer.step()</span><br><span class="line"></span><br><span class="line">total_loss += loss.item()</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> total_loss</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 梯度 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络数学运算</title>
      <link href="/posts/6ad6b028.html"/>
      <url>/posts/6ad6b028.html</url>
      
        <content type="html"><![CDATA[<h1 id="Vectorization"><a href="#Vectorization" class="headerlink" title="Vectorization"></a>Vectorization</h1><p>For computer, doing Loop to handling some iterating tasks is slow. Store some information in vectors, matrices, tensors can be greatly accelerated.</p><h1 id="Derivative-for-Matrix"><a href="#Derivative-for-Matrix" class="headerlink" title="Derivative for Matrix"></a>Derivative for Matrix</h1><h2 id="Gradient-for-Vector"><a href="#Gradient-for-Vector" class="headerlink" title="Gradient for Vector"></a>Gradient for Vector</h2><p>Given a function with $1$ output and $n$ inputs(n-dimension vector), we have</p><script type="math/tex; mode=display">f(x)=f(x_1,x_2,......,x_n)</script><p>then</p><script type="math/tex; mode=display">\frac{\partial f}{\partial x}=[\frac{\partial f}{\partial x_1},\frac{\partial f}{\partial x_2},\frac{\partial f}{\partial x_3},......,\frac{\partial f}{\partial x_n}]</script><h2 id="Jacobian-Matrix"><a href="#Jacobian-Matrix" class="headerlink" title="Jacobian Matrix"></a>Jacobian Matrix</h2><p>The gradient is for a function that inputs $n$ and outputs $1$.<br>The Jacobian Matrix is for a function that inputs $n$ and outputs $m$.<br>We have</p><script type="math/tex; mode=display">\begin{matrix}f(x)=[f_1(x_1,x_2,......,x_n),......,f_m(x_1,x_2,......,x_n)]\\=[f_1(x),f_2(x),......,f_m(x)]\end{matrix}</script><p>then</p><script type="math/tex; mode=display">\frac{\partial f}{\partial x}=\begin{bmatrix}\frac{\partial f_1}{\partial x_1}......\frac{\partial f_1}{\partial x_n}\\............\\\frac{\partial f_m}{\partial x_1}......\frac{\partial f_m}{\partial x_n}\end{bmatrix}</script><h3 id="Elementwise-Activation-Function"><a href="#Elementwise-Activation-Function" class="headerlink" title="Elementwise Activation Function"></a>Elementwise Activation Function</h3><p>For a activation function $h(x)$ which takes $n$ input and $n$ output, the Jacobian Matrix should be a diagonal $n \times n$ matrix.</p><script type="math/tex; mode=display">(\frac{\partial h}{\partial z})_{ij}=\begin{cases}h'(z_i)\,\,if\,\,\,i=j\\0\,\,\,else\end{cases}</script><h3 id="Examples-for-Jacobian"><a href="#Examples-for-Jacobian" class="headerlink" title="Examples for Jacobian"></a>Examples for Jacobian</h3><script type="math/tex; mode=display">\frac{\partial(Wx+b)}{\partial x}=W</script><script type="math/tex; mode=display">\frac{\partial(Wx+b)}{\partial b}=E(Identity Matrix)</script><script type="math/tex; mode=display">\frac{\partial(u^Th)}{\partial u}=h^T</script><h2 id="Shape-Convention"><a href="#Shape-Convention" class="headerlink" title="Shape Convention"></a>Shape Convention</h2><p>$s$ a single value while $W$ is $n \times m$ matrix.<br>We define that $\frac{\partial s}{\partial W}$ is also a $n\times m$ matrix.<br>By convention, we set the gradient of any object to be the shape of that object.</p><h1 id="Appliance-of-Chain-Rule"><a href="#Appliance-of-Chain-Rule" class="headerlink" title="Appliance of Chain Rule"></a>Appliance of Chain Rule</h1><h2 id="The-Chain-Rule"><a href="#The-Chain-Rule" class="headerlink" title="The Chain Rule"></a>The Chain Rule</h2><p>For a neural network with a linear layer, activation layer, and a last linear layer, we have<br>$x(input)$,$z=Wx+b$,$h=f(z)$,$s=u^Th$.<br>In terms of finding $\frac{\partial s}{\partial b}$, we should work out</p><script type="math/tex; mode=display">\frac{\partial s}{\partial b}=\frac{\partial s}{\partial h}\cdot\frac{\partial h}{\partial z}\cdot\frac{\partial z}{\partial b}</script><p>We then have</p><script type="math/tex; mode=display">\frac{\partial s}{\partial b}=u^T \text{diag}(f'(z))I=u^T \odot f'(z)</script><p>The symbol $\odot$ means element-wise multiplication between two same-dimensional vectors.</p><h2 id="Reusing-Computation"><a href="#Reusing-Computation" class="headerlink" title="Reusing Computation"></a>Reusing Computation</h2><p>For $\frac{\partial s}{\partial W}$, we have</p><script type="math/tex; mode=display">\frac{\partial s}{\partial W}=\frac{\partial s}{\partial h}\cdot\frac{\partial h}{\partial z}\cdot\frac{\partial z}{\partial W}</script><p>So, $\frac{\partial s}{\partial W}$ and $\frac{\partial s}{\partial b}$ have same part $\frac{\partial s}{\partial h}\cdot\frac{\partial h}{\partial z}$.<br>In regard to they are in a same layer, so the value can be passed from upstream layers and be reused to work out target derivatives.</p><h3 id="Dimension-Analyse"><a href="#Dimension-Analyse" class="headerlink" title="Dimension Analyse"></a>Dimension Analyse</h3><p>$W$ is $n\times m$; $x$ is $m\times 1$; $b,z,h,u$ is $n\times 1$.<br>$\frac{\partial s}{\partial h}\cdot\frac{\partial h}{\partial z}$ is $1\times n$.<br>$\frac{\partial z}{\partial W}$ is $n\times n\times m$.<br>Them multiplies, the result is $1\times n\times m$, can collapses to $n\times m$, in this cases, meet the definition of the Shape Convention.</p><h1 id="Numeric-Gradient"><a href="#Numeric-Gradient" class="headerlink" title="Numeric Gradient"></a>Numeric Gradient</h1><p>Numeric Gradient is used to check whether the algorithm to work out gradients is implemented correctly.<br>Starting from the definition of derivative, we see both sides of a certain value.<br>(for small $h \approx$ <code>1e-4</code> on computer)</p><script type="math/tex; mode=display">f'(x)\approx\frac{f(x+h)-f(x-h)}{2h}</script><h1 id="Computation-Graph"><a href="#Computation-Graph" class="headerlink" title="Computation Graph"></a>Computation Graph</h1><p>While doing forward propagation and backward propagation, we should have a graph to store our chain of calculation.<br><img src="/img/CS224n/截屏2025-10-18 20.39.32.png" alt=""><br>When backward propagation, just go through a reverse order of the graph carrying the current accumulated derivatives.<br><img src="/img/CS224n/截屏2025-10-18 20.41.30.png" alt=""><br>For a single Node case:<br><img src="/img/CS224n/截屏2025-10-18 20.41.59.png" alt=""><br><img src="/img/CS224n/截屏2025-10-18 20.43.25.png" alt=""><br>If the route divides in a node, then the gradient back passed from all routes should be sum up.<br><img src="/img/CS224n/截屏2025-10-18 20.45.15.png" alt=""><br>So in theory, we can build networks not only have classical neurons linked regularly layer by layer, but also like a <strong>DAG</strong> with diverse type of nodes.<br>Just work out gradient for each node. And go through the graph based on a <strong>topological order</strong> of the graph.<br><img src="/img/CS224n/截屏2025-10-18 20.48.06.png" alt=""></p><h1 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h1><p>Adam is a optimizing method that introduces <strong>Momentum $m$</strong> and <strong>Adaptive Learning Rate $v$</strong>.<br>Given the total parameter set $\theta$ and the hyper parameter $\alpha,\beta_1,\beta_2$, for the learning batch $t$, we modify<br><img src="/img/CS224n/截屏2025-10-21 16.08.40.png" alt=""></p><h2 id="Advantage-of-momentum"><a href="#Advantage-of-momentum" class="headerlink" title="Advantage of momentum"></a>Advantage of momentum</h2><p><em>Generated by Doubao</em><br>$m$ is a rolling average of gradients. Instead of relying solely on the noisy gradient of the current minibatch, it combines past gradients. This smooths out the fluctuations in gradients, so parameter updates don’t swing wildly. With lower variance, updates are more stable and consistent, which helps the model converge better and learn more reliably, avoiding being thrown off by the randomness in small batches of data.</p><h2 id="Advantage-of-Adaptive-Learning-Rate"><a href="#Advantage-of-Adaptive-Learning-Rate" class="headerlink" title="Advantage of Adaptive Learning Rate"></a>Advantage of Adaptive Learning Rate</h2><p>$v$ is a kind of rolling average of the magnitude(模长) of every gradient.<br><em>Generated by Doubao</em><br>Some parameters might have only had small gradient signals so far (leading to small $v$). By giving these parameters larger updates, Adam ensures they can still adjust significantly and contribute to learning. This way, even parameters that haven’t been changing much get a chance to be updated meaningfully, helping the model learn more comprehensively and efficiently.</p><h1 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h1><p>Dropout is a regularization technique.<br>For a hidden layer $h$ in the model, to every node, we have possibility $p$ to ignore it.<br>For ignored nodes, they have no output in forward propagation and no update to themselves in backward propagation.<br>If the some nodes are ignored in a layer, the total output of the layer may be smaller(the output signal may be weaker).<br>So, to every surviving node, we multiply $\frac{1}{1-p}$ to its output.</p><script type="math/tex; mode=display">h_{modified\,\,out}=\frac{1}{1-p}h_{origin\,\,out}</script><p>We can use vector multiplication to make process faster instead of using for-loop.</p><h2 id="Circumstances-to-Apply-Dropout"><a href="#Circumstances-to-Apply-Dropout" class="headerlink" title="Circumstances to Apply Dropout"></a>Circumstances to Apply Dropout</h2><p>Dropout should only be applied while training.<br>When the model is used to predict, we should not drop out any nodes to throughly use the information stored in the neural network.</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 梯度 </tag>
            
            <tag> 反向传播 </tag>
            
            <tag> 维度分析 </tag>
            
            <tag> 计算图 </tag>
            
            <tag> Adam </tag>
            
            <tag> Dropout </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Embedding</title>
      <link href="/posts/caaad70d.html"/>
      <url>/posts/caaad70d.html</url>
      
        <content type="html"><![CDATA[<h1 id="Distributed-Representation"><a href="#Distributed-Representation" class="headerlink" title="Distributed Representation"></a>Distributed Representation</h1><p>Naturally, we use context to learn about word.<br>So, we can build a dense vector for each word in <strong>corpus</strong>(word library/vocabulary).<br>By dot product, we can detect the similarity of given two words. Large result stands for large similarity while small one stands for small similarity.<br>Usually, a word vector is 300~500 dimensional. For some modern models, it can be around 1000.</p><h1 id="Word2Vector"><a href="#Word2Vector" class="headerlink" title="Word2Vector"></a>Word2Vector</h1><p>Word2Vector is the algorithm to turn words in corpus to vectors.<br>There are two methods to achieve it: <strong>Skip-grams(SG)</strong> and <strong>Continuous Bag of Words(CBOW)</strong>.<br>SG predicts context words based on given center word.<br>CBOW predicts center word based on given context words.<br>Following is a demonstration of SG.<br>The process on the corpus is a sliding window.<br><img src="/img/CS224n/截屏2025-10-13 19.16.55.png" alt=""></p><h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><p>We use $\theta$ to represent all the parameters in the set of all vectors.<br>For a given sentence, the Likelihood for its appearance in our model is</p><script type="math/tex; mode=display">L(\theta)=\prod_{t=1}^T\prod_{-m\leq j\leq m,j\neq0}P(w_{t+j}|w_t;\theta)</script><p>The sentence is already appeared. So to optimize out parameter, we should let it become bigger.<br>So, take the average of negative log likelihood as loss. The loss of out model is</p><script type="math/tex; mode=display">J(\theta)=-\frac{1}{T}\sum_{t=1}^T\sum_{-m\leq j\leq m,j\neq 0}\log P(w_{t+j},w_t;\theta)</script><h2 id="Definition-of-P-w-t-j-w-t-theta"><a href="#Definition-of-P-w-t-j-w-t-theta" class="headerlink" title="Definition of $P(w_{t+j},w_t;\theta)$"></a>Definition of $P(w_{t+j},w_t;\theta)$</h2><p>For a word $w$, we should maintain 2 vectors.<br>$v_w$: $w$ is a center word.<br>$u_w$: $w$ is a context word.<br>So, for a corpus with $v$ words, each vector is $d$ dimensional, then we’ll have $2vd$ words in total. All the parameters are initialized in random before optimizing.<br>Let $o$ be one of the context words while $c$ be the central word. We have</p><script type="math/tex; mode=display">P(o|c)=\frac{exp(u_o^Tv_c)}{\sum_{w\in V}exp(u_w^Tv_c)}</script><p>It is a <strong><code>softmax</code></strong> function $R^n\rightarrow (0,1)^n$.</p><h3 id="Gradient-of-v-c"><a href="#Gradient-of-v-c" class="headerlink" title="Gradient of $v_c$"></a>Gradient of $v_c$</h3><p>By taking derivatives using chain rule, we have</p><script type="math/tex; mode=display">\frac{\partial(\log P(o|c))}{\partial{v_c}}=u_o-\sum_{w\in v}P(w|c)u_w</script><p>The outcome is in the form of $observed-expected$.<br>observed: $u<em>o$<br>expected: $\sum</em>{w\in v}p(w|c)u_w$ which is the expected vector of possible results when the center word is $c$.</p><h3 id="Gradient-of-every-u-w"><a href="#Gradient-of-every-u-w" class="headerlink" title="Gradient of every $u_w$"></a>Gradient of every $u_w$</h3><p>when $w = o$, we have</p><script type="math/tex; mode=display">\frac{\partial(\log P(o|c))}{\partial{u_o}}=v_c\cdot(1-P(o|c))</script><p>when $w \neq o$, we have</p><script type="math/tex; mode=display">\frac{\partial(\log P(o|c))}{\partial{u_w}}=-v_c\cdot P(w|c)</script><h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><p>Basing on this, we can form a descent for the whole $\theta$.<br>Given the learning rate $\alpha$, we have</p><script type="math/tex; mode=display">\theta^{new}=\theta^{old}-\alpha\nabla_\theta J(\theta)</script><h2 id="Forming-Word-Vector"><a href="#Forming-Word-Vector" class="headerlink" title="Forming Word Vector"></a>Forming Word Vector</h2><p>After training, it usually turns out that every word’s $u$ and $v$ vectors are very close.<br>We can take average of them to form a final vector for each word.</p><h1 id="More-Sophisticated-Way-for-Word2Vector"><a href="#More-Sophisticated-Way-for-Word2Vector" class="headerlink" title="More Sophisticated Way for Word2Vector"></a>More Sophisticated Way for Word2Vector</h1><p>In fact, It’s impossible to do GD or SGD on the mode above, because that process needs to iterate over all word in the corpus.<br>Instead, we can use <strong>Negative Sampling</strong>.</p><h2 id="Sample"><a href="#Sample" class="headerlink" title="Sample"></a>Sample</h2><p>Instead of pulling out every word, we just sample some words.<br>The words which are more frequently used in human language are more easily to be sampled out.<br>For every word $w$ in the corpus $V$ with total possibility of $U(w)$ to appear in human language, let</p><script type="math/tex; mode=display">p(w)=U^{3/4}(w)</script><p>Then we work out the total possibility to Standard all the $p(w)$ to let the sum of them is $1$.</p><script type="math/tex; mode=display">Z=\sum_{w\in V}p(w)</script><p>Just divide with $Z$, and get the final output for sampling</p><script type="math/tex; mode=display">P(w)=\frac{p(w)}{Z}</script><p>With the operation of taking $U^{3/4}(w)$ in the beginning, we can let the words that have small possibility to appear weigh a little more(a bit more likely to be sampled) when sampling.</p><h2 id="Loss-Function-1"><a href="#Loss-Function-1" class="headerlink" title="Loss Function"></a>Loss Function</h2><p>Only for words that are not context of the given center word, we sample them.<br>Then, we need to let the machine know they are not similar with the center word(by do positive contribution to the loss).<br>We sample out $K$ such words per batch. They are called negative samples.<br>So, we can have the loss function</p><script type="math/tex; mode=display">J_{neg-sample}(u_o,v_c,U)=-\log\sigma(u_o^Tv_c)-\sum_{k\in K\,sampled\,words}\log\sigma(-u_k^Tv_c)</script><p>Here, $\sigma(x)$ is the <strong>Sigmoid</strong> function.<br>The context word’s vector $u_o$ make negative contributions to the loss while sampled word’s vectors make positive contributions. That is suitable for optimizing.</p><h2 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h2><p>We only need to update a few vectors related to the loss function: $u_o$, $v_c$, and every sampled word $w$’s $u_w$.</p><script type="math/tex; mode=display">\frac{\partial{J}}{\partial u_o}=[\sigma(u_o^T​v_c​)−1]⋅v_c​</script><script type="math/tex; mode=display">\frac{\partial{J}}{\partial v_c}=[\sigma(u_o^T​v_c​)−1]⋅u_o​+\sum_{k\in K\,sampled\,words}​[\sigma(u_w^T​v_c​)]⋅u_w​</script><script type="math/tex; mode=display">\frac{\partial{J}}{\partial u_w}=\sigma(u_w^T​v_c​)⋅v_c</script><h1 id="Word-Sense-Ambiguity"><a href="#Word-Sense-Ambiguity" class="headerlink" title="Word Sense Ambiguity"></a>Word Sense Ambiguity</h1><p>Most of common words have different meanings.<br>Sure we can insert different copies of a same word into a corpus, and do some clustering to make each copy belongs to its relative area(train multiple word vectors for a single word).<br>But that is too difficult. Actually we can just do linear functions.<br>For a word $w$ which has $n$ meanings, let $f_1$,$f_2$,……,$f_n$ be frequency of each meaning.$v_1$,$v_2$,……,$v_n$ is each meaning’s vector. So we have a final meaning vector</p><script type="math/tex; mode=display">v=\frac{1}{\sum_{i=1}^nf_i}\sum_{i=1}^nf_iv_i</script><p>Although this process discards lots of information, but it usually works in a high-dimensional space.</p><h1 id="Named-Entity-Recognition-NER"><a href="#Named-Entity-Recognition-NER" class="headerlink" title="Named Entity Recognition(NER)"></a>Named Entity Recognition(NER)</h1><p>We can build a neural network to sign a word with some labels.<br>For example, labels like LOC,PER,DATE(location, person, date) to sign what a word refers to.<br><img src="/img/CS224n/截屏2025-10-14 16.42.48.png" alt=""></p><h2 id="Window-Classification-Using-Binary-Logistic-Classifier"><a href="#Window-Classification-Using-Binary-Logistic-Classifier" class="headerlink" title="Window Classification Using Binary Logistic Classifier"></a>Window Classification Using Binary Logistic Classifier</h2><p>We can use a sliding window of a fixed size, sliding over the sentences and detect whether a word in the center position is a LOC, or a PER, or a DATE.<br><img src="/img/CS224n/截屏2025-10-14 16.47.01.png" alt=""><br>For the input of the neural network, we view the word vectors in the window to a big vector.<br>Then, we do some regression.<br><img src="/img/CS224n/截屏2025-10-14 16.58.49.png" alt=""><br><em>$h=f(Wx+b)$ is a process that do Linear Transformation and then Activate the data. Actually we can use more than one layer of this rather than the process shown in the graph.</em></p><h2 id="Cross-entropy-Loss"><a href="#Cross-entropy-Loss" class="headerlink" title="Cross-entropy Loss"></a>Cross-entropy Loss</h2><p>The output of the neural network should be a vector that demonstrates whether the central word in the window is a LOC/PER/DATE.<br>For example, if the word is LOC, then the target vector to output is <code>[1,0,0]</code>.<br>Let $p$ be the target vector, and $q$ is the predicted vector output by the neural network. Both are n-dimensional vectors. $v_i$ is the $i^{th}$ dimension’s value.<br>The loss is</p><script type="math/tex; mode=display">H(p,q)=-\sum_{i=1}^np_i\log q_i</script><p><em>Note that this formula of cross-entropy loss is only suitable for the circumstance that there is only 1 <code>1</code> in the target vector and the else are all <code>0</code>.</em></p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理(CS224n)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 梯度 </tag>
            
            <tag> 损失函数 </tag>
            
            <tag> 词嵌入 </tag>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聚类算法</title>
      <link href="/posts/35f08535.html"/>
      <url>/posts/35f08535.html</url>
      
        <content type="html"><![CDATA[<h1 id="K-means-Algorithm"><a href="#K-means-Algorithm" class="headerlink" title="K-means Algorithm"></a>K-means Algorithm</h1><p>假设需要给地图（空间）上的$n$个人分配$k$个食堂。要求所有人到答自己配到的食堂距离的平方和最小。这就是一个K-means聚类（K-means Clustering）问题。<br>一个食堂理解为一个聚类中心（Cluster Centre）。<br>空间上的一个人认为一个散点。<br>散点$i$的坐标为$x^{(i)}$，它关联的聚类中心的索引为$y^{(i)}$<br>聚类中心$j$的坐标为$\mu^{(j)}$<br>那么，可以定义$i$点到$j$中心的Squared Loss为$|x^{(i)}-\mu^{(j)}|^2$<br>我们记这个系统的总平方损失为</p><script type="math/tex; mode=display">Loss=\sum_{j=1}^k\sum_{i=1}^n1\begin{Bmatrix}y^{(i)}=j\end{Bmatrix}\cdot |x^{(i)}-\mu^{(j)}|^2</script><p>其中的变化因素为聚类中心的坐标$\mu$，以及每个点分配到的聚类中心$y$<br>我们定义K-means Objective（K-means目标）为使得这个Loss最小的$\mu,y$组合。即</p><script type="math/tex; mode=display">K\,means\,Objective=argmin_{\mu,y}\sum_{j=1}^k\sum_{i=1}^n1\begin{Bmatrix}y^{(i)}=j\end{Bmatrix}\cdot |x^{(i)}-\mu^{(j)}|^2</script><p>K-means算法的实现<br>对于给定的聚类中心个数$k$以及最大迭代轮数$\tau$</p><ol><li>先执行初始化，获得最初的$\mu,y$</li><li>然后执行$\tau$轮循环。每一轮中<ul><li>对于$n$个点，将其分配至距离最近的聚类中心。<br>  即对于<code>i in range(n)</code>，set $y^{(i)}=argmin_j|x^{(i)}-\mu^{(j)}|$</li><li>然后调整每个聚类中心，将其转移至所有分配给自身的点的几何重心上<br>  即对于<code>j in range(k)</code>，set<script type="math/tex; mode=display">\mu^{(j)}=\frac{\sum_{i=1}^n1\begin{Bmatrix}y^{(i)}=j\end{Bmatrix}\cdot x^{(i)}}{\sum_{i=1}^n1\begin{Bmatrix}y^{(i)}=j\end{Bmatrix}}</script></li><li>比对：如果上一轮迭代结束后的$y$与这一轮结束后的$y$一样，那么直接跳出循环。</li></ul></li><li>返回所得的$\mu,y$。<br>实际上，这个算法对于某些初始化的情况只能收敛到Local Optimal，不能收敛到Global Optimal。因此可以采取Restart：设置多个初始化的数据组，分别做K-means算法，取Loss最低的方式。<h1 id="Definition-of-Clustering"><a href="#Definition-of-Clustering" class="headerlink" title="Definition of Clustering"></a>Definition of Clustering</h1>上述K-means算法的数据集没有Labels。K-means算法本质上实现了一种聚类（Clustering）。<br>聚类就是依照某些依据把数据集做拆分。<br>由于其不依赖Labels，因此聚类操作是Unsupervised Machine Learning的一种。<br><img src="/img/MIT6036/与无监督机器学习有关的图.png" alt=""><h1 id="Attributes-of-K-means"><a href="#Attributes-of-K-means" class="headerlink" title="Attributes of K-means"></a>Attributes of K-means</h1>$k$的选取<br> 有些情境下，$k$是给定的<br> 有时候$k$不给定，需要自行选取<br> 一般的，$k$越大，获得的Loss越小。如果$k\geq n$，那最小的Loss=0<br> 一般计算损失的时候，可以算一个与$k$值正相关的损失项。<script type="math/tex; mode=display"> Loss=\sum_{j=1}^k\sum_{i=1}^n1\begin{Bmatrix}y^{(i)}=j\end{Bmatrix}\cdot |x^{(i)}-\mu^{(j)}|^2+cost(k)</script>K-means聚类的形态：K-means算法能完美分类等大小的圆形区域点。<br><img src="/img/MIT6036/等密度等半径聚类.png" alt=""><br><img src="/img/MIT6036/密度不一的等量聚类.png" alt=""><br><img src="/img/MIT6036/大样本区和散点.png" alt=""><br><img src="/img/MIT6036/大聚团.png" alt=""></li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无监督机器学习 </tag>
            
            <tag> K-means </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>决策树与随机森林</title>
      <link href="/posts/becca920.html"/>
      <url>/posts/becca920.html</url>
      
        <content type="html"><![CDATA[<h1 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h1><p>决策树可以理解为一种多维的更复杂的Step Function。<br>其变化是瞬变而非平滑。<br>作为一种可解释的预测模型，决策树也分为分类树和回归树<br>树的节点：</p><ul><li>Internal Node<ul><li>组成：Features和Values</li><li>Features是一个d维向量，维度的下标为j</li><li>Split Values拆分值，一个数</li><li>左子节点是条件维度小于Split Value，右子节点是条件维度大于等于Split Value。</li></ul></li><li>Leaf Node<ul><li>在给定触发条件下返回的预测（输出）值<br><img src="/img/MIT6036/决策树结构示意举例.png" alt=""></li></ul></li></ul><h1 id="Growing-a-Decision-Tree"><a href="#Growing-a-Decision-Tree" class="headerlink" title="Growing a Decision Tree"></a>Growing a Decision Tree</h1><p>给出一个数据集$I$，给出分类机制来把$I$中的Label分类，并形成一个决策树。<br>基于树的结构，我们要调用递归函数。<br>BuildTree($I$，$k$)<br>如果$|I|&lt;k$</p><ol><li>记$\widehat{y}=average_{i\in I}y^{(i)}$</li><li>返回一个叶子节点 Leaf(label = $\widehat{y}$) 这里的label是基于树的预测值<br>否则<br>对于Feature的每一个维度 $j$ 和所有点中的一个在这个维度下的坐标$s$：<br>设子集<script type="math/tex; mode=display">I^+_{j,s} = \{ i\in I \mid x^{(i)}_j \geq s \}</script>设子集<script type="math/tex; mode=display">I^-_{j,s} = \{ i\in I \mid x^{(i)}_j < s \}</script>设平均值<script type="math/tex; mode=display">\widehat{y}^+_{j,s} = \text{average}_{i\in I^+_{j,s}} y^{(i)}</script>设平均值<script type="math/tex; mode=display">\widehat{y}^-_{j,s} = \text{average}_{i\in I^-_{j,s}} y^{(i)}</script>设误差（损失）<script type="math/tex; mode=display">E_{j,s} = \sum_{i\in I^+_{j,s}} (y^{(i)} - \widehat{y}^+_{j,s})^2 + \sum_{i\in I^-_{j,s}} (y^{(i)} - \widehat{y}^-_{j,s})^2</script>设<script type="math/tex; mode=display">(j^*, s^*) = \underset{j,s}{\text{argmin}} \, E_{j,s}</script>返回一个Internal节点<script type="math/tex; mode=display">Node(j^*,s^*，BuildTree(I^-_{j^*,s^*}，k)，BuildTree(I^+_{j^*,s^*}，k))</script>如果$k$太小，会出现过拟合的情况。<br>同样的，一般很可能会出现同一Internal节点下出现多个预测值一样的Leaf节点。<br>处理方法：</li></ol><ul><li>正则化损失</li><li>记$|T|$为树的Leaf节点个数，在总损失中引入这一参数<script type="math/tex; mode=display">C_\alpha(T)=\sum_{i=1}^nL(T(x^{(i)}),y^{(i)})+\alpha|T|</script></li><li>只需要很小的一个$\alpha$值，就可以推断为不值得生成这个Leaf节点。</li><li>基于新的损失来修剪树的冗余的Leaf节点。<h1 id="Ensembling"><a href="#Ensembling" class="headerlink" title="Ensembling"></a>Ensembling</h1>Ensembling是一种提高数据集利用率的方式。<br>典型的方法为Bagging，即Bootstrap Aggregating。<br>(Bootstrap)对于一个数据集$D_n$，我们遍历$b=1,2,3,\dots,B$</li></ul><ol><li>设$\widetilde{D}_n^{(b)}$是对$D_n$的n次随机采样（允许重复）取得的假数据集</li><li>基于假数据集训练模型$\widetilde{f}^{(b)}$<br>(Aggregating)返回平均的模型<script type="math/tex; mode=display">\widetilde{f}_{bag}(x)=\frac{1}{B}\sum_{b=1}^B\widetilde{f}^{(b)}(x)</script><h1 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h1>随机森林是一种特殊的Bagging，针对决策树问题。<br>对$1,2,3,4,\dots,B$，通过可重复采样生成$B$个假数据集。<br>对每一个$\widetilde{D}_n^{(b)}$：<br>递归直到遇到边界($k&gt;|I|$)</li><li>随机在$d$个维度中不重复地取$m$个维度，记为$1,2,3,\dots,m$</li><li>找到最佳的(<script type="math/tex">m^*,s^*</script>)（类似于上面的找(<script type="math/tex">j^*,s^*</script>)）</li><li>基于此创建树节点以及其子节点。<br>预测时，对于回归问题，取各个树返回值的平均数。对于分类问题，返回采样点在各个树上返回值的众数（类似于各个树在投票）</li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 决策树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循环神经网络-导论</title>
      <link href="/posts/39a9d4ee.html"/>
      <url>/posts/39a9d4ee.html</url>
      
        <content type="html"><![CDATA[<h1 id="Components"><a href="#Components" class="headerlink" title="Components"></a>Components</h1><p>RNN（循环神经网络）也可以理解为一个状态机。<br>假设讨论第$t$轮，其state是一个$m \times 1$向量$s_t$。<br>输入向量$x_t$，可以认为是$1 \times 1$（Special Case），也可以认为是$c \times 1$。<br>预测向量$p_t$，为$v \times 1$，为一个链结的输出值。<br>线性操作的矩阵：</p><ul><li>外界输入向量$x_t$前面的系数矩阵$W^{sx}$，为$m \times c$</li><li>上一轮迭代向量$s_{t-1}$前面的系数矩阵$W^{ss}$，为$m \times m$</li><li>常数矩阵$W_0^{ss}$，为$m \times 1$</li><li>获取$p_t$的激活函数（第二次激活函数）前的线性变换矩阵$W^o$（$v \times m$）与$W_0^o$（$v \times 1$）<br><img src="/img/MIT6036/循环神经网络结构示意图.png" alt=""><h1 id="Operations-for-Each-Layer"><a href="#Operations-for-Each-Layer" class="headerlink" title="Operations for Each Layer"></a>Operations for Each Layer</h1>已知输入向量<script type="math/tex">x_t</script>，状态向量<script type="math/tex">s_{t-1}</script>。<br>则线性变换有<script type="math/tex; mode=display">z_t^1 = W^{sx}x_t + W^{ss}s_{t-1} + W_0^{ss}</script>转入激活函数$f_1$得$s_t$<script type="math/tex; mode=display">s_t = f_1(z_t^1)</script>这个$s_t$即为下一层的状态向量<br>做第二次线性变换<script type="math/tex; mode=display">z_t^2 = W^os_t + W_0^o</script>经过激活函数得到这一层向外界输出的预测向量<script type="math/tex; mode=display">p_t = f_2(z_t^2)</script>注意变元右上角的数字并不是指数而是上标。<br>举例：假设在做一个英文字母预测提词器，认为状态机中保存已经输入的3个英文字符为<script type="math/tex">s_{t-1}</script>，现在再从字符串中读取下一个字符<script type="math/tex">x_t</script>。我们要使得<script type="math/tex">s_t</script>中有<script type="math/tex">s_{t-1}</script>中的后两个字符以及<script type="math/tex">x_t</script>，（字符可以做One-Hot编码，但是这里假设是一位线性的方便表示）那我们可以认为<script type="math/tex">f_1</script>为<script type="math/tex">f_1(x)=x</script>，然后适当的取转换矩阵。<script type="math/tex; mode=display">s_t = \begin{bmatrix}1\\0\\0\end{bmatrix}x_t + \begin{bmatrix}0 & 0 & 0\\1 & 0 & 0\\0 & 1 & 0\end{bmatrix}s_{t-1}</script>实际情况更加复杂，但是参数训练完后差不多会是如是情形。<h1 id="Loss-and-Gradient"><a href="#Loss-and-Gradient" class="headerlink" title="Loss and Gradient"></a>Loss and Gradient</h1>RNN的训练样本应该是有时序的一串序列，比如字符串。<br>每次迭代序列的下一列或下一子串$x_t$进入神经网络。<br>我们假设训练样本有$q$个序列。每个序列有$n^{(i)}$个子单元。<br>则一个序列的损失为<script type="math/tex; mode=display">L_{seq}(p^{(i)}, y^{(i)}) = \sum_{t=1}^{n^{(i)}} L_{elt}(p_t^{(i)}, y_t^{(i)})</script>总损失为<script type="math/tex; mode=display">J(W^o, W_0^o) = \sum_{i=1}^q L_{seq}(p^{(i)}, y^{(i)})</script>对一个$L_{seq}$，其对于参数的梯度有（以$W^{sx}$为例）<script type="math/tex; mode=display">\frac{\partial L_{seq}(p^{(i)}, y^{(i)})}{\partial W^{sx}} = \sum_{t=1}^{n^{(i)}} \frac{\partial L_{elt}(p_t^{(i)}, y_t^{(i)})}{\partial W^{sx}}</script></li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> 梯度 </tag>
            
            <tag> NN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习</title>
      <link href="/posts/748f0bbe.html"/>
      <url>/posts/748f0bbe.html</url>
      
        <content type="html"><![CDATA[<h1 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h1><p>与<a href="/posts/11aff4a7.html" title="马尔可夫决策过程">马尔可夫决策过程</a>不同的是，强化学习是当智能体进入一个陌生的环境中，并不知道奖励和转换矩阵，智能体需要做出操作并依据反馈学习周围的环境。<br>即进入陌生环境后，依然有状态机$S$和操作集合$A$，但不知道所有的转移概率$T$与奖励$R$。</p><h1 id="Exploration-amp-Exploitation"><a href="#Exploration-amp-Exploitation" class="headerlink" title="Exploration &amp; Exploitation"></a>Exploration &amp; Exploitation</h1><p>智能体笼统地有两种策略：探索和利用。<br>智能体被投放入陌生环境后，假设会进行无限轮操作。其目的是获取尽可能大的Reward。<br>Exploration策略为探索环境中的信息<br>    操作为不管环境为何种情况，完全随机选择一个$a\in A$当做该轮操作。<br>Exploitation为基于获取的信息做出最优的决策<br>    操作为基于搜集到的信息和当前的$s$决策出最优的行为$a$。<br>为了获得更好的Reward，智能体需要权衡Exploration和Exploitation的操作比例。<br>我们用$\epsilon$来表示权衡的比例。<br>$\epsilon\in (0,1)$，我们认为有$1-\epsilon$的概率采取Exploitation策略，有$\epsilon$的概率采取Exploration策略。<br>实际上，每一步操作都会有信息的摄入，即$R(s,a)，s_{new}$。</p><h1 id="Searching-for-Optimal-Policy-By-T-and-R"><a href="#Searching-for-Optimal-Policy-By-T-and-R" class="headerlink" title="Searching for Optimal Policy By $T$ and $R$"></a>Searching for Optimal Policy By $T$ and $R$</h1><p>可以通过持续从环境中学习到更准确的$T$和$R$值。</p><ol><li>初始化智能体状态：$s^{(1)}=s_0$</li><li>初始化$T$：对任何的$s,a,s^{‘}$，我们有$\widehat{T}(s,a,s^{‘})=\frac{1}{|S|}，\widehat{R}(s,a)=0$</li><li>对于第$t$轮迭代：</li></ol><ul><li>基于$\epsilon$选择操作$a^{(t)}$。</li><li>执行操作$a^{(t)}$，获得更新的该情况下的收益$r^{(t)}$与下一轮得到的状态$s^{(t+1)}$。</li><li>更新：<br>$\widehat{R}(s^{(t)},a^{(t)})=r^{(t)}$<script type="math/tex; mode=display">\widehat{T}(s,a,s^{'}) = \frac{1 + \sum_{i=1}^t \mathbb{I}(s^{(i)}=s, a^{(i)}=a, s^{(i+1)}=s^{'})}{|S| + \sum_{i=1}^t \mathbb{I}(s^{(i)}=s, a^{(i)}=a)}</script>实质即假设在$s$状态下的$a$操作中，原本变为任何一个$s^{‘}$的情况都发生过1次。<br>随着迭代，如果某轮发现$s$状态下的$a$操作后产出一个$s^{‘}$，那变为$s^{‘}$的情况计数（频数）加一。<br>若干次迭代后，可以依据频数推出各个$s^{‘}$的$\widehat{T}(s,a,s^{‘})$。<br>数据量充足后，各个$s^{‘}$初始化默认发生过的1次会收敛掉。<br>依据新的$\widehat{R}$、$\widehat{T}(s,a,s^{‘})$预测新的$Q$以及更新策略$\pi$。<br>在实际操作中，$\epsilon$不一定为常数。起初，可以让$\epsilon$大一些，随着探索轮数变多，其实可以认为对环境系统的认知已经收敛至真实情况，这时可以让$\epsilon$变小。</li></ul><h1 id="Searching-for-Optimal-Policy-By-Q"><a href="#Searching-for-Optimal-Policy-By-Q" class="headerlink" title="Searching for Optimal Policy By $Q$"></a>Searching for Optimal Policy By $Q$</h1><h2 id="Expected-Values"><a href="#Expected-Values" class="headerlink" title="Expected Values"></a>Expected Values</h2><p>首先讨论一下各种期望值。<br>经典期望值</p><script type="math/tex; mode=display">\widetilde{E}^{(t)}=\frac{1}{t}\sum_{i=1}^tx^{(i)}</script><p>运行时期望值：每一轮产生一个期望值，新输入值之后基于迭代轮数、旧期望值产生新期望值。<br>已知$\widetilde{E}^{(0)}=0，\alpha^{(t)}=\frac{1}{t}$，则有</p><script type="math/tex; mode=display">\widetilde{E}^{(t)}=(1-\alpha^{(t)})\widetilde{E}^{(t-1)}+\alpha^{(t)}x^{(t)}</script><p>变化版运行时均值：任何$\alpha^{(t)}$都为一个常数$\alpha$。</p><script type="math/tex; mode=display">\widetilde{E}^{(t)}=(1-\alpha)\widetilde{E}^{(t-1)}+\alpha x^{(t)}</script><p>可由递推得通项公式：$\widetilde{E}^{(t)}=\sum_{i=1}^t(1-\alpha)^{t-i}\alpha x^{(t)}$<br>运行时均值其实对后输入的值权重更大。</p><h2 id="Estimate-Q"><a href="#Estimate-Q" class="headerlink" title="Estimate Q"></a>Estimate Q</h2><p>已有Q的迭代公式</p><script type="math/tex; mode=display">Q_{new}=R(s,a)+\gamma\sum_{s^{'}\in S}T(s,a,s^{'})max_{a^{'}}Q_{old}(s^{'},a^{'})</script><p>化成概率×值加和的形式为</p><script type="math/tex; mode=display">Q_{new}=\sum_{s^{'}\in S}T(s,a,s^{'})(R(s,a)+\gamma max_{a^{'}}Q_{old}(s^{'},a^{'}))</script><p>这就是一个均值的形成方式。<br>基于上述的变化版运行时均值，可以把这个公式近似成用于迭代更新$Q(s,a)$的方法(其中箭头表示取代被指向的值)</p><script type="math/tex; mode=display">Q(s,a)\leftarrow (1-\alpha)Q(s,a)+\alpha(R(s,a)+\gamma max_{a^{'}}Q_{old}(s^{'},a^{'}))</script><p>公式中保留<script type="math/tex">Q_{old}</script>作用不大，直接用当前轮的<script type="math/tex">Q</script>替换<script type="math/tex">Q_{old}</script>；<script type="math/tex">R(s,a)</script>其实就是这一轮读取到的Reward，记为<script type="math/tex">r</script>。则有简化版迭代公式</p><script type="math/tex; mode=display">Q(s,a)\leftarrow (1-\alpha)Q(s,a)+\alpha(r+\gamma max_{a^{'}}Q(s^{'},a^{'}))</script><p>可以用这种方法替换掉上一种学习方式中对$T,R$的迭代。<br>当需要采取Exploitation策略时：对于给定$s$的每一步决策，我们对于任何$a$，直接搜索所有的$Q(s,a)$。取使得$Q(s,a)$最大的a。<br>这种方法也称为Q-Learning。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MDP </tag>
            
            <tag> 最优Q策略 </tag>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>马尔可夫决策过程</title>
      <link href="/posts/11aff4a7.html"/>
      <url>/posts/11aff4a7.html</url>
      
        <content type="html"><![CDATA[<h1 id="State-Machine"><a href="#State-Machine" class="headerlink" title="State Machine"></a>State Machine</h1><p>状态机的组成：</p><ul><li>$S$：所有可能状态$s$的集合<ul><li>$s_0$：起始状态</li><li>所有状态满足马尔科夫性，即下一状态和奖励仅与当前状态和动作有关，与历史无关。</li></ul></li><li>$A$：所有可能输入$a$（操作）的集合<ul><li>对于一个操作，在某个状态下给出，它有可能在各个概率下转化为各个其他状态</li><li>则有转化矩阵<script type="math/tex; mode=display">Matrix_a = \begin{bmatrix}p_{s_1\rightarrow s_1} & p_{s_1\rightarrow s_2} & p_{s_1\rightarrow s_3} & \dots & p_{s_1\rightarrow s_n} \\p_{s_2\rightarrow s_1} & p_{s_2\rightarrow s_2} & p_{s_2\rightarrow s_3} & \dots & p_{s_2\rightarrow s_n} \\\vdots & \vdots & \vdots & \ddots & \vdots \\p_{s_n\rightarrow s_1} & p_{s_n\rightarrow s_2} & p_{s_n\rightarrow s_3} & \dots & p_{s_n\rightarrow s_n}\end{bmatrix}</script></li></ul></li><li>$f:S × A \rightarrow S$：函数，输入一个起始状态以及一个输入操作，映射从一种状态转化为另一种状态。</li><li>$T$：Transition Model。给定原状态和操作和后续状态，返回转变为该后续状态的概率。<ul><li><script type="math/tex; mode=display">P(s_t | s_{t-1}, a_{t-1}) = T(s_{t-1}, a_{t-1}, s_t)</script></li></ul></li><li>$R$：奖励函数，指某状态下执行操作会有多少受益。$S × A \rightarrow \mathbb{R}$。<ul><li>$R(s,a)$为该轮收益</li></ul></li></ul><h1 id="Policy"><a href="#Policy" class="headerlink" title="Policy"></a>Policy</h1><p>策略$\pi$。输入一个状态，输出一个操作。$\pi : S \rightarrow A$。<br>期限(Horizon)$h$：总共可以进行操作的轮数（一轮操作获得一次收益）<br>总受益$V$。输入一个状态，给出对应策略。<br>$V_\pi^h(s)$表示在剩余期限为h轮，策略集为$\pi$，初始状态为$s$的状况下的总收益。<br>则有递推公式</p><script type="math/tex; mode=display">V_\pi^h(s) = R(s,\pi(s)) + \sum_{s^{'}\in S} T(s,\pi(s),s^{'}) \cdot V_\pi^{h-1}(s^{'})</script><p>上述的$\pi$为non_stationary的。因为其只和$s$有关。<br>实际上，策略还应该与剩余轮数$h$有关，记为$\pi_h(s)$。</p><h1 id="Seeking-Best-Policy"><a href="#Seeking-Best-Policy" class="headerlink" title="Seeking Best Policy"></a>Seeking Best Policy</h1><h2 id="Finite-Horizon"><a href="#Finite-Horizon" class="headerlink" title="Finite Horizon"></a>Finite Horizon</h2><p>$Q^h(s,a)$：在当前状态为$s$，还剩$h$轮时。我们这一轮采取操作$a$，那么假设接下来$h-1$轮我们都能采取了最佳操作，我们说这样操作的总收益为$Q^h(s,a)$。<br>有了$Q$的概念，我们可以找到一个optimal policy：$\pi_h^*(s)=argmax_a Q^h(s,a)$。即所有$a$中，使得$Q^h(s,a)$最大的那个$a$。<br>则有最大收益的递推公式</p><script type="math/tex; mode=display">Q^h(s,a) = R(s,a) + \sum_{s^{'}} T(s,a,s^{'}) \max_{a^{'}\in A} Q^{h-1}(s^{'},a^{'})</script><h2 id="Infinite-Horizon"><a href="#Infinite-Horizon" class="headerlink" title="Infinite Horizon"></a>Infinite Horizon</h2><p>当$h\rightarrow +\infty$，我们认为可以操作并收益无限轮。<br>这时，时间成本应该被计入：越晚获取的收益，相对于第一轮获取的收益就越不值钱。(Horizon非无限的时候其实也可以引入$\gamma$，只不过其影响一般不大)<br>我们引入一个Discount Factor $\gamma \in (0,1)$ 。表示物品价值的折损率。<br>从第一轮开始，经过$t$轮后，其价值相对于第一轮收益的折损表示为$\gamma^t$。<br>以钱为标的，用$\gamma^{-1}$表示每轮货币通货膨胀的比率。比如一袋米，第1年为1元，第2年就为$\gamma^{-1}$元。第$t+1$年为$\gamma^{-t}$元。<br>假设我每一轮弄到1袋米时间，则总收益为</p><script type="math/tex; mode=display">V = 1 + \gamma + \gamma^2 + \gamma^3 + \dots = \frac{1}{1-\gamma}</script><p>从单调性来看，$\gamma$越小，价值缩水的越快，总收益越小，则$V$越小。<br>我们记初始状态为$s$，策略集为$\pi:s\rightarrow a$，则无穷期限的总收益$V_\pi(s)$为</p><script type="math/tex; mode=display">V_\pi(s) = R(s,\pi(s)) + \gamma \sum_{s^{'}\in S} T(s,\pi(s),s^{'}) V_\pi(s^{'})</script><p>往方程里分别代入$S$集合中的所有$s$，这个方程可以写出由$|S|$个线性方程组成的线性方程组。<br>记$n=|S|,S={s_1,s_2,s_3,\dots,s_n}$，<br>则每一个可以整理为</p><script type="math/tex; mode=display">V_\pi(s_i) - \gamma \sum_{j=1}^n T(s_i,\pi(s_i),s_j) V(s_j) = R(s_i,\pi(s_i))</script><p>矩阵表示为</p><script type="math/tex; mode=display">(E - \gamma P)V = R</script><p>其中：</p><ul><li>$E$为$n$阶单位矩阵。</li><li>$P$为转移概率矩阵，$P_{ij}=T(s_i,\pi(s_i),s_j)$。</li><li>$V$为价值函数向量，为待求的未知数。</li><li>$R$为即时奖励向量。</li></ul><p>$\gamma$小于1时，可保证矩阵可逆，则可解出唯一的解向量$V$。</p><p>对于最优策略：假设$s$状态$a$操作之后，做出的每一步策略都是最优策略得到的总收益为$Q(s,a)$，则有</p><script type="math/tex; mode=display">Q(s,a) = R(s,a) + \gamma \sum_{s^{'}\in S} T(s,a,s^{'}) \max_{a^{'}\in A} Q(s^{'},a^{'})</script><p>则认为最优策略为</p><script type="math/tex; mode=display">\pi_{Q^*}(s) = argmax_a Q^*(s,a)</script><p>求取最优策略的方法之一：Policy Iteration<br>记第$k$轮策略集为<script type="math/tex">\pi_k</script>，价值函数<script type="math/tex">V_{\pi_k}</script>，则有线性方程组</p><script type="math/tex; mode=display">(E - \gamma P_{\pi_k}) V_{\pi_k} = R_{\pi_k}</script><p>接下来有了确知的$V_{\pi_k}$，基于此改进策略：</p><ul><li>对每个状态$s$，选择使得接下来的总收益值最大的那个$a$作为$\pi_{k+1}(s)$。即<script type="math/tex; mode=display">\pi_{k+1}(s) = argmax_a \left[ R(s,a) + \gamma \sum_{s^{'}} T(s,a,s^{'}) V_{\pi_k}(s^{'}) \right]</script>直到我们发现某一轮后有$\pi_{k+1}=\pi_k$，说明收敛结束，得到最佳策略$\pi^*$。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MDP </tag>
            
            <tag> 最优Q策略 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>卷积神经网络-导论</title>
      <link href="/posts/570edd9c.html"/>
      <url>/posts/570edd9c.html</url>
      
        <content type="html"><![CDATA[<h1 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h1><h2 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h2><p>采用filter，对图像或一维序列取每个局部。在对应位置乘权重最后加和，然后加上偏移量形成新的图像或一维序列的操作。<br><img src="/img/MIT6036/一维卷积举例1.png" alt=""><br>如上图，把最上面的序列依次乘filter上的权重再相加形成新值，再把新值排列形成新序列。<br><img src="/img/MIT6036/一维卷积举例2.png" alt=""><br>这个过程称为Convolution（卷积）。<br>卷积后序列大小减少，比如上图中的10长度序列卷积完产出8长度序列。<br>可以采取对原数据的填充（Padding）。即在信息的边缘同时补一个值（默认补0），再卷积，即可确保产出的信息不损失大小。<br><img src="/img/MIT6036/一维卷积的Padding举例.png" alt=""><br>偏移量（Bias）：对卷积完后的值再加一个数字。<br>比如上述图没有再加数字，那结果如上图。<br>如果加了偏移量，则结果序列为1,0,1,0,1,-1,2,0,1,1。<br>二维图像（假设颜色只有0和1）也是同理，此时filter也是二维的。<br><img src="/img/MIT6036/二维卷积举例.png" alt=""><br>Filter的维度和大小（shape）是可以变的。<br>    一维中，不止可以用长度3的Filter。可以用别的长度，甚至可以跳着采样。<br>    其他维度也是同理。</p><h2 id="Dimensions"><a href="#Dimensions" class="headerlink" title="Dimensions"></a>Dimensions</h2><p>一维的数据可称为向量（Vector）<br>二维的数据可称为矩阵（Matrix）<br>三维的数据可称为张量（Tensor）</p><h2 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h2><p>Filter中与原图像相乘的数为权重（Weight）。</p><ul><li>$a×b$的Filter，其参数（权重）为<script type="math/tex">w_1,w_2,w_3......,w_{ab-1},w_{ab}</script><br>Filter采集完后再加的数字为偏移量（Bias）<h1 id="Activation"><a href="#Activation" class="headerlink" title="Activation"></a>Activation</h1>卷积完可以用激活函数进一步处理。<br>一般采用[[Neural Network]]中提到的ReLU函数。<br><img src="/img/MIT6036/卷积后激活举例.png" alt=""><br>这一次卷积+激活，实际上是找到了原一维序列中孤立的1。<br>对于同一张图片，不止可以采用一次Convolution+Activation的操作。<br>称一次Convolution+Activation操作为一个Channel（通道）。<br>实际上可以采取多次。<br>假设采取了n次不同的Convolution+Activation操作，则称这一层的通道数为n。<br><img src="/img/MIT6036/多通道示意图.png" alt=""><h1 id="Max-Pool"><a href="#Max-Pool" class="headerlink" title="Max Pool"></a>Max Pool</h1>Max Pooling（最大池操作）：一种特殊的Filter操作，每次返回Filter覆盖区域中最大的数值。<br>参数<br>  size（shape），即这个Filter一次覆盖的区域。<br>  stride（步长）：一次Filter结束后，跨步的距离。<br>比如Filter的size为3，步长为1，则最大池操作为<br><img src="/img/MIT6036/大小3步长1Filter举例.png" alt=""><br>当Filter的size为3，步长为3，则产出的结果矩阵会更小<br><img src="/img/MIT6036/步长3最大池操作举例.png" alt=""><h1 id="Typical-Architecture-of-CNN"><a href="#Typical-Architecture-of-CNN" class="headerlink" title="Typical Architecture of CNN"></a>Typical Architecture of CNN</h1><img src="/img/MIT6036/卷积神经网络一般架构示意图.png" alt=""><br>获得Input，经过多次卷积+线性整流产生最终图像。（Feature Learning）<br>然后扁平化后再做处理和提取获得结果。（Classification）<br>  扁平化后的数据其实可以看做一个一维向量。<br>  因此可以做前面已经有的<a href="/posts/becca920.html" title="逻辑回归">逻辑回归</a>、<a href="/posts/84aea1c5.html" title="回归模型">回归模型</a>(线性回归)，或再用下游神经网络操作。<h1 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h1>反向传播可以用来求神经网络中某一层中参数的梯度。<br>下面以一个仅有2层的卷积神经网络为例。<br>输入为一个$5×1$列向量$X$。<br>Filter为一个$3×1$列向量$W^{(1)}$。<br>Pad入$X_0,X_6$，则Filter后得结果为$5×1$列向量$Z^{(1)}$。<br>第一层的激活函数为ReLU，结果为$5×1$列向量$A^{(1)}$。<br>第二层直接左乘一个$5×1$列向量的转置$(W^{(2)})^T$。为$A^{(2)}=(W^{(2)})^TA^{(1)}$。结果是一个数。<br>损失函数<script type="math/tex; mode=display">L(A^{(2)},y)=(A^{(2)}-y)^2</script>$W^{(1)}$为隐藏层的参数。要求其梯度需要用链式法则。有<script type="math/tex; mode=display">\frac{\partial L}{\partial W^{(1)}}=\frac{\partial Z^{(1)}}{\partial W^{(1)}}\cdot\frac{\partial A^{(1)}}{\partial Z^{(1)}}\cdot\frac{\partial L}{\partial A^{(1)}}</script>记$a×b$矩阵为$M[a,b]$，维度为k的列向量为$V[k]$。则有向量相偏导数的结果为<script type="math/tex; mode=display">\frac{\partial V[a]}{\partial V[b]}=M[b,a]</script>则可验证上述链式法则的维数合理性<script type="math/tex; mode=display">\begin{matrix}\frac{\partial V[1]}{\partial V[3]}=\frac{\partial V[5]}{\partial V[3]}\cdot\frac{\partial V[5]}{\partial V[5]}\cdot\frac{\partial V[1]}{\partial V[5]}\\M[3,1]=M[3,5]\cdot M[5,5]\cdot M[5,1]\end{matrix}</script>完全合理。下关注其中一个。以$\frac{\partial Z^{(1)}}{\partial W^{(1)}}$为例<br>我们记$Z^{(1)}$的分量为$Z_1^{(1)},Z_2^{(1)},Z_3^{(1)},Z_4^{(1)},Z_5^{(1)}$，$W^{(1)}$的分量为$Z^{(1)}$的分量为$W_1^{(1)},W_2^{(1)},W_3^{(1)}$。<br>则有<script type="math/tex; mode=display">\frac{\partial Z^{(1)}}{\partial W^{(1)}}=\begin{bmatrix}\frac{\partial Z_1^{(1)}}{\partial W_1^{(1)}}\,\,\frac{\partial Z_2^{(1)}}{\partial W_1^{(1)}}\,\,\frac{\partial Z_3^{(1)}}{\partial W_1^{(1)}}\,\,\frac{\partial Z_4^{(1)}}{\partial W_1^{(1)}}\,\,\frac{\partial Z_5^{(1)}}{\partial W_1^{(1)}}\\\frac{\partial Z_1^{(1)}}{\partial W_2^{(1)}}\,\,\frac{\partial Z_2^{(1)}}{\partial W_2^{(1)}}\,\,\frac{\partial Z_3^{(1)}}{\partial W_2^{(1)}}\,\,\frac{\partial Z_4^{(1)}}{\partial W_2^{(1)}}\,\,\frac{\partial Z_5^{(1)}}{\partial W_2^{(1)}}\\\frac{\partial Z_1^{(1)}}{\partial W_3^{(1)}}\,\,\frac{\partial Z_2^{(1)}}{\partial W_3^{(1)}}\,\,\frac{\partial Z_3^{(1)}}{\partial W_3^{(1)}}\,\,\frac{\partial Z_4^{(1)}}{\partial W_3^{(1)}}\,\,\frac{\partial Z_5^{(1)}}{\partial W_3^{(1)}}\end{bmatrix}</script>带入有<script type="math/tex; mode=display">\frac{\partial Z^{(1)}}{\partial W^{(1)}}=\begin{bmatrix}X_0\,\,X_1\,\,X_2\,\,X_3\,\,X_4\\X_1\,\,X_2\,\,X_3\,\,X_4\,\,X_5\\X_2\,\,X_3\,\,X_4\,\,X_5\,\,X_6\end{bmatrix}</script>同理求出其他矩阵，再相乘得出梯度。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 反向传播 </tag>
            
            <tag> CNN </tag>
            
            <tag> 维度分析 </tag>
            
            <tag> NN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络-导论</title>
      <link href="/posts/3c10a607.html"/>
      <url>/posts/3c10a607.html</url>
      
        <content type="html"><![CDATA[<h1 id="Activation-Function"><a href="#Activation-Function" class="headerlink" title="Activation Function"></a>Activation Function</h1><p>激活函数一般是非线性的函数，使得神经网络能够学习复杂模式。<br>最原始的模型为Step Function，但是由于其导数处处为0，因此不适合用于模型训练。</p><script type="math/tex; mode=display">StepFunction:\Phi(x)=1\begin{Bmatrix}w^Tx+w_0>=0\end{Bmatrix}</script><h2 id="常用激活函数"><a href="#常用激活函数" class="headerlink" title="常用激活函数"></a>常用激活函数</h2><p>Sigmoid函数</p><script type="math/tex; mode=display">\sigma(x)=\frac{1}{1+e^{-x}}</script><p>优点：可把原先的0-1二元输出改为输出概率（适合二分类输出）<br>缺点：$|x|$较大时，梯度小，梯度下降慢。<br>tanh函数</p><script type="math/tex; mode=display">tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}</script><p>把+1，-1的标的改为(-1,+1)区间内连续值的输出。<br>ReLU函数</p><script type="math/tex; mode=display">ReLU(x)=\begin{cases}x\,\,\,(x>0)\\0\,\,\,(x<=0)\end{cases}</script><p>Leaky ReLU</p><script type="math/tex; mode=display">LeakyReLU(x)=\begin{cases}x\,\,\,(x>0)\\\alpha x\,\,\,(x<=0)\end{cases}</script><p>其中$\alpha$通常取0.01<br>激活函数通过对数据集的处理并叠加产生新的数据集。<br><img src="/img/MIT6036/激活函数举例图.png" alt=""></p><h1 id="Layer-of-Neural-Network"><a href="#Layer-of-Neural-Network" class="headerlink" title="Layer of Neural Network"></a>Layer of Neural Network</h1><p>对于一个数据集，取其中一个向量x来讨论<br>作为第一层Input，其为一个$m^{(1)}×1$向量。<br>其输出为$A^{(1)}$，为一个$n^{(1)}×1$的向量，满足$A_i^{(1)}=f^{(1)}(w_i^{(1)T}x+w_i^{1})，其中i \in \begin{Bmatrix}1,2,3……,n^{(1)}\end{Bmatrix}$。<br>把所有的$A_i^{(1)}$纵向拼成一个大的列向量作为第一个Layer的输出。<br>接下来重新定义$f^{(i)}$：它可以是一个激活函数。我们认为其不止作用于一个数，而是作用于一个列向量。即对列向量的每一个数都做同样的动作，然后把对应的结果生成一个新的列向量。<br>则有</p><script type="math/tex; mode=display">A^{(1)}=f^{(1)}(W^{(1)T}x+W_0^{(1)})</script><p>其中，$W^{(1)}$为$m^{(1)}×n^{(1)}$矩阵，$W_0^{(1)}$为$n^{(1)}×1$向量。<br>对于下一层（第二层），有$m^{(2)}=n^{(1)}$。即上一层的输出向量为下一层的输入向量。<br>接下来进行类似的处理。</p><script type="math/tex; mode=display">A^{(2)}=f^{(2)}(W^{(2)T}A^{(1)}+W_0^{(2)})</script><p>直到最后一层。<br>整体来看</p><script type="math/tex; mode=display">A(last) = NN(x,W,W_0)</script><h1 id="Function-Graph"><a href="#Function-Graph" class="headerlink" title="Function Graph"></a>Function Graph</h1><p>以图表示神经网络<br>每一层(Layer)的结构：Inputs-Dot Product(线性变换)-Pre-activation(图中Z列)-Activation Function-Activation(图中A列)<br><img src="/img/MIT6036/神经网络的一层示意图.png" alt=""><br>中间的操作步骤视为一个神经元(neuron/unit/node)。则图中这一层有$n^{(1)}$个神经元。<br>Fully Connected<br>    对于层：一个层中的每一个输入的向量进行的操作都相同，产出对应量的输出向量。<br>    对于神经网络：一个神经网络中的所有层都是Full Connected，则这个神经网络也是Fully Connected。<br>对于一个神经网络中的层<br>    最后一层为输出结果的层，称为输出层(Output Layer)。<br>    对于输出层前面的层，称为隐藏层(Hidden Layer)。<br>每一层都可以部署回归或分离器的神经元。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NN </tag>
            
            <tag> 激活函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>回归模型</title>
      <link href="/posts/84aea1c5.html"/>
      <url>/posts/84aea1c5.html</url>
      
        <content type="html"><![CDATA[<h1 id="Regress（回归）"><a href="#Regress（回归）" class="headerlink" title="Regress（回归）"></a>Regress（回归）</h1><p><a href="/posts/4aa284f3.html" title="机器学习基础">机器学习基础</a>中的分类器是找到一条能大致切分平面中不同种类点的超平面的假设。返回值是+1或者-1或者+1的预测概率。<br>回归器是在d维空间中找到一个超平面（或曲面）来大致拟合数据点的走向。<br>其Label $y^{(i)}\in R$。<br>假设h为 $h：R^d\rightarrow R$。<br><img src="/img/MIT6036/一元回归器举例.png" alt=""><br>回归器的损失采取Squared Error Loss：$L(g,a)=(g-a)^2$。<br>    $g,a \in R$<br>    其中g是回归模型的预测值，a是给定数据集对应位置的实际值。</p><h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><p>给定一个超平面$(\theta,\theta_0)$，以及一个数据集。<br>对于一个位置向量$x$，这个线性回归的预测（假设）为$h(x;\theta,\theta_0)=\theta^T x+\theta_0$<br>则平方损失为</p><script type="math/tex; mode=display">J(\theta,\theta_0)=\frac{1}{n}\sum_{i=1}^nL(h(x^{(i)};\theta,\theta_0),y^{(i)})=\frac{1}{n}\sum_{i=1}^n(\theta^Tx^{(i)}+\theta_0-y^{(i)})^2</script><p>$\theta_0$很碍眼。我们用[[Perceptron]]中的扩维操作，对所有x向量扩维，并对$\theta$向量扩维。</p><script type="math/tex; mode=display">\begin{matrix}x^{(i)}_{new}\in R^{d+1},x_{new}^{(i)}=\begin{bmatrix}x_1^{(i)},x_2^{(i)},x_3^{(i)},x_4^{(i)}......,x_d^{(i)},1\end{bmatrix}\\\theta_{new}\in R^{d+1},\theta_{new}=\begin{bmatrix}\theta_1,\theta_2,\theta_3,\theta_4......,\theta_d,\theta_0\end{bmatrix}\end{matrix}</script><p>为方便后续计算，我们重新把扩维后的维数记为d维。<br>则平方损失为</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{n}\sum_{i=1}^n(\theta^Tx^{(i)}-y^{(i)})^2=\frac{1}{n}\sum_{i=1}^n((x^{(i)})^T\theta-y^{(i)})^2</script><p>为方便表示，我们直接定义数据集中的位置向量集为$n×d$矩阵（同一向量以行排列）</p><script type="math/tex; mode=display">\widetilde{X}=\begin{bmatrix}x_1^{(1)}\,\,x_2^{(1)}\,\,......\,\,x_d^{(1)}\\x_1^{(2)}\,\,x_2^{(2)}\,\,......\,\,x_d^{(2)}\\......\\x_1^{(n)}\,\,x_2^{(n)}\,\,......\,\,x_d^{(n)}\end{bmatrix}</script><p>再定义数据集中的y值集为$n×1$矩阵</p><script type="math/tex; mode=display">\widetilde{Y}=\begin{bmatrix}y^{(1)}\\y^{(2)}\\...\\y^{(n)}\end{bmatrix}</script><p>由于$(x^{(i)})^T\theta-y^{(i)}$产出一个数字，则$\widetilde{X}\theta-\widetilde{Y}$产出一个$n×1$列向量。<br>则有</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{n}\sum_{i=1}^n((x^{(i)})^T\theta-y^{(i)})^2=\frac{1}{n}|\widetilde{X}\theta-\widetilde{Y}|^2=\frac{1}{n}(\widetilde{X}\theta-\widetilde{Y})^T(\widetilde{X}\theta-\widetilde{Y})</script><p>由于$J(\theta)$的表达式是一个关于$\theta$的二次多项式，因此可以通过公式直接求出最低点。<br>当梯度为$\overrightarrow{0}$，可以认为这个点是这个函数的最小值点。有</p><script type="math/tex; mode=display">\nabla_{\theta}J(\theta)=\frac{2}{n}\widetilde{X}^T(\widetilde{X}\theta-\widetilde{Y})=\overrightarrow{0}</script><p>展开、移项再化简得</p><script type="math/tex; mode=display">\theta=(\widetilde{X}^T\widetilde{X})^{-1}\widetilde{X}^T\widetilde{Y}</script><p>取这个$\theta$，就获得了最优的线性回归器。</p><h1 id="Ridge-Regression"><a href="#Ridge-Regression" class="headerlink" title="Ridge Regression"></a>Ridge Regression</h1><p>有时候，这个$\theta$并非唯一。<br>    直观上的成因：数据坍缩成维度更低的形式（比如原本分布于二维平面上的点集现在只分布于或近似只分布于一条直线上。那拟合结果作为一个平面，自然有过这条线的无数种可能）。<br><img src="/img/MIT6036/拟合结果非唯一的数据集举例.png" alt=""><br>    梯度层面的反应：梯度为0的点不止一个点而是有无数个点（比如下图右图中的情况，梯度为0的点其实分布于一条线上）。<br><img src="/img/MIT6036/拟合结果非唯一的梯度视角.png" alt=""><br>    代数本质：数据集$\widetilde{X}$的秩小于d。<br>        此时$R(\widetilde{X}^T\widetilde{X})&lt;d$，d元线性方程组 $\widetilde{X}^T\widetilde{X}\theta=\widetilde{X}^T\widetilde{Y}$的解非唯一，为一个解集。(上述方程组就是$\theta=(\widetilde{X}^T\widetilde{X})^{-1}\widetilde{X}^T\widetilde{Y}$的前身)<br>        $|\widetilde{X}^T\widetilde{X}|$为0或几乎为0，则$\widetilde{X}^T\widetilde{X}$不存在逆矩阵。无法直接求出$\theta$。因此看到这个行列式为0或近似0，那直接认为理论上可求出的$\theta$不唯一。<br>解决方法：岭回归(Ridge Regression)。<br>核心思想是虽然理论上只能确定无限个$\theta$，我们添加一个条件：要使$|\theta|$尽可能小。<br>这时$\theta$就会受这个制约条件限制而收敛向一个尽可能使得$|\theta|$小的值。<br>类似正则化，岭回归也可以配一个与$|\theta|$有关的量。<br>扩维前的表达式为</p><script type="math/tex; mode=display">J_{ridge}(\theta,\theta_0)=\frac{1}{n}\sum_{i=1}^n((x^{(i)})^T\theta+\theta_0-y^{(i)})^2+\lambda|\theta|^2</script><p>下重点看扩维后的情形。扩维后的表达式为</p><script type="math/tex; mode=display">J_{ridge}(\theta)=\frac{1}{n}|\widetilde{X}\theta-\widetilde{Y}|^2+\lambda|\theta|^2=\frac{1}{n}(\widetilde{X}\theta-\widetilde{Y})^T(\widetilde{X}\theta-\widetilde{Y})+\lambda|\theta|^2</script><p>其中的$\lambda|\theta|^2$类似于[[Logistic Regression]]中Regularizer方法中的penalty。<br>$\lambda$是一个极小的正量，用于配权。<br>令<script type="math/tex">\nabla_{\theta}J_{ridge}(\theta)=0</script>，可以得出</p><script type="math/tex; mode=display">\theta=(\widetilde{X}^T\widetilde{X}+n\lambda E_d)^{-1}\widetilde{X}^T\widetilde{Y}</script><p>其中$E_d$是d阶单位矩阵。<br>其中，$\widetilde{X}^T\widetilde{X}+n\lambda E_d$是一个可逆（Invertible）矩阵。<br>Tips<br>    用于加入训练的数据集中的一列数据，其数量级和分布对之后的$\theta$可能产生较大影响。因此可以进行[[DataSets Preprocessing]]中的数据标准化操作。<br>    上述回归模型依然可以用<a href="/posts/e92b12e5.html" title="数据预处理">数据预处理</a>中的Featurization来处理非数字类型的数据。</p><h1 id="Gradient-Descent-for-Regression"><a href="#Gradient-Descent-for-Regression" class="headerlink" title="Gradient Descent for Regression"></a>Gradient Descent for Regression</h1><p>其实使用公式来求最优$\theta$看似很快（只有一步迭代），但是实际上这个过程中涉及到求逆矩阵。<br>求逆矩阵的时间复杂度为$O(n^3)$（其中n为矩阵阶数）。这导致这样操作很耗时。<br>实际上也可以用梯度下降来实现训练。<br>这样虽然损失了精确性，但是减少了训练所需工作量。<br>下直接给出$J(\theta,\theta_0)$（扩维前）关于$\theta$，$\theta_0$的偏导数，由此可以直接求出梯度：</p><script type="math/tex; mode=display">\begin{matrix}\nabla_\theta J_{ridge}=\frac{2}{n}\sum_{i=1}^n[((x^{(i)})^T\theta+\theta_0-y^{(i)})x^{(i)}]+2\lambda\theta\\\frac{\partial J_{ridge}}{\partial\theta_0}=\frac{2}{n}\sum_{i=1}^n((x^{(i)})^T\theta+\theta_0-y^{(i)})\end{matrix}</script><p>其中，$\theta$是由多个实数组成的向量。给出<script type="math/tex">J_{ridge}(\theta,\theta_0)</script>关于<script type="math/tex">\theta</script>的梯度也可以当偏导数用。其梯度为<script type="math/tex">\begin{bmatrix}\nabla_\theta J_{ridge}\\\frac{\partial J_{ridge}}{\partial\theta_0}\end{bmatrix}</script>。</p><h1 id="Othor-Loss-Example-for-Regression"><a href="#Othor-Loss-Example-for-Regression" class="headerlink" title="Othor Loss Example for Regression"></a>Othor Loss Example for Regression</h1><script type="math/tex; mode=display">\text{RMSE} = \sqrt{ \frac{1}{n} \sum_{i=1}^n \left( y^{(i)} - f(x^{(i)}) \right)^2 }</script>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 梯度 </tag>
            
            <tag> 损失函数 </tag>
            
            <tag> 线性回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>逻辑回归</title>
      <link href="/posts/becca920.html"/>
      <url>/posts/becca920.html</url>
      
        <content type="html"><![CDATA[<h1 id="Linear-Logistic-Classification"><a href="#Linear-Logistic-Classification" class="headerlink" title="Linear Logistic Classification"></a>Linear Logistic Classification</h1><p>有时候给出的数据集无法被Linearly Separate。<br>因此在交汇区域（有+1的数据点也有-1的数据点），我们可以认为是一个概率问题。<br>在其他区域，有产出+1的概率为1或-1的概率为1。<br>而在交汇区域，产出+1的概率为介于0到1中间的某值。<br>因此我们需要一个平滑的曲线（而非跳跃点）来描述样本-产出值的概率。<br><img src="/img/MIT6036/获得平滑概率曲线示意图.png" alt=""><br>假设$A$为样本点产出的数据为+1，则$\overline{A}$表示样本数据点的产出为-1。<br>Linear Logistic Classification可以用于描述$P(A)$的一个函数。<br>典型的用于Linear Logistic Classification的函数：</p><script type="math/tex; mode=display">\begin{matrix}Sigmoid/Logistic\,\,Function\\\sigma(z)=\frac{1}{1+e^{-z}}\end{matrix}</script><p>Sigmoid函数不一定能用于预测所有的情况。有时候需要对传入的数据做几何变换（乘系数θ，加常数θ）。因此可以表示为：</p><script type="math/tex; mode=display">g(x)=\sigma(\theta x+\theta_0)=\frac{1}{1+e^{-(\theta x+\theta_0)}}</script><p>这里只涉及了传入的数据为一维数字的情况。实际上传入的数据点x为d维向量。<br>因此可以把Sigmoid函数的变量推广到d维向量的形式：</p><script type="math/tex; mode=display">\begin{matrix}Given\,d维向量x,则有d维法向量\theta\\g(x)=\sigma(\theta^Tx+\theta_0)=\frac{1}{1+e^{-(\theta^Tx+\theta_0)}}\end{matrix}</script><p><img src="/img/MIT6036/二维数据的Sigmoid函数举例.png" alt=""></p><h1 id="Linear-Logistic-Classification与线性分离器"><a href="#Linear-Logistic-Classification与线性分离器" class="headerlink" title="Linear Logistic Classification与线性分离器"></a>Linear Logistic Classification与线性分离器</h1><p>Linear Logistic Classification可以看作是产出一个概率（预测为1的概率）。我们称这个式子为$Possibility=\sigma(\theta^Tx+\theta_0)$<br>而线性分离器的假设h产出一个确定的值，但不确保这个值对。<br>数学上的统一性：<br>    当我们令$\sigma(\theta^Tx+\theta_0)&gt;0.5$，则依据Sigmoid函数的展开式可以化简得$\theta^Tx+\theta_0&gt;0$。<br>    由此，Logistic Classification预测得概率大于0.5的条件与线性分离器预测为+1的条件相同。<br>然而，当数据并非线性可分时，Logistic Classification有更强的保障性。</p><h1 id="Negative-Log-Likelihood-Loss"><a href="#Negative-Log-Likelihood-Loss" class="headerlink" title="Negative Log Likelihood Loss"></a>Negative Log Likelihood Loss</h1><p>对于一个逻辑分类器($g(x)=\sigma(\theta^Tx+\theta_0)$)和一个给定的数据(已给出一个$x^{(i)}$向量和对应的$y^{(i)}$的值)，我们认为这个逻辑分类器预测对的概率为</p><script type="math/tex; mode=display">Probability(Data\,Point\,i)=\begin{cases}g(x^{(i)})\,\,\,(y^{(i)}=+1)\\1-g(x^{(i)})\,\,\,(y^{(i)}=-1)\end{cases}</script><p>那么给定一个逻辑分类器和一个数据集，其预测全部正确的概率为</p><script type="math/tex; mode=display">Probability(D_n)=\prod_{i=1}^nProbability(Data\,Point\,i)</script><p>这个概率其实反应了一个逻辑分类器的预测水平（产出可信预测的能力）。<br>由于这个值是很多个小于1的正数的乘积，因此会十分小。计算机的精度无法精确模拟如此小的数据。<br>因此可以对整个概率取对数。则上式子右边从一串乘积改为一串取完对数的结果的加和。<br>取对数不改变单调性，因此取完对数和也可以看作逻辑分类器预测水平的标的。<br>再取这个对数的相反数，则可以成为估计这个逻辑分离器预测中产生的损失的一种标的。（预测精确度越高，一方面可认为损失越小，另一方面这个相反数越小。因此这个相反数可以反应这个预测模型的损失）<br>我们称这组取对数再取相反数的结果为负对数似然损失（Negative Log Likelihood Loss，简称NLL损失）。<br>下给出公式（g为猜测，a为实际结果）。对一个数据点的情况：</p><script type="math/tex; mode=display">\begin{matrix}L_{NLL}(g,a)\\=-\log(Provavility(Data\,Point\,i))\\=\begin{cases}-\log g(x^{(i)})\,\,\,(y^{(i)}=+1)\\-\log (1-g(x^{(i)}))\,\,\,(y^{(i)}=-1)\end{cases}\end{matrix}</script><p>对总体数据集的情况：</p><script type="math/tex; mode=display">\begin{matrix}总体NLL损失\\=\frac{1}{n}\sum_{i=1}^nL_{NLL}(\sigma(\theta^Tx^{(i)}+\theta_0),y^{(i)})\\=-\frac{1}{n}\sum_{i=1}^n\log(Probability(Data\,Point\,i))\end{matrix}</script><p>其中$Probability(Data\,Point\,i)=\begin{cases}g(x^{(i)})\,\,\,(y^{(i)}=+1)\1-g(x^{(i)})\,\,\,(y^{(i)}=-1)\end{cases}$</p><h1 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h1><p>逻辑分类器化离散为连续，可以利用基于微分的手法进行训练。<br>一个分类器的参数有d维向量$\theta$和标量$\theta$。一共d+1个参数。<br>在进行逻辑分类器的训练时，可以把所有参数统一成一组变量$\Theta$。</p><script type="math/tex; mode=display">J_{lr}(\Theta)=J_{lr}(\theta,\theta_0)=\frac{1}{n}\sum_{i=1}^nL_{NLL}(\sigma(\theta^Tx^{(i)}+\theta_0),y^{(i)})</script><p>下定义梯度（Gradient）：<br>假设$\Theta\in R^m$，是一个m维向量。有$\Theta=\begin{bmatrix}\Theta_1,\Theta_2,\Theta_3……,\Theta_m\end{bmatrix}^T$。<br>对于关于$\Theta$的函数$f(\Theta)$，其梯度为</p><script type="math/tex; mode=display">Gradient\,\nabla_{\Theta}f=\begin{bmatrix}\frac{\partial f}{\partial\Theta_1},\frac{\partial f}{\partial\Theta_2},\frac{\partial f}{\partial\Theta_3}......,\frac{\partial f}{\partial\Theta_m}\end{bmatrix}^T</script><p>梯度下降(Gradient Descent)是基于梯度来调整参数来使得参数组获得季小损失的算法。<br>梯度下降的参数：初始参数向量$\Theta<em>{init}$，跨度$\eta$，基于数据集确定的分类器函数$f$，梯度$\nabla</em>{\Theta}f$，梯度下降的临界值正数$\epsilon$，训练最大轮数$\tau$（可选可不选）。<br>步骤<br>    Initailize $\Theta^{(0)}=\Theta<em>{init}$<br>    Initailize $t = 0$<br>    Loop<br>        更新t：$t = t + 1$<br>        更新$\Theta$：$\Theta^{(t)}=\Theta^{(t-1)}-\eta \nabla</em>{\Theta}f(\Theta^{(t-1)})$<br>    结束循环的条件（可以依据训练需求实际情况选择其中一个或数个）：<br>        (1) $|f(\Theta^{(t)})-f(\Theta^{(t-1)})|&lt;\epsilon$<br>        (2) $|\Theta^{(t)}-\Theta^{(t-1)}|&lt;\epsilon$<br>        (3) $|\nabla_{\Theta}f(\Theta^{(t)})|&lt;\epsilon$<br>        (4) $t\geq \tau$<br><img src="/img/MIT6036/二维梯度下降举例.png" alt=""><br>Gradient Descent的性质：<br>    如果<br>        $f(\Theta)$是平滑的，且是下凸(convex)的<br>        $f(\Theta)$在$\Theta$全域上至少存在一个全局最优点<br>        $\eta$充分小<br>    那么<br>        经过有限轮梯度下降后，一定会找到在$\epsilon$范围内的最优点。<br>    注意：对于梯度下降算法来说，最优点就是最小值点。</p><h1 id="Regularizer"><a href="#Regularizer" class="headerlink" title="Regularizer"></a>Regularizer</h1><p>当数据集的交汇区没有值时，依据这组数据持续梯度下降下去，会使得$\Theta$的模长越来越大。同时，交汇区的曲线越来越陡峭。这就失去了逻辑回归的意义。<br><img src="/img/MIT6036/交汇区缺乏数据导致的问题举例.png" alt=""><br>因此需要设置这种情况的限制因素。<br>使用较大的$\epsilon$算一种方法，但是容易产生其他问题。<br>可以引入Regularizer（正则化器）来解决这个问题。<br>在原来的用于梯度下降的逻辑回归函数中加入一个与$\theta$的模长有关的项。</p><script type="math/tex; mode=display">J_{lr}(\Theta)=J_{lr}(\theta,\theta_0)=\frac{1}{n}\sum_{i=1}^nL_{NLL}(\sigma(\theta^Tx^{(i)}+\theta_0),y^{(i)})+\lambda|\theta|^2</script><p>其中，$R(\theta)=\lambda|\theta|^2$表示一个Regularizer（或者一个Penalty（惩罚））。<br>当$\theta$模长过大，其平方值在算式中就变得不可忽略，进而印象到梯度下降的方向来防止之。<br>Regularizer的性质：<br>    加入函数后，函数还是可微分且下凸的。<br>    $\lambda$其实是一个用于调节权重的系数。<br>        $\lambda$过大，Regularizer更容易对式子占主导地位<br>        $\lambda$过小，前面的NLLLoss更容易对式子占主导地位<br>定义指示函数$1(condition)$指的是condition成立时返回1；否则返回0。<br>把上述的$J_{lr}(\theta,\theta_0)$函数的梯度求出来则是</p><script type="math/tex; mode=display">\begin{matrix}\frac{\partial J_{lr}}{\partial \theta}=\frac{1}{n}\sum_{i=1}^n[(\sigma(\theta^Tx^{(i)}+\theta_0)-1(y^{(i)}=1))x^{(i)}]+2\lambda\theta\\\frac{\partial J_{lr}}{\partial\theta_0}=\frac{1}{n}\sum_{i=1}^n(\sigma(\theta^Tx^{(i)}+\theta_0)-1(y^{(i)}=1))\end{matrix}</script>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 梯度 </tag>
            
            <tag> 反向传播 </tag>
            
            <tag> 损失函数 </tag>
            
            <tag> 线性回归 </tag>
            
            <tag> 过拟合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据预处理</title>
      <link href="/posts/e92b12e5.html"/>
      <url>/posts/e92b12e5.html</url>
      
        <content type="html"><![CDATA[<h1 id="Encode-Data-in-Usable-Form-Featurization"><a href="#Encode-Data-in-Usable-Form-Featurization" class="headerlink" title="Encode Data in Usable Form(Featurization)"></a>Encode Data in Usable Form(Featurization)</h1><p>有时，数据集中的数据并不可以直接变成可以直接变成数字的形式用于分析。因此需要一些其他标的对数据进行预处理。<br>这些预处理本身就是一种映射（Mapping）。把原来的数据$x(比如区间、字符串)$映射成可以用于线性化数据训练的数据$\phi(x)$。<br>下以分析心脏病发病的情况为例阐述如何把数据预处理。<br><img src="/img/MIT6036/心脏病样本调查表.png" alt=""></p><h2 id="0-1Mapping"><a href="#0-1Mapping" class="headerlink" title="0-1Mapping"></a>0-1Mapping</h2><p>图中第一列“Has heart disease”中只有是或者否，则可以用数据1表示是，0表示否。由此参与学习模型。</p><h2 id="One-hot-Encoding"><a href="#One-hot-Encoding" class="headerlink" title="One-hot Encoding"></a>One-hot Encoding</h2><p>图中“Job”栏无法用单一数据表述两者的区别。<br>因为如果给每个职业都赋一个值：护士-1，高管-2，医生-3。依据线性运算的理念，可以认为“高管介于护士和医生之间”。但没有任何明确标的来对这些职业做排序。<br>所以我们可以采取升维，把所有职业列入一张表。<br><img src="/img/MIT6036/单一热点编码示意图.png" alt=""><br>如上图。假设一共有5个职业，则把表示职业的列扩维成5列。每个职业只在对应的维度为1。</p><h2 id="Factored-Encoding"><a href="#Factored-Encoding" class="headerlink" title="Factored Encoding"></a>Factored Encoding</h2><p>对于上图中的药物栏，如果采取One-hot Encoding，则需要用到$2^2=4$维(p,p&amp;b,b,null)。并且无法体现p与p&amp;b两组中共同用了p药物这样的关系。<br>因此可以用Factored Encoding：药物有几种，就用几维。<br><img src="/img/MIT6036/要素导向编码示意图.png" alt=""></p><h2 id="Using-a-Representative-for-a-Range"><a href="#Using-a-Representative-for-a-Range" class="headerlink" title="Using a Representative for a Range"></a>Using a Representative for a Range</h2><p>表中的年龄，照理可以用一个年龄段的中间数来表示一个区间。<br>然而实际上，对于一个表示区间的数据，有时候用区间的中间值（即为每个区间给予了默认值）其实有失偏颇。<br>因此需要用一个代表数据来表示一个区间。<br>因此，可以把表中的20s映射为2,40s映射为4，50s映射为5。</p><h2 id="Unary-Thermometer-Code"><a href="#Unary-Thermometer-Code" class="headerlink" title="Unary/Thermometer Code"></a>Unary/Thermometer Code</h2><p>有些数据之间有程度关联但是无法定义明确的线性关系（Ordinal Data）。<br>比如强烈反对-反对-中立-同意-强烈同意之间，有程度区别但是没法定义每种态度之间的心理差别是一样的（各种态度的关系是线性的）。有时候同意和强烈同意之间的差别大于中立和同意之间的差别。因此没法用一个数字表示。<br>因此可用温度计编码。<br>比如一共有5种态度，则可以扩维成5维。每种态度对应的列前面的列全为1，后面的全为0：<br><img src="/img/MIT6036/温度计编码示意图.png" alt=""></p><h1 id="Standardize-Numerical-Datas"><a href="#Standardize-Numerical-Datas" class="headerlink" title="Standardize Numerical Datas"></a>Standardize Numerical Datas</h1><p>有时数字类型的数据在数量级上区别很大，对于有些学习算法来说训练十分困难。因此需要对数字类型标准化。<br>假设数据集中某一列数据为数据类型。记为$x_d^{(1)}，x_d^{(2)}，x_d^{(3)}，x_d^{(4)}……,x_d^{(n)}$，他们的算数平均值为$\overline{x}$,标准差为σ。<br>则对一个数据，标准化后为</p><script type="math/tex; mode=display">\phi_d^{(k)}=\frac{x_d^{(k)}-\overline{x}}{σ}</script><h1 id="Processing-of-Nonlinear-Boundaries"><a href="#Processing-of-Nonlinear-Boundaries" class="headerlink" title="Processing of Nonlinear Boundaries"></a>Processing of Nonlinear Boundaries</h1><p><img src="/img/MIT6036/非线性边缘数据集举例.png" alt=""><br>有些数据集不同区域的边缘并非直线（如左下角图）。这就需要引入Taylor Polynomial（泰勒多项式）。<br>分离器的本质：对于一个d元函数$z=f(x_1,x_2……,x_d)+h_0$，<br>    若满足$z&gt;0$，则判定为y=+1<br>    若满足$z&lt;0$，则判定为y=-1<br>线性分离器的$f(x_1,x_2……,x_d)$满足对于所有变量，都是一次的。<br>其他的函数不一定时一次的，但我们知道如果如果对函数泰勒展开，则一定会形成一个多项式的形式。<br>我们取所有次数低于a的项，那这些项里包含</p><div class="table-container"><table><thead><tr><th>次数</th><th>项</th></tr></thead><tbody><tr><td>0</td><td>$h_0$</td></tr><tr><td>1</td><td>$x_1,x_2,x_3……,x_d$</td></tr><tr><td>2</td><td><script type="math/tex">x_1^2,x_2^2,x_3^2......,x_d^2,x_1x_2,x_1x_3......x_1x_d,......x_{d-1}x_d</script></td></tr><tr><td>3</td><td>所有三次项（包括一个变量的立方，两个变量一个一次一个两次，三个变量各一次）</td></tr><tr><td>……</td><td>……</td></tr><tr><td>a</td><td>同上</td></tr></tbody></table></div><p>依照上面的展开方法，把一个样本的上述的所有的项放在一个新的向量里形成一个新的样本。<br>这个样本其实维度还是d，但是向量长度比d长。因为只需确定$x_1,x_2,x_3……,x_d$共d个值，就可以确定整个向量。</p><h1 id="Detecting-Overfitting（过度拟合）"><a href="#Detecting-Overfitting（过度拟合）" class="headerlink" title="Detecting Overfitting（过度拟合）"></a>Detecting Overfitting（过度拟合）</h1><h2 id="Definition-of-Overfitting"><a href="#Definition-of-Overfitting" class="headerlink" title="Definition of Overfitting"></a>Definition of Overfitting</h2><p>对于一个数据集，有时候会出现过度拟合的状况。<br><img src="/img/MIT6036/过度拟合举例.png" alt=""><br>如图。图中的样本可以用线性分离器来拟合。<br>但是图中应该是采用了高次的拟合方法，使得把y=+1的值都极度精确的描出来了（过于依赖样本数据）。这会在实际应用中产生错误。</p><h2 id="Rough-Ways-to-Detect-Overfitting-of-a-Learning-Algorithm"><a href="#Rough-Ways-to-Detect-Overfitting-of-a-Learning-Algorithm" class="headerlink" title="Rough Ways to Detect Overfitting of a Learning Algorithm"></a>Rough Ways to Detect Overfitting of a Learning Algorithm</h2><p>对于一个已有的数据集，我们可以做一个分类：一部分纯用于训练，另一部分用于检测训练结果。</p><ul><li>一般有训练-测试用数据以3:1分开或者1:1分开。</li><li>训练用的数据多，则越接近真实情况。</li><li>测试用的数据多，则检测时的噪音更小。</li><li>可以将数据集shuffle（重新排列）来减小一些极端情况（比如训练用的数据大多都y=+1，测试用的大多都y=-1）。<h2 id="More-Precise-Way-to-Evaluate-a-Learning-Algorithm"><a href="#More-Precise-Way-to-Evaluate-a-Learning-Algorithm" class="headerlink" title="More Precise Way to Evaluate a Learning Algorithm"></a>More Precise Way to Evaluate a Learning Algorithm</h2>方法：Cross-Validate(Dn,k)</li></ul><ol><li>把数据随机平均分成k组<br>记为 <script type="math/tex">D_{n,1},D_{n,2},D_{n,3},\dots,D_{n,k}</script>。</li><li>然后进行k轮循环。在第i轮中:<br>基于 <script type="math/tex">D_n/D_{n,i}</script> 这个数据集训练出一个 <script type="math/tex">h_i</script>。其中 <script type="math/tex">D_n/D_{n,i}=\{x|x\in D_n且x\notin D_{n,i}\}</script><br>基于 <script type="math/tex">D_{n,i}</script> 这个数据集计算出这一轮的平均误差 <script type="math/tex">\varepsilon(h_i,D_{n,i})</script>。</li><li>最后返回 <script type="math/tex">Res=\frac{1}{k}\sum_{i=1}^k\varepsilon(h_i,D_{n,i})</script>。如果使用0-1Loss，那么这个返回值应该介于0和1之间。</li><li>比较有没有组的平均误差与Res有明显差别。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据集 </tag>
            
            <tag> 过拟合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习基础</title>
      <link href="/posts/4aa284f3.html"/>
      <url>/posts/4aa284f3.html</url>
      
        <content type="html"><![CDATA[<h1 id="Data-Set-and-Hypothesis"><a href="#Data-Set-and-Hypothesis" class="headerlink" title="Data Set and Hypothesis"></a>Data Set and Hypothesis</h1><p>在机器学习中，数据可以表示为vector的形式。<br>一个d维欧几里得空间中的一个vector x为</p><script type="math/tex; mode=display">x = (x_1,x_2,x_3,......,x_d)</script><p>设一个数据集有n个向量。则表示为(右上角括号里的数不是指数，而可以理解为上标，表示数据集中第i个向量)</p><script type="math/tex; mode=display">\begin{matrix}可记数据集(Training data)为D_n\\则i \in \begin{Bmatrix}{1,2,3,......,n}\end{Bmatrix}\\x^{(i)} = (x_1^{(i)},x_2^{(i)},x_3^{(i)},......,x_d^{(i)})\end{matrix}</script><p>标记器Label：y(x)为输出端。一个vector x可以对应一个输出y。<br>当y为一个二元输出结果时，可以定义一个假设h</p><script type="math/tex; mode=display">\begin{matrix}Label\,\,\,\,y \in \begin{Bmatrix}-1,+1\end{Bmatrix}\\Define \,Hypothesis\\h:R^d\rightarrow\begin{Bmatrix}-1,+1\end{Bmatrix}\\其中R^d为定义在d维上的欧几里得空间\end{matrix}</script><p>依据一个假设h，可以定义一个假设函数：y = h(x)<br>假设集H：所有假设h形成的集合记为H。</p><h1 id="Linear-Classifier"><a href="#Linear-Classifier" class="headerlink" title="Linear Classifier"></a>Linear Classifier</h1><p><img src="/img/MIT6036/线性分离器的推导示意图.png" alt=""><br>如图，任意一个给定的vector θ，由其方向可以确定无数条垂直于θ的直线（红线）。<br>对于所有起点位于远点，终点落在某一条红线上的vector x，有</p><script type="math/tex; mode=display">\frac{\theta^T\cdot x}{|\theta|} = a</script><p>把常数统一，该式子可以化成</p><script type="math/tex; mode=display">\theta^T\cdot x + \theta_0 = 0</script><p>不难得出</p><script type="math/tex; mode=display">\begin{matrix}以\theta^T\cdot x + \theta_0=0为分界线\\\theta^T\cdot x + \theta_0 \geq  0表示\theta正方向上的空间\\\theta^T\cdot x + \theta_0 \leq  0表示\theta负方向上的空间\end{matrix}</script><p>则依据线性分类器，可以定义假设</p><script type="math/tex; mode=display">h(x,\theta,\theta_0) = \begin{cases}+1(\theta^T\cdot x + \theta_0 \geq  0)\\-1(\theta^T\cdot x + \theta_0 < 0)\end{cases}</script><p>其中，θ和θ0为参数(parameters)，表述的是假设本身的性质。而x是变量，是假设中的因子用于确定y。<br>假设集H是所有如此定义的h的集合。</p><h1 id="判断假设的好坏：Loss-Assessment"><a href="#判断假设的好坏：Loss-Assessment" class="headerlink" title="判断假设的好坏：Loss Assessment"></a>判断假设的好坏：Loss Assessment</h1><p>假设应该能够用于在新的情况下预测出正确的结论。<br>因此可以用这个能力确定判定的好坏。<br>可以用损失函数L(Loss)来记录当预测错误或偏差时，造成的损失。<br>记依据假设给出的预测值是g(Guess) ，而实际值是a(Actual)。则可以定义L(g,a)。<br>比如<br>0-1 loss</p><script type="math/tex; mode=display">L(g,a) = \begin{cases}0(a=g)\\1(a\neq g)\end{cases}</script><p>asymmetric loss（非对称损失，强调一些预测失误的情况损失极大，需要优先避免）</p><script type="math/tex; mode=display">L(g,a)=\begin{cases}1(g=1,a=-1)\\100(g=-1,a=1)\\0(else)\end{cases}</script><p>用L(g,a)检测平均误差</p><script type="math/tex; mode=display">\begin{matrix}基于n'个新的样例获得Test\,\,\,Error\\\varepsilon(h,D_{new\,n^{'}})=\frac{\sum_{i=n+1}^{n+n'}L(h(x^{(i)}),y^{(i)})}{n'}\\基于原有n个样例获得Test\,\,\,Error\\\varepsilon_n(h,D_n)=\frac{\sum_{i=1}^{n}L(h(x^{(i)}),y^{(i)})}{n}\end{matrix}</script><p>获得的平均误差更小的h认为更优。</p><h1 id="Concept-of-Learning-Algorithm"><a href="#Concept-of-Learning-Algorithm" class="headerlink" title="Concept of Learning Algorithm"></a>Concept of Learning Algorithm</h1><p><img src="/img/MIT6036/学习算法功能示意图.png" alt=""><br>一个假设可以根据数据集中的一组数据获得一个预测。<br>学习算法可以基于数据集Dn获得一个较优的假设来用于更好的预测。<br>一个简易的学习功能实现<br>    执行k次循环：<br>        随机取样θ，θ0，形成一个假设h。<br>        计算这个h的平均误差。<br>        再随机取样。直到k次循环全部结束。<br>    记录并返回所有h中，使得平均误差最小的h。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据集 </tag>
            
            <tag> 损失函数 </tag>
            
            <tag> 线性分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>感知器</title>
      <link href="/posts/94d11b34.html"/>
      <url>/posts/94d11b34.html</url>
      
        <content type="html"><![CDATA[<h1 id="Perceptron-Algorithm（感知器算法）"><a href="#Perceptron-Algorithm（感知器算法）" class="headerlink" title="Perceptron Algorithm（感知器算法）"></a>Perceptron Algorithm（感知器算法）</h1><p><img src="/img/MIT6036/感知器算法流程图.png" alt=""><br>初始化后，预设进行τ次调整（有些数据无法在有限次调整后完成学习）。<br>if语句后面的含义</p><script type="math/tex; mode=display">\begin{matrix}预测反应结果正确的情况\begin{cases}y^{(i)}=+1且\theta^Tx^{(i)}+\theta_0>0\\y^{(i)}=-1且\theta^Tx^{(i)}+\theta_0<0\end{cases}\\反应结果错误的情况（需要进入if之后的调整语句）\begin{cases}y^{(i)}与\theta^Tx^{(i)}+\theta_0异号(预测错误)\\x^{(i)}=\overrightarrow{0}且\theta_0=0(刚初始化完)\\\theta^Tx^{(i)}+\theta_0=0(样本点落在分界超平面上)\end{cases}\\当向量空间维度为d，超平面指的就是d-1维的面。\\一个超平面可以线性地把d维空间分成两片。\end{matrix}</script><p>更新操作的效果<br><img src="/img/MIT6036/更新操作的效果示意图.png" alt=""><br>更新后，把跟新的数据代入if后面的表达式左侧，可以发现化简完比原来多出一个恒正的量。因此更新后的假设更有可能做正确的预测。<br>但是依据原数据进行这样一次更新，必不一定能让更新后的假设预测原数据取得正确的结果。<br>如果每次更新都计算一次对于所有样本的Test Error，则一次更新后的Test Error不一定会比上次小。因此训练中还是需要记录使得Test Error最小的h，并确保感知器算法的输出结果要么是这个h，要么是循环跳出后最终的h。</p><h1 id="Linearly-Separable（线性可分性）"><a href="#Linearly-Separable（线性可分性）" class="headerlink" title="Linearly Separable（线性可分性）"></a>Linearly Separable（线性可分性）</h1><p>线性可分性是对于数据集的性质。其表述为正负的点一定可以被一个超平面完美切分（一侧的样本全为正，一侧的样本全为负，即所有样本数据可以被线性分类器正确分类）。<br>数学语言表述：</p><script type="math/tex; mode=display">\begin{matrix}If\,\,there\,\,exists\,\,\theta\,\,and\,\,\theta_0,\,\,such\,\,that\\for\,\,every\,\,point\,\,index\,\,i\in\begin{Bmatrix}1,2,3,4,5......,n\end{Bmatrix}\\we\,\,have\,\,y^{(i)}(\theta^Tx^{(i)}+\theta_0)>0\\Then\,\,we\,\,verdict\,\,DataSet\,\,D_n\,\,as\\Linearly\,\,Separable.\end{matrix}</script><h1 id="Margin-of-DataSet"><a href="#Margin-of-DataSet" class="headerlink" title="Margin of DataSet"></a>Margin of DataSet</h1><p>可以推导出空间中一点x* 与一个超平面(θ，θ0)的有向距离为（在θ指向的方向为正，在θ指向的方向的反方向为负）：</p><script type="math/tex; mode=display">distance(x^*,\theta,\theta_0)=\frac{\theta^Tx^*+\theta_0}{|\theta|}</script><p>基于有向距离的定义，下给出Margin of the Labelled Point的定义（默认为对于超平面θ，θ0）：</p><script type="math/tex; mode=display">Margin(x^{(i)})=y^{(i)}(\frac{\theta^Tx^*+\theta_0}{|\theta|})</script><p>可以认为点对超平面的Margin也是有向的。当这个点被预测正确时，这个值为正；预测错误时，这个值为负或者0。<br>基于点对超平面的Margin，下定义一个DataSet对于一个超平面的Margin（默认为对于超平面θ，θ0）：</p><script type="math/tex; mode=display">Margin(D_n)=min_{i=\begin{Bmatrix}1,2,3,4......,n\end{Bmatrix}}Margin(x^{(i)})</script><p>因此可以知道，如果一个线性分类器未能把一组数据完美分类，则这个数据集对其超平面的Margin(Dn)一定不大于0。</p><h1 id="Theorem-of-Perceptron-Performance"><a href="#Theorem-of-Perceptron-Performance" class="headerlink" title="Theorem of Perceptron Performance"></a>Theorem of Perceptron Performance</h1><p>对于满足如下条件的DataSet：</p><script type="math/tex; mode=display">Assumptions\begin{cases}Hypothesis对应的超平面经过空间的原点（超平面的\theta_0=0）\\\\存在\gamma(\gamma>0)与\theta^*，使得对有所数据点i\in\begin{Bmatrix}1,2,3,4......,n\end{Bmatrix}，满足Margin(x^{(i)})>\gamma\\即y^{(i)}(\frac{\theta^Tx^*}{|\theta|})>\gamma\\\\存在R(R>0)，使得对所有的数据点i\in\begin{Bmatrix}1,2,3,4......,n\end{Bmatrix}，满足|x^{(i)}|\leq R\end{cases}</script><p>可以得出如下结论：</p><script type="math/tex; mode=display">上述的Perceptron\,\,Algorithm可以在(\frac{R}{\gamma})^2次更新内，完成学习，产出完美的线性分离器。</script><p>实际上，不是所有数据集都能找到过原点的分类器。<br>我们可以将数据集和分类器升维来满足过原点的需求：</p><script type="math/tex; mode=display">\begin{matrix}Initial:\\x\in R^d,\theta\in R^d,\theta_0\in R\\Point\,x:\theta^Tx+\theta_0=0\\Update \,\,Dimension:\\x_{new}\in R^{d+1},x_{new}=\begin{bmatrix}x_1,x_2,x_3,x_4......,x_d,1\end{bmatrix}\\\theta_{new}\in R^{d+1},\theta_{new}=\begin{bmatrix}\theta_1,\theta_2,\theta_3,\theta_4......,\theta_d,\theta_0\end{bmatrix}\\Then\,\,we\,\,have:\\\theta_{new}^Tx_{new}=0\\注意到\theta_{new}^Tx_{new}与\theta^Tx+\theta_0值一样，则正负性一样，\\则输入同一数据点，升维后的分类器（假设）依然能给出与之前一致的返回值。\end{matrix}</script><p>因此上述结论可以推广到θ0≠0的情况。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习导论(MIT6.036)笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 损失函数 </tag>
            
            <tag> 线性回归 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>文章分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>link</title>
      <link href="/link/index.html"/>
      <url>/link/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>

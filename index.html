<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>SCPZ24-blog - Welcome!</title><meta name="author" content="SCPZ24"><meta name="copyright" content="SCPZ24"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="SCPZ24-blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="SCPZ24-blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/OldWu.png">
<meta property="article:author" content="SCPZ24">
<meta property="article:tag" content="blog,AI,CNN,Transformers,ML,LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/OldWu.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "name": "SCPZ24-blog",
  "alternateName": [
    "Welcome!",
    "example.com"
  ],
  "url": "http://example.com/"
}</script><link rel="shortcut icon" href="/img/lpls.png"><link rel="canonical" href="http://example.com/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.4"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.1.9/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"pagination":{"enable":false,"hitsPerPage":8},"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.13.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'SCPZ24-blog',
  isHighlightShrink: true,
  isToc: false,
  pageType: 'home'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div class="bg-animation" id="web_bg" style="background: linear-gradient(20deg, #fffbeb, #ecfdf5);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/OldWu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">45</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background: linear-gradient(36deg,rgba(46, 0, 102, 0.77) 0%, rgba(9, 9, 121, 0.76) 35%, rgba(0, 212, 255, 0.7) 100%);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">SCPZ24-blog</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="site-info"><h1 id="site-title">SCPZ24-blog</h1></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts nc masonry" id="recent-posts"><div class="recent-post-items"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/4358da15.html" title="小型ToC产品从灵感到落地">小型ToC产品从灵感到落地</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2026-02-10T15:51:00.000Z" title="发表于 2026-02-10 23:51:00">2026-02-10</time></span></div><div class="content">REF: 如何用2小时靠AI做出月入至少$3M美金的APP—by文复利WenFree本博客作为这个视频的听课笔记。 关于产品idea解决情绪需求人类的负面情绪比如渴望，不爽，恐惧。 如何区别真需求解决需求需要有可验证性，这体现在  有这种负面情绪的人很多。 这个产品能解决大多数人的这样的情绪。市面上很多产品会暴死，本质上是因为解决的需求是开发者自己的需求，不是大多数用户的需求。“伪需求“只是想象出来的，看似漂亮的没什么用的功能。真正的需求可用高情绪-高频率-明确的受众-有消费意愿的SOP验证。消费意愿的验证： PayWallScreen 可研究一个需求（对应的现有产品）的下载量和收入，用数据验证需求。  产品足够简单可用一句话清晰表述这个产品是干什么的。 最小可行性产品(MVP)基于一开始的最简单的产品功能，设计一个初始用例。MVP只需要实现这个初始用例。后续的设计，只需要在这个MVP的基础上加功能即可。 需求文档(PRD)PRD不仅用来设计软件，更是可以用来当作AI Coding的prompt。  用户流程 描述用户为了完成某个目标或任务，与产品进行交互的完整路径。它通常以步骤...</div></div></div><div class="recent-post-item"><div class="post_cover"><a href="/posts/4a42f569.html" title="卷积神经网络和树递归神经网络"><img class="post-bg" src="/img/CS224n/%E6%88%AA%E5%B1%8F2025-11-12%2011.58.16.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="卷积神经网络和树递归神经网络"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/4a42f569.html" title="卷积神经网络和树递归神经网络">卷积神经网络和树递归神经网络</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-11-12T00:56:00.000Z" title="发表于 2025-11-12 08:56:00">2025-11-12</time></span></div><div class="content">ConvNetBasicsApart from doing convolution to a 2-D image, we can do convolution to languages.Typically, it should be using a 1-D convolutional layer.To the first layer, the number of input channel is equal to the dimension of word embeddings.After a layer of convolution, we can then apply MaxPool or AveragePool to the features.Also, we can set strides to convolutional filters or pools.Note that pooling can do globally(take average or max through all output features) or locally(only do pooling...</div></div></div><div class="recent-post-item"><div class="post_cover"><a href="/posts/a7b1f35d.html" title="训练优化"><img class="post-bg" src="/img/CS224n/%E6%88%AA%E5%B1%8F2025-11-07%2021.26.04.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="训练优化"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/a7b1f35d.html" title="训练优化">训练优化</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-11-07T03:21:00.000Z" title="发表于 2025-11-07 11:21:00">2025-11-07</time></span></div><div class="content">Mixed Precision TrainingTwo Kinds of floatFP16 and FP 32 are all floats. FP16 takes 2 bytes while FP32 takes 4 bytes.Compared to FP16, FP32 has greater range and is preciser. But it takes more memory and time during computation.It’s common to meet CUDA Out Of Memory exception.But when we are using FP16 throughout the training, some small gradient values will underflow(become zero). We should use both FP16 and FP32. Mixing FP32 and FP16For origin model parameters, we all use FP32 to store them...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/8c119005.html" title="HuggingFace入门">HuggingFace入门</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-11-02T04:55:00.000Z" title="发表于 2025-11-02 12:55:00">2025-11-02</time></span></div><div class="content">Basic python tools are in transformers library.1pip install transformers TokenizerA Large Language Model has its own tokenizer.Tokenizer is the algorithm to divide sentences into a sequence of tokens. Load Tokenizer1from transformers import DistilBertTokenizer, DistilBertTokenizerFast, AutoTokenizer DistilBert is the distilled version of BERT Model.(distill makes the model smaller but has similar function)DistilBertTokenizer is its Tokenizer.DistilBertTokenizerFast the version rewrite in Rust...</div></div></div><div class="recent-post-item"><div class="post_cover"><a href="/posts/26410c69.html" title="预训练后续"><img class="post-bg" src="/img/CS224n/%E6%88%AA%E5%B1%8F2025-11-01%2023.18.56.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="预训练后续"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/26410c69.html" title="预训练后续">预训练后续</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-11-01T06:32:00.000Z" title="发表于 2025-11-01 14:32:00">2025-11-01</time></span></div><div class="content">Prompting for Pretrained ModelsThis involves no gradient steps!Pretrained models have learned some basic tools and knowledges to handle human language tasks.Take GPT as example. GPT is a decoder that can generated a sequence of tokens based on input tokens(may be human’s questions).When it’s not finetuned for specific tasks, we can still use some prompts(ask it explicitly in the input sentence) to let it handle specific tasks with already learned general skills.The state that the model is tra...</div></div></div><div class="recent-post-item"><div class="post_cover"><a href="/posts/b1811702.html" title="预训练"><img class="post-bg" src="/img/CS224n/%E6%88%AA%E5%B1%8F2025-10-31%2023.46.08.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="预训练"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/b1811702.html" title="预训练">预训练</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-31T13:07:00.000Z" title="发表于 2025-10-31 21:07:00">2025-10-31</time></span></div><div class="content">SubwordA trained embedding can’t cover every word in human language(humans are keeping generating new words, and there misspelling of human).If we keep signing this words with &lt;Unk&gt;(unknown) token, then great amount of information will be missed. Byte-pair Encode AlgorithmThen, we can generate some subword tokens according to the appearing frequency in the corpus of specific character combinations.In detail, we do  Separate the whole text into smallest units(usually one character). Each...</div></div></div><div class="recent-post-item"><div class="post_cover"><a href="/posts/ab3e853d.html" title="Transformers"><img class="post-bg" src="/img/CS224n/%E6%88%AA%E5%B1%8F2025-10-28%2019.47.08.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Transformers"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/ab3e853d.html" title="Transformers">Transformers</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-27T03:06:00.000Z" title="发表于 2025-10-27 11:06:00">2025-10-27</time></span></div><div class="content">For RNNs, it’s difficult to handle word that are far from each other but have dependencies.Moreover, GPUs work well in doing parallelizable tasks such as matrix multiplication. For recurrent jobs, GPUs can’t work well.Transformers can take advantages of parallel computing of GPUs.Time cost for transformers is $O(dn^2)$ while for RNN is $O(d^2n)$.In which, $d$ is the dimension of word vectors and $n$ is the sequence length. Self-attentionSimilarity with RNN’s AttentionRecall the Attention proc...</div></div></div><div class="recent-post-item"><div class="post_cover"><a href="/posts/ade63eae.html" title="RNN进阶"><img class="post-bg" src="/img/CS224n/%E6%88%AA%E5%B1%8F2025-10-24%2023.16.44.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="RNN进阶"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/ade63eae.html" title="RNN进阶">RNN进阶</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-24T15:25:00.000Z" title="发表于 2025-10-24 23:25:00">2025-10-24</time></span></div><div class="content">Long Short-Term Memory RNNsLSTM introduces some gates into the model.Cell content is the container vector to store long-term memories.The sigmoids in the forget gate, input gate and output gate are used to turn switch on($1$) or off($0$), in order decide which value in the coming vector remains and which discards.For example, if the model judges that a certain dimension of $c^{(t-1)}$ should be forgotten, then the same dimension in $f^{(t)}$ should be nearly $0$. Then after element-wise produ...</div></div></div><div class="recent-post-item"><div class="post_cover"><a href="/posts/6fe72dd0.html" title="RNN"><img class="post-bg" src="/img/CS224n/%E6%88%AA%E5%B1%8F2025-10-23%2020.57.19.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="RNN"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/6fe72dd0.html" title="RNN">RNN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-22T16:44:00.000Z" title="发表于 2025-10-23 00:44:00">2025-10-23</time></span></div><div class="content">Language ModelingThe task of a language model is to predict the next word given the formal several context words.For example, when typing some words in a keyboard, the phone will predict some potential next words.Recurrent Neural Network(RNN) is a common tool to build a language model. Brief Structure of RNNA sentence is actually a sequence of words.RNN can take in previous words and predict the upcoming words. Generating WordsViewing the ContextLook up the embedding of each word in the seque...</div></div></div><div class="recent-post-item"><div class="post_cover"><a href="/posts/b610878f.html" title="依存句法分析"><img class="post-bg" src="/img/CS224n/%E6%88%AA%E5%B1%8F2025-10-20%2022.45.19.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="依存句法分析"></a></div><div class="recent-post-info"><a class="article-title" href="/posts/b610878f.html" title="依存句法分析">依存句法分析</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-19T13:44:00.000Z" title="发表于 2025-10-19 21:44:00">2025-10-19</time></span></div><div class="content">Dependency StructureThe structure of a sentence can usually be shown in a tree.Sentence structure consists of relations between words, which are normally binary asymmetric relations(“arrows”) called dependencies.For example, the sentence “[ROOT] Bills on ports and immigration were submitted by Republican Senator Brownback of Kansas.” can be represented by a treeThe root is a assist node to help parse the sentence. There is a tree in an array to describe the whole structure.In the sentence abo...</div></div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><a class="page-number" href="/page/3/#content-inner">3</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/OldWu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">SCPZ24</div><div class="author-info-description">软件工程大二学生，努力成为极客中。</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">45</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/SCPZ24"><i class="fab fa-github"></i><span>Github</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">我的机器学习导论(MIT6.036)和自然语言处理(CS224n)笔记现已上传。欢迎参考交流。</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/4358da15.html" title="小型ToC产品从灵感到落地">小型ToC产品从灵感到落地</a><time datetime="2026-02-10T15:51:00.000Z" title="发表于 2026-02-10 23:51:00">2026-02-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/4a42f569.html" title="卷积神经网络和树递归神经网络"><img src="/img/CS224n/%E6%88%AA%E5%B1%8F2025-11-12%2011.58.16.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="卷积神经网络和树递归神经网络"/></a><div class="content"><a class="title" href="/posts/4a42f569.html" title="卷积神经网络和树递归神经网络">卷积神经网络和树递归神经网络</a><time datetime="2025-11-12T00:56:00.000Z" title="发表于 2025-11-12 08:56:00">2025-11-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/a7b1f35d.html" title="训练优化"><img src="/img/CS224n/%E6%88%AA%E5%B1%8F2025-11-07%2021.26.04.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="训练优化"/></a><div class="content"><a class="title" href="/posts/a7b1f35d.html" title="训练优化">训练优化</a><time datetime="2025-11-07T03:21:00.000Z" title="发表于 2025-11-07 11:21:00">2025-11-07</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
          </div>
          <ul class="card-category-list expandBtn" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%AE%BA-MIT6-036-%E7%AC%94%E8%AE%B0/"><span class="card-category-list-name">机器学习导论(MIT6.036)笔记</span><span class="card-category-list-count">12</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-CS224n-%E7%AC%94%E8%AE%B0/"><span class="card-category-list-name">自然语言处理(CS224n)笔记</span><span class="card-category-list-count">12</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%90%BD%E5%9C%B0%E8%83%BD%E5%8A%9B/"><span class="card-category-list-name">落地能力</span><span class="card-category-list-count">1</span></a></li>
          </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/" style="font-size: 1.3em; color: rgb(50, 157, 57);">数据集</a><a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 1.45em; color: rgb(50, 127, 167);">损失函数</a><a href="/tags/%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB/" style="font-size: 1.15em; color: rgb(63, 50, 151);">线性分类</a></div></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站信息</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">25</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总浏览量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2026-02-11T15:52:59.486Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background: linear-gradient(36deg,rgba(46, 0, 102, 0.77) 0%, rgba(9, 9, 121, 0.76) 35%, rgba(0, 212, 255, 0.7) 100%);"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2026 By SCPZ24</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.4</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.4"></script><script src="/js/main.js?v=5.5.4"></script><script src="/js/tw_cn.js?v=5.5.4"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.1.9/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden="hidden"></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="local-search-input"><input placeholder="搜索文章" type="text"/></div><hr/><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none;"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.5.4"></script></div></div><script>"use strict";if("serviceWorker"in navigator){navigator.serviceWorker.register("service-worker.js").then((function(reg){reg.onupdatefound=function(){var installingWorker=reg.installing;installingWorker.onstatechange=function(){switch(installingWorker.state){case"installed":if(navigator.serviceWorker.controller){console.log("New or updated content is available.")}else{console.log("Content is now available offline!")}break;case"redundant":console.error("The installing service worker became redundant.");break}}}}))["catch"]((function(e){console.error("Error during service worker registration:",e)}))}</script></body></html>